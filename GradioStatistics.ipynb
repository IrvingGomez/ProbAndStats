{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21f60193",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# To plot\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# To create GUI\n",
    "import gradio as gr\n",
    "\n",
    "# To integrate a function\n",
    "from scipy import integrate\n",
    "\n",
    "# Gamma function\n",
    "from scipy.special import gamma\n",
    "\n",
    "# To calculate statistics\n",
    "from scipy.stats import norm, t, chi2\n",
    "from scipy.stats import hmean, trim_mean, iqr, median_abs_deviation, skew, kurtosis\n",
    "from scipy.stats.mstats import gmean, winsorize\n",
    "from statsmodels.distributions import ECDF\n",
    "\n",
    "# To make hypothesis testing\n",
    "import pingouin as pg\n",
    "from scipy.stats import bartlett, levene\n",
    "from scipy.stats import gaussian_kde\n",
    "\n",
    "# To make linear regression\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b49df773",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROUND = 4 # Number of decimals to round the results\n",
    "\n",
    "df_cache = {\n",
    "    \"df\": None,\n",
    "    \"filtered_df\": None,\n",
    "    \"stats\": None,\n",
    "    \"numeric_cols\": [],\n",
    "    \"categorical_cols\": [],\n",
    "    \"overrides\": {\n",
    "        \"num_to_cat\": [],\n",
    "        \"cat_to_num\": []\n",
    "    }\n",
    "}\n",
    "\n",
    "export_cache = {\n",
    "    \"table\": None,\n",
    "    \"figure\": None\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cac4b5c",
   "metadata": {},
   "source": [
    "# üß† üìê üìä üßÆ üí≠ Statistics class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dea68472",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Statistics():\n",
    "    def __init__(self, data):\n",
    "        self.data = data    \n",
    "        self.n = len(data)  \n",
    "\n",
    "    # --- Descriptive Statistics ---    \n",
    "\n",
    "    # --- Quantiles ---\n",
    "    def CalculateQuantiles(self, prob):\n",
    "        if type(prob) is list:\n",
    "            self.quantiles = pd.DataFrame({'Value': np.quantile(self.data, prob)}, ['Q{}'.format(p) for p in prob])\n",
    "        else:\n",
    "            self.quantiles = pd.DataFrame({'Value': np.quantile(self.data, prob)}, ['Q{}'.format(prob)])\n",
    "\n",
    "    # --- Quartiles ---\n",
    "    def CalculateQuartiles(self):\n",
    "        self.quartiles = pd.DataFrame({'Value': np.quantile(self.data, [0.25,0.5,0.75])},['Q1', 'Q2', 'Q3'])\n",
    "\n",
    "    # --- Central Tendency ---\n",
    "    def CalculateCentralTendency(self, trim_param=0.1, winsor_param=[0.1,0.1], weights=None):\n",
    "\n",
    "        #Mode = mode(data) # To calculate the mode \n",
    "        self.mean = self.data.mean()\n",
    "        self.median = np.median(self.data)\n",
    "        self.interquartile_mean = trim_mean(self.data, 0.25)\n",
    "        \n",
    "        if trim_param is None:\n",
    "            self.trimmed_mean = np.nan\n",
    "        else:\n",
    "            self.trimmed_mean = trim_mean(self.data, trim_param)\n",
    "\n",
    "        if winsor_param is None:\n",
    "            self.winsorized_mean = np.nan\n",
    "        else:\n",
    "            # Winsorized data\n",
    "            data_winsorized = winsorize(self.data, winsor_param)\n",
    "            self.winsorized_mean = data_winsorized.mean()\n",
    "            \n",
    "        if np.all(self.data > 0): # If all observations are greater than zero, calculate geometric and harmonic mean\n",
    "            self.geometric_mean = gmean(self.data)\n",
    "            self.harmonic_mean = hmean(self.data)\n",
    "        else:\n",
    "            self.geometric_mean = np.nan\n",
    "            self.harmonic_mean = np.nan\n",
    "\n",
    "        if weights is None:\n",
    "            self.weighted_mean = np.nan\n",
    "        else:\n",
    "            self.weighted_mean = np.average(self.data, weights=weights)\n",
    "\n",
    "        # Write the statistics in a list\n",
    "        central_tendency = [\n",
    "            self.mean,\n",
    "            self.median,\n",
    "            self.geometric_mean,\n",
    "            self.harmonic_mean,\n",
    "            self.weighted_mean,\n",
    "            self.trimmed_mean,\n",
    "            self.interquartile_mean,\n",
    "            self.winsorized_mean\n",
    "        ]\n",
    "\n",
    "        # Return the statistics as a table\n",
    "        labels = ['Mean', 'Median', 'Geometric Mean', 'Harmonic Mean', 'Weighted Mean', 'Trimmed Mean', 'Interquartile Mean', 'Winsorized Mean']\n",
    "        self.central_tendency = pd.DataFrame({'Value':central_tendency, 'Robust':[1, 0, 0, 0, 0, 1, 1, 1]}, labels)\n",
    "\n",
    "    # --- Dispersion ---\n",
    "    # Auxiliary functions to correct the bias\n",
    "    def c4(self, n):\n",
    "        return np.sqrt(2/(n-1)) * gamma(n/2) / gamma((n-1)/2)\n",
    "\n",
    "    def d2(self, n):\n",
    "        f = lambda x, n: 1 - (1 - norm.cdf(x))**n - (norm.cdf(x))**n\n",
    "        return round(integrate.quad(f, -np.inf, np.inf, args=(n,))[0], 3)\n",
    "    \n",
    "    def CalculateDispersion(self):\n",
    "        # Original estimators\n",
    "        self.S0 = np.std(self.data)             # By default the standard deviation is calculated with zero degrees of freedom\n",
    "        self.S1 = np.std(self.data, ddof=1)     # Standard deviation with one degree of freedom\n",
    "        R = self.data.max() - self.data.min()\n",
    "        IQR = iqr(self.data)                \n",
    "        MAD = median_abs_deviation(self.data)   \n",
    "        AAD = abs(self.data - self.data.mean()).mean()\n",
    "\n",
    "        # Bias correction\n",
    "        S0_bias_correct = self.S0 * np.sqrt(self.n/(self.n-1)) / self.c4(self.n)\n",
    "        S1_bias_corrected = self.S1 / self.c4(self.n)\n",
    "        self.R_bias_corrected = R / self.d2(self.n)\n",
    "        self.IQR_bias_corrected = IQR / (2 * norm.ppf(0.75))\n",
    "        self.MAD_bias_corrected = MAD / norm.ppf(0.75)\n",
    "        self.AAD_bias_corrected = AAD * np.sqrt(np.pi/2)\n",
    "\n",
    "        # Write the statistics in a list\n",
    "        sigma_biased = [self.S0, self.S1, R, IQR, MAD, AAD]\n",
    "        sigma_unbiased = [\n",
    "            S0_bias_correct,\n",
    "            S1_bias_corrected,\n",
    "            self.R_bias_corrected,\n",
    "            self.IQR_bias_corrected,\n",
    "            self.MAD_bias_corrected,\n",
    "            self.AAD_bias_corrected\n",
    "        ] \n",
    "\n",
    "        # Return the statistics as a table\n",
    "        labels = ['Deviation, ddof=0', 'Deviation, ddof=1', 'Range', 'IQR', 'MAD', 'AAD']\n",
    "        self.dispersion = pd.DataFrame({'Value':sigma_biased, 'Value_bias_corrected':sigma_unbiased, 'Robust':[0,0,0,1,1,1]}, labels)\n",
    "\n",
    "    # --- Skew ---\n",
    "    def CalculateSkewness(self):\n",
    "        SkewCentralMoments = skew(self.data)\n",
    "        SkewKStatistics = skew(self.data, bias=False)\n",
    "\n",
    "        self.skew = pd.DataFrame({'Value':[SkewCentralMoments, SkewKStatistics]}, ['Skew Central Moments', 'Skew K Statistics'])\n",
    "    \n",
    "    # --- Kurtosis ---\n",
    "    def CalculateKurtosis(self):\n",
    "        KurtosisCentralMoments = kurtosis(self.data, fisher=False)\n",
    "        KurtosisKStatistics = kurtosis(self.data, fisher=False, bias=False)\n",
    "\n",
    "        self.kurtosis = pd.DataFrame(\n",
    "            {'Value':[KurtosisCentralMoments, KurtosisKStatistics], 'Excess Kurtosis':[KurtosisCentralMoments-3, KurtosisKStatistics-3]},\n",
    "            ['Kurtosis CentralMoments', 'Kurtosis K Statistics']\n",
    "        )\n",
    "\n",
    "    def CalculateDescriptiveStatistics(self, trim_param, winsor_param, weights):\n",
    "        self.CalculateQuartiles()\n",
    "        self.CalculateCentralTendency(trim_param, winsor_param, weights)\n",
    "        self.CalculateDispersion()\n",
    "        self.CalculateSkewness()\n",
    "        self.CalculateKurtosis()\n",
    "\n",
    "    # --- Statistical Inference ---\n",
    "\n",
    "    # --- Confidence Intervals ---\n",
    "    def CalculateCiMean(self, alpha, hat_mean, hat_sigma, dist):\n",
    "        # Calculate confidence interval for the mean\n",
    "        scale = hat_sigma / np.sqrt(self.n)\n",
    "\n",
    "        if dist==\"norm\":\n",
    "            self.ci_mean = norm.ppf(alpha/2, hat_mean, scale), norm.ppf(1-alpha/2, hat_mean, scale)\n",
    "        if dist==\"t\":\n",
    "            # Only if we are using standard deviaiton with one degree of freedom without correction\n",
    "            self.ci_mean = t.ppf(alpha/2, self.n-1, hat_mean, scale), t.ppf(1-alpha/2, self.n-1, hat_mean, scale)\n",
    "        \n",
    "    def CalculateCiMedian(self, alpha, hat_median, hat_sigma):\n",
    "        # Calculate confidence interval based on the median\n",
    "        scale = hat_sigma * np.sqrt(np.pi/(2*self.n))\n",
    "        self.ci_median = norm.ppf(alpha/2, hat_median, scale), norm.ppf(1-alpha/2, hat_median, scale)\n",
    "\n",
    "    def CalculateCiDeviation(self, alpha):\n",
    "        # Calculate confidence interval for the standard deviation\n",
    "        num = self.S1 * np.sqrt(self.n-1)\n",
    "        den_low = np.sqrt(chi2.ppf(1-alpha/2, self.n-1))\n",
    "        den_upp = np.sqrt(chi2.ppf(alpha/2, self.n-1))\n",
    "\n",
    "        self.ci_deviation = num/den_low, num/den_upp\n",
    "\n",
    "    def CalculateConfidenceInterval(self, alpha, hat_mean, hat_median, hat_sigma, dist):\n",
    "        self.CalculateCiMean(alpha, hat_mean, hat_sigma, dist)\n",
    "        self.CalculateCiMedian(alpha, hat_median, hat_sigma)\n",
    "        self.CalculateCiDeviation(alpha)\n",
    "\n",
    "        # Return the statistics as a table\n",
    "        labels = ['Mean', 'Median', 'Deviation']\n",
    "        self.confidence_intervals = pd.DataFrame(\n",
    "            [self.ci_mean, self.ci_median, self.ci_deviation],\n",
    "            index=labels, columns=[\"Lower\", \"Upper\"]\n",
    "        )\n",
    "\n",
    "    # --- Prediction Intervals ---\n",
    "    def CalculatePiMean(self, alpha, hat_mean, hat_sigma, dist):\n",
    "        # Calculate prediction interval based on the mean\n",
    "        scale = np.sqrt(hat_sigma**2 + hat_sigma**2/self.n)\n",
    "\n",
    "        if dist == \"norm\":\n",
    "            self.pi_mean = norm.ppf(alpha/2, hat_mean, scale), norm.ppf(1-alpha/2, hat_mean, scale)\n",
    "        if dist == \"t\":\n",
    "            # Only if we are using standard deviaiton with one degree of freedom without correction\n",
    "            self.pi_mean = t.ppf(alpha/2, self.n-1, hat_mean, scale), t.ppf(1-alpha/2, self.n-1, hat_mean, scale)\n",
    "    \n",
    "    def CalculatePiMedian(self, alpha, hat_median=None, hat_sigma=None):\n",
    "        scale = np.sqrt(hat_sigma**2 + np.pi*hat_sigma**2/(2*self.n))\n",
    "        self.pi_median = norm.ppf(alpha/2, hat_median, scale), norm.ppf(1-alpha/2, hat_median, scale)\n",
    "\n",
    "    def CalculatePiIqr(self, alpha):\n",
    "        # Calculate prediction interval based on the first and third quartile\n",
    "        q1, q3 = np.quantile(self.data, [0.25, 0.75])\n",
    "        iqr = q3-q1\n",
    "        delta = 0.5 * (norm.ppf(1-alpha/2)/norm.ppf(0.75)-1)\n",
    "\n",
    "        self.pi_iqr = q1 - delta * iqr, q3 + delta * iqr\n",
    "\n",
    "    def CalculatePredictionInterval(self, alpha, hat_mean, hat_median, hat_sigma, dist):\n",
    "        self.CalculatePiMean(alpha, hat_mean, hat_sigma, dist)\n",
    "        self.CalculatePiMedian(alpha, hat_median, hat_sigma)\n",
    "        self.CalculatePiIqr(alpha)\n",
    "\n",
    "        # Return the statistics as a table\n",
    "        labels = ['Mean', 'Median', 'IQR']\n",
    "        self.prediction_intervals = pd.DataFrame(\n",
    "            [self.pi_mean, self.pi_median, self.pi_iqr],\n",
    "            index=labels, columns=[\"Lower\", \"Upper\"]\n",
    "        )\n",
    "\n",
    "    # --- Relative Likelihood ---\n",
    "    def RelativeLogLikelihood(self, mu, sigma):\n",
    "        return self.n * (np.log(self.S0 / sigma) + 0.5 * (1 - (np.mean(self.data**2) - 2 * mu * np.mean(self.data) + mu**2) / sigma**2))\n",
    "\n",
    "    def RelativeLikelihood(self, mu, sigma):\n",
    "        return np.exp(self.RelativeLogLikelihood(mu, sigma))\n",
    "\n",
    "    # --- Graphical Analysis ---\n",
    "    \n",
    "    # --- Plot Histogram ---\n",
    "    def PlotHistogram(self, name_variable, kde, show_data, histo_add_ci, histo_choose_ci, histo_add_pi, histo_choose_pi, add_normal, hat_mu, hat_sigma):\n",
    "        # Style\n",
    "        plt.style.use(\"seaborn-v0_8-whitegrid\")\n",
    "        \n",
    "        show_intervals = histo_add_ci or histo_add_pi\n",
    "\n",
    "        if show_intervals:\n",
    "            fig, (ax1, ax2) = plt.subplots(2, 1, sharex=True, figsize=(8, 6))\n",
    "        else:\n",
    "            fig, ax1 = plt.subplots(1, 1, figsize=(8, 4))\n",
    "            ax2 = None\n",
    "\n",
    "        # Histogram and KDE\n",
    "        sns.histplot(self.data, kde=kde, stat=\"density\", color=\"rebeccapurple\", alpha=0.5, ax=ax1)\n",
    "        ax1.set_ylabel(\"Density\")\n",
    "        ax1.set_xlabel(f\"{name_variable}\")\n",
    "        ax1.set_title(f\"Distribution of {name_variable}\")\n",
    "\n",
    "        if add_normal:\n",
    "            y_vect = np.linspace(hat_mu - 3*hat_sigma, hat_mu + 3*hat_sigma, 100)\n",
    "            ax1.plot(y_vect, norm.pdf(y_vect, hat_mu, hat_sigma), color=\"black\", linestyle=\"--\", label=\"Normal density\")\n",
    "            ax1.legend()\n",
    "\n",
    "        if show_data:\n",
    "            _, upper = ax1.get_ylim()\n",
    "            sns.rugplot(self.data, height=0.1*upper, ax=ax1, color='black')\n",
    "\n",
    "        # Interval annotations (confidence/prediction)\n",
    "        if show_intervals:\n",
    "            ax2.set_yticks([])\n",
    "            ax2.set_xlabel(f\"{name_variable}\")\n",
    "            ax2.set_ylim(0, 0.5)\n",
    "\n",
    "            # Helper to plot a horizontal interval\n",
    "            def plot_interval(ax, y_val, low, high, label, color):\n",
    "                ax.hlines(y_val, low, high, color=color, linewidth=2, label=label)\n",
    "                ax.scatter((low + high)/2, y_val, color=color, s=30, zorder=5)\n",
    "                ax.text(high, y_val, f\" {label}\", va=\"center\", fontsize=9,\n",
    "                        bbox=dict(boxstyle='round,pad=0.2', facecolor='whitesmoke', edgecolor='gray'))\n",
    "\n",
    "            # Confidence Intervals\n",
    "            ci_y = 0.4\n",
    "            if histo_add_ci:\n",
    "                if histo_choose_ci in [\"Mean\", \"Both\"]:\n",
    "                    plot_interval(ax2, ci_y, self.ci_mean[0], self.ci_mean[1], \"CI Mean\", \"blue\")\n",
    "                if histo_choose_ci in [\"Median\", \"Both\"]:\n",
    "                    plot_interval(ax2, ci_y - 0.1, self.ci_median[0], self.ci_median[1], \"CI Median\", \"green\")\n",
    "\n",
    "            # Prediction Intervals\n",
    "            pi_y = 0.1\n",
    "            if histo_add_pi:\n",
    "                if histo_choose_pi == \"Mean\":\n",
    "                    plot_interval(ax2, pi_y, self.pi_mean[0], self.pi_mean[1], \"PI Mean\", \"darkred\")\n",
    "                elif histo_choose_pi == \"Median\":\n",
    "                    plot_interval(ax2, pi_y, self.pi_median[0], self.pi_median[1], \"PI Median\", \"darkred\")\n",
    "                elif histo_choose_pi == \"IQR\":\n",
    "                    plot_interval(ax2, pi_y, self.pi_iqr[0], self.pi_iqr[1], \"PI IQR\", \"darkred\")\n",
    "\n",
    "        return fig\n",
    "    \n",
    "    # --- Plot ECDF ---\n",
    "    def PlotEcdf(self, name_variable, alpha, confidence, add_normal, hat_mu, hat_sigma):\n",
    "\n",
    "        ecdf = ECDF(self.data)\n",
    "        \n",
    "        plt.style.use(\"seaborn-v0_8-whitegrid\")  # Consistent styling\n",
    "        \n",
    "        fig, ax = plt.subplots(figsize=(8, 5))\n",
    "\n",
    "        # ECDF step plot\n",
    "        ax.step(ecdf.x, ecdf.y, where='post', color='rebeccapurple', linewidth=2, label=\"ECDF\")\n",
    "\n",
    "        # Optional: scatter markers (remove if redundant)\n",
    "        ax.scatter(ecdf.x, ecdf.y, color='rebeccapurple', s=10, alpha=0.6)\n",
    "\n",
    "        # Confidence band using DKW inequality\n",
    "        if confidence:\n",
    "            epsilon = np.sqrt(np.log(2 / alpha) / (2 * self.n))\n",
    "            lower = np.clip(ecdf.y - epsilon, 0, 1)\n",
    "            upper = np.clip(ecdf.y + epsilon, 0, 1)\n",
    "            ax.fill_between(ecdf.x, lower, upper, step='post', color='plum', alpha=0.4, label='DKW CI')\n",
    "\n",
    "        # Optional: add normal CDF for comparison\n",
    "        if add_normal:\n",
    "            y_vals = np.linspace(hat_mu - 3 * hat_sigma, hat_mu + 3 * hat_sigma, 100)\n",
    "            ax.plot(y_vals, norm.cdf(y_vals, hat_mu, hat_sigma), color='black', linestyle='--', linewidth=2, label=\"Normal CDF\")\n",
    "            ax.set_xlim(min(self.data.min(), y_vals.min()) - 0.1, max(self.data.max(), y_vals.max()) + 0.1)\n",
    "        else:\n",
    "            ax.set_xlim(self.data.min() - 0.1, self.data.max() + 0.1)\n",
    "\n",
    "        # Axis labels and title\n",
    "        ax.set_title(\"Empirical Cumulative Distribution Function\", fontsize=14)\n",
    "        ax.set_xlabel(f\"{name_variable}\", fontsize=12)\n",
    "        ax.set_ylabel(\"ECDF\", fontsize=12)\n",
    "        ax.set_ylim(0, 1.05)\n",
    "\n",
    "        # Gridlines and legend\n",
    "        ax.grid(True, linestyle='--', alpha=0.5)\n",
    "        ax.legend(loc=\"lower right\", fontsize=10)\n",
    "\n",
    "        return fig\n",
    "\n",
    "    # --- Plot Confidence Regions ---\n",
    "    def PlotConfidenceRegions(self, probs, eps, add):\n",
    "\n",
    "        # Reverse probabilities to get increasing chi2 levels\n",
    "        probs = probs[::-1]\n",
    "        levels = np.exp(-0.5 * chi2.ppf(probs, 2))\n",
    "\n",
    "        # Grids for mu and sigma\n",
    "        mu_vect = np.linspace(self.ci_mean[0] - eps[0], self.ci_mean[1] + eps[0], 200)\n",
    "        sigma_vect = np.linspace(self.ci_deviation[0] - eps[1], self.ci_deviation[1] + eps[1], 200)\n",
    "        mu_grid, sigma_grid = np.meshgrid(mu_vect, sigma_vect)\n",
    "\n",
    "        # Create plot\n",
    "        fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "        # Contour plot of relative likelihood\n",
    "        Z = self.RelativeLikelihood(mu_grid, sigma_grid)\n",
    "        contour = ax.contour(mu_grid, sigma_grid, Z, levels=levels, cmap=\"plasma\")\n",
    "\n",
    "        # Mark the MLE estimate\n",
    "        ax.scatter(self.mean, self.S0, color='black', s=60, label=\"MLE\", zorder=5)\n",
    "\n",
    "        # Optional: add rectangular CI box\n",
    "        if add:\n",
    "            ci_x = [self.ci_mean[0], self.ci_mean[1], self.ci_mean[1], self.ci_mean[0], self.ci_mean[0]]\n",
    "            ci_y = [self.ci_deviation[0], self.ci_deviation[0], self.ci_deviation[1], self.ci_deviation[1], self.ci_deviation[0]]\n",
    "            ax.plot(ci_x, ci_y, color='red', linestyle='--', label=\"CI box\")\n",
    "\n",
    "        # Axis and title\n",
    "        ax.set_title(r\"Confidence Regions for $\\mu$ and $\\sigma$\", fontsize=14)\n",
    "        ax.set_xlabel(r\"$\\mu$\", fontsize=12)\n",
    "        ax.set_ylabel(r\"$\\sigma$\", fontsize=12)\n",
    "        ax.grid(True, linestyle='--', alpha=0.6)\n",
    "\n",
    "        # Format legend from contour handles\n",
    "        handles, _ = contour.legend_elements()\n",
    "        formatted_probs = [f\"{100*p:.1f}%\" for p in probs]\n",
    "        ax.legend(handles + [ax.collections[-1]], formatted_probs + [\"MLE\"], loc=\"upper right\", frameon=True)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        return fig\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee47afaa",
   "metadata": {},
   "source": [
    "# üß† üåè General functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "38b1fdbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_table_as_csv(filename):\n",
    "    df = export_cache.get(\"table\")\n",
    "    if df is None:\n",
    "        return \"‚ùå Error: No table available to save.\"\n",
    "    \n",
    "    if not filename.strip():\n",
    "        return \"‚ùå Error: Filename is empty.\"\n",
    "\n",
    "    try:\n",
    "        filepath = os.path.abspath(f\"{filename.strip()}.csv\")\n",
    "        df.to_csv(filepath, index=False)\n",
    "        return \"‚úÖ Table saved successfully.\"\n",
    "    except Exception as e:\n",
    "        return f\"‚ùå Error: {e}\"\n",
    "    \n",
    "def save_figure_as_image(filename):\n",
    "    fig = export_cache.get(\"figure\")\n",
    "    if fig is None:\n",
    "        return \"‚ùå Error: No figure available to save.\"\n",
    "    \n",
    "    if not filename.strip():\n",
    "        return \"‚ùå Error: Filename is empty.\"\n",
    "\n",
    "    try:\n",
    "        filepath = os.path.abspath(f\"{filename.strip()}.png\")\n",
    "        fig.savefig(filepath, bbox_inches='tight')\n",
    "        return \"‚úÖ Image saved successfully.\"\n",
    "    except Exception as e:\n",
    "        return f\"‚ùå Error: {e}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0cecaeaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def blank_plot():\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.axis('off')\n",
    "    return fig\n",
    "\n",
    "def load_numeric_cols():\n",
    "    numeric_cols = df_cache.get(\"numeric_cols\", [])\n",
    "    selected = numeric_cols[0] if numeric_cols else None\n",
    "    return gr.update(choices=numeric_cols, value=selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2650afd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(column):\n",
    "    # --- Read data and validate ---\n",
    "    original_df = df_cache.get(\"df\")\n",
    "    filtered_df = df_cache.get(\"filtered_df\")\n",
    "\n",
    "    if original_df is None:\n",
    "        return None, None, None, pd.DataFrame([[\"Please upload a valid CSV.\"]], columns=[\"Error\"]), blank_plot()\n",
    "\n",
    "    # --- Use filtered data if it differs from original ---\n",
    "    df = filtered_df if filtered_df is not None and not filtered_df.equals(original_df) else original_df\n",
    "\n",
    "    # --- Select numeric column ---\n",
    "    if column not in df.columns:\n",
    "        return None, None, None, pd.DataFrame([[\"Selected column is not in the dataframe.\"]], columns=[\"Error\"]), blank_plot()\n",
    "\n",
    "    data = df[column].dropna()\n",
    "\n",
    "    # --- Initialize or reuse Statistics object ---\n",
    "    stats = df_cache.get(\"stats\")\n",
    "    if stats is None or not np.array_equal(stats.data, data.to_numpy()):\n",
    "        stats = Statistics(data)\n",
    "        df_cache[\"stats\"] = stats\n",
    "\n",
    "    return df, data, stats, None, None  # df, data, stats, error_df, error_plot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ddb3dd11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_mu(sel, stats, text_box):\n",
    "    if sel == \"Sample Mean\":\n",
    "        hat_mu = stats.mean\n",
    "    elif sel == \"Sample Median\":\n",
    "        hat_mu = stats.median\n",
    "    elif sel == \"Geometric Mean\":\n",
    "        hat_mu = stats.geometric_mean\n",
    "    elif sel == \"Harmonic Mean\":\n",
    "        hat_mu = stats.harmonic_mean\n",
    "    elif sel == \"Weighted Mean\":\n",
    "        hat_mu = stats.weighted_mean\n",
    "    elif sel == \"Trimmed Mean\":\n",
    "        hat_mu = stats.trimmed_mean\n",
    "    elif sel == \"Interquartile Mean\":\n",
    "        hat_mu = stats.interquartile_mean\n",
    "    elif sel == \"Winsorized Mean\":\n",
    "        hat_mu = stats.winsorized_mean\n",
    "    elif sel == \"Other\":\n",
    "        hat_mu = float(text_box)\n",
    "        \n",
    "    return hat_mu\n",
    "\n",
    "def choose_sigma(sel, stats, text_box):\n",
    "    if sel == \"Deviation (1 ddof)\":\n",
    "        hat_sigma = stats.S1\n",
    "    elif sel == \"Range (bias corrected)\":\n",
    "        hat_sigma = stats.R_bias_corrected\n",
    "    elif sel == \"IQR (bias corrected)\":\n",
    "        hat_sigma = stats.IQR_bias_corrected\n",
    "    elif sel == \"MAD (bias corrected)\":\n",
    "        hat_sigma = stats.MAD_bias_corrected\n",
    "    elif sel == \"AAD (bias corrected)\":\n",
    "        hat_sigma = stats.AAD_bias_corrected\n",
    "    elif sel == \"Other\":\n",
    "        hat_sigma = float(text_box)\n",
    "\n",
    "    return hat_sigma"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d2a1850",
   "metadata": {},
   "source": [
    "# üéÆ üåè General logic of GUI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d55dae87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_normal_warning(check):\n",
    "    if check:\n",
    "        gr.Warning(\"If you haven't done it yet, run first a descriptive analysis for central tendency and dispersion.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ae82e1b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_text(input_str):   \n",
    "        return float(input_str) if input_str.strip() else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c9978559",
   "metadata": {},
   "outputs": [],
   "source": [
    "def toggle_add_normal(check, sel_mu, sel_sigma):\n",
    "    if check:\n",
    "        if sel_mu == \"Other\":\n",
    "            if sel_sigma == \"Other\":\n",
    "                return [\n",
    "                    gr.update(visible=True), # hat_mu\n",
    "                    gr.update(visible=True), # hat_mu_text\n",
    "                    gr.update(visible=True), # hat_sigma\n",
    "                    gr.update(visible=True)  # hat_sigma_text\n",
    "                ]\n",
    "            else:\n",
    "                return (\n",
    "                    gr.update(visible=True),\n",
    "                    gr.update(visible=True),\n",
    "                    gr.update(visible=True),\n",
    "                    gr.update(visible=False)\n",
    "                )\n",
    "        else:\n",
    "            if sel_sigma == \"Other\":\n",
    "                return (\n",
    "                    gr.update(visible=True), \n",
    "                    gr.update(visible=False), \n",
    "                    gr.update(visible=True), \n",
    "                    gr.update(visible=True)\n",
    "                )\n",
    "            else:\n",
    "                return (\n",
    "                    gr.update(visible=True),\n",
    "                    gr.update(visible=False),\n",
    "                    gr.update(visible=True),\n",
    "                    gr.update(visible=False)\n",
    "                )\n",
    "    else:\n",
    "        return (\n",
    "            gr.update(visible=False),\n",
    "            gr.update(visible=False),\n",
    "            gr.update(visible=False),\n",
    "            gr.update(visible=False)\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e41649d",
   "metadata": {},
   "source": [
    "# üñ•Ô∏è üåè  General GUI blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "763c76fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_results_block(table_view, plot_view):\n",
    "    with gr.Group() as results_block:         \n",
    "        gr.Markdown(\"# üéØ Results\")\n",
    "\n",
    "        with gr.Group(visible=table_view) as output_table_group:\n",
    "            with gr.Row(elem_id=\"row_centered\"):\n",
    "                save_table_button = gr.Button(\"üíæ Save Table as CSV\")\n",
    "                name_save_table = gr.Textbox(label=\"Filename (without extension)\", placeholder=\"e.g. descriptive_stats\")\n",
    "                table_save_status = gr.Textbox(label=\"Table Save Status\", interactive=False)\n",
    "\n",
    "            output_table = gr.Dataframe()\n",
    "\n",
    "        with gr.Group(visible=plot_view) as output_plot_group:\n",
    "            with gr.Row(elem_id=\"row_centered\"):\n",
    "                save_figure_button = gr.Button(\"üñºÔ∏è Save Figure as PNG\")\n",
    "                name_save_figure = gr.Textbox(label=\"Filename (without extension)\", placeholder=\"e.g. histogram\")\n",
    "                img_save_status = gr.Textbox(label=\"Image Save Status\", interactive=False)\n",
    "\n",
    "            output_plot = gr.Plot()\n",
    "\n",
    "        save_table_button.click(\n",
    "            fn=save_table_as_csv,\n",
    "            inputs=[name_save_table],\n",
    "            outputs=[table_save_status]\n",
    "        )\n",
    "\n",
    "        save_figure_button.click(\n",
    "            fn=save_figure_as_image,\n",
    "            inputs=[name_save_figure],\n",
    "            outputs=[img_save_status]\n",
    "        )\n",
    "\n",
    "    return output_table_group, output_table, output_plot_group, output_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d98c8d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_results_block_2(html_view, plot_view):\n",
    "    with gr.Group() as results_block:         \n",
    "        gr.Markdown(\"# üéØ Results\")\n",
    "\n",
    "        with gr.Group(visible=html_view) as output_table_group:\n",
    "            with gr.Row(elem_id=\"row_centered\"):\n",
    "                save_table_button = gr.Button(\"üíæ Save Coefficient Table as CSV\")\n",
    "                name_save_table = gr.Textbox(label=\"Filename (without extension)\", placeholder=\"e.g. descriptive_stats\")\n",
    "                table_save_status = gr.Textbox(label=\"Table Save Status\", interactive=False)\n",
    "\n",
    "            output_table = gr.HTML()\n",
    "\n",
    "        with gr.Group(visible=plot_view) as output_plot_group:\n",
    "            with gr.Row(elem_id=\"row_centered\"):\n",
    "                save_figure_button = gr.Button(\"üñºÔ∏è Save Figure as PNG\")\n",
    "                name_save_figure = gr.Textbox(label=\"Filename (without extension)\", placeholder=\"e.g. histogram\")\n",
    "                img_save_status = gr.Textbox(label=\"Image Save Status\", interactive=False)\n",
    "\n",
    "            output_plot = gr.Plot()\n",
    "\n",
    "        save_table_button.click(\n",
    "            fn=save_table_as_csv,\n",
    "            inputs=[name_save_table],\n",
    "            outputs=[table_save_status]\n",
    "        )\n",
    "\n",
    "        save_figure_button.click(\n",
    "            fn=save_figure_as_image,\n",
    "            inputs=[name_save_figure],\n",
    "            outputs=[img_save_status]\n",
    "        )\n",
    "\n",
    "    return output_table_group, output_table, output_plot_group, output_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3b8f8cd",
   "metadata": {},
   "source": [
    "# üß† üóÑÔ∏è Brain of Data Tab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4d9ad4be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_effective_column_types(df):\n",
    "    all_numeric = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    all_categorical = df.select_dtypes(exclude=[np.number]).columns.tolist()\n",
    "    overrides = df_cache.get(\"overrides\", {\"num_to_cat\": [], \"cat_to_num\": []})\n",
    "\n",
    "    numeric = [col for col in all_numeric if col not in overrides[\"num_to_cat\"]]\n",
    "    categorical = [col for col in all_categorical if col not in overrides[\"cat_to_num\"]]\n",
    "\n",
    "    numeric += [col for col in overrides[\"cat_to_num\"] if col in df.columns]\n",
    "    categorical += [col for col in overrides[\"num_to_cat\"] if col in df.columns]\n",
    "\n",
    "    return sorted(set(numeric)), sorted(set(categorical))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5d21ea60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_csv(file):\n",
    "    try:\n",
    "        df = pd.read_csv(file.name)\n",
    "\n",
    "        if df.empty:\n",
    "            raise ValueError(\"The uploaded CSV file is empty.\")\n",
    "\n",
    "        df_cache[\"df\"] = df\n",
    "        df_cache[\"filtered_df\"] = df\n",
    "        df_cache[\"stats\"] = None\n",
    "\n",
    "        numeric_cols, categorical_cols = get_effective_column_types(df)\n",
    "\n",
    "        df_cache[\"numeric_cols\"] = numeric_cols\n",
    "        df_cache[\"categorical_cols\"] = categorical_cols\n",
    "\n",
    "        return (\n",
    "            gr.update(choices=categorical_cols, value=[]),            # cat_col_dropdown\n",
    "            gr.update(choices=numeric_cols, value=None),              # num_override_dropdown\n",
    "            gr.update(choices=categorical_cols, value=None),          # cat_override_dropdown\n",
    "            gr.update(choices=[], value=[], visible=False),           # cat_val_multiselect_1\n",
    "            gr.update(choices=[], value=[], visible=False),           # cat_val_multiselect_2\n",
    "            gr.update(choices=[], value=[], visible=False),           # cat_val_multiselect_3\n",
    "            \"CSV loaded successfully.\"                                # status_output (Textbox!)\n",
    "        )\n",
    "    except Exception as e:\n",
    "        return tuple([gr.update(choices=[], value=None)] * 7 + [f\"Error: {e}\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d23791cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_data_overview():\n",
    "    original_df = df_cache.get(\"df\")\n",
    "    filtered_df = df_cache.get(\"filtered_df\")\n",
    "\n",
    "    if original_df is None:\n",
    "        error_df = pd.DataFrame([[\"Please upload a valid CSV.\"]], columns=[\"Error\"])\n",
    "        return error_df, error_df\n",
    "\n",
    "    # --- Use filtered data if it differs from original ---\n",
    "    df = filtered_df if filtered_df is not None and not filtered_df.equals(original_df) else original_df\n",
    "\n",
    "    # --- Compute description and data types ---\n",
    "    try:\n",
    "        desc = df.describe().T.round(ROUND).reset_index().rename(columns={\"index\": \"Variable\"})\n",
    "    except Exception as e:\n",
    "        desc = pd.DataFrame([[str(e)]], columns=[\"Error\"])\n",
    "\n",
    "    try:\n",
    "        dtypes_df = pd.DataFrame(df.dtypes).reset_index().rename(columns={\"index\": \"Variable\", 0: \"Type\"})\n",
    "    except Exception as e:\n",
    "        dtypes_df = pd.DataFrame([[str(e)]], columns=[\"Error\"])\n",
    "\n",
    "    return desc, dtypes_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c2384f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reclassify_as_categorical(column):\n",
    "    numeric_cols = df_cache.get(\"numeric_cols\", [])\n",
    "    categorical_cols = df_cache.get(\"categorical_cols\", [])\n",
    "\n",
    "    if column and column in numeric_cols:\n",
    "        numeric_cols.remove(column)\n",
    "        categorical_cols.append(column)\n",
    "        df_cache[\"numeric_cols\"] = numeric_cols\n",
    "        df_cache[\"categorical_cols\"] = categorical_cols\n",
    "\n",
    "        return (\n",
    "            gr.update(choices=categorical_cols),                      # cat_col_dropdown\n",
    "            gr.update(choices=numeric_cols),                          # num_override_dropdown\n",
    "            gr.update(choices=categorical_cols),                      # cat_override_dropdown\n",
    "            f\"Column '{column}' reclassified as categorical.\"         # status\n",
    "        )\n",
    "    else:\n",
    "        return (\n",
    "            gr.update(), gr.update(), gr.update(), gr.update(),\n",
    "            f\"Column '{column}' is not currently classified as numeric.\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4d2c1bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reclassify_as_numeric(column):\n",
    "    numeric_cols = df_cache.get(\"numeric_cols\", [])\n",
    "    categorical_cols = df_cache.get(\"categorical_cols\", [])\n",
    "\n",
    "    if column and column in categorical_cols:\n",
    "        categorical_cols.remove(column)\n",
    "        numeric_cols.append(column)\n",
    "        df_cache[\"categorical_cols\"] = categorical_cols\n",
    "        df_cache[\"numeric_cols\"] = numeric_cols\n",
    "\n",
    "        return (\n",
    "            gr.update(choices=categorical_cols),                      # cat_col_dropdown\n",
    "            gr.update(choices=numeric_cols),                          # num_override_dropdown\n",
    "            gr.update(choices=categorical_cols),                      # cat_override_dropdown\n",
    "            f\"Column '{column}' reclassified as numeric.\"             # status\n",
    "        )\n",
    "    else:\n",
    "        return (\n",
    "            gr.update(), gr.update(), gr.update(), gr.update(),\n",
    "            f\"Column '{column}' is not currently classified as categorical.\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "03c84847",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only 3 category filters are supported.\n",
    "def update_category_filters(selected_columns):\n",
    "    original_df = df_cache.get(\"df\")\n",
    "    filtered_df = df_cache.get(\"filtered_df\")\n",
    "\n",
    "    # --- Use filtered data if it differs from original ---\n",
    "    df = filtered_df if filtered_df is not None and not filtered_df.equals(original_df) else original_df\n",
    "\n",
    "    if df is None or not selected_columns:\n",
    "        # Hide all category selectors if nothing is selected\n",
    "        return [gr.update(visible=False, choices=[], value=[]) for _ in range(3)]\n",
    "\n",
    "    updates = []\n",
    "    for i in range(3):\n",
    "        if i < len(selected_columns):\n",
    "            col = selected_columns[i]\n",
    "            if col in df.columns:\n",
    "                values = sorted(df[col].dropna().unique().tolist())\n",
    "                updates.append(gr.update(visible=True, choices=values, value=[]))\n",
    "            else:\n",
    "                updates.append(gr.update(visible=False, choices=[], value=[]))\n",
    "        else:\n",
    "            updates.append(gr.update(visible=False, choices=[], value=[]))\n",
    "\n",
    "    return updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "50a3647f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_filters(cat_cols, val1, val2, val3):\n",
    "    df = df_cache.get(\"df\")\n",
    "    if df is None:\n",
    "        return \"‚ùå No data loaded.\"\n",
    "\n",
    "    filtered_df = df.copy()\n",
    "    category_filters = [val1, val2, val3]\n",
    "\n",
    "    if not cat_cols or all(not vals for vals in category_filters):\n",
    "        # No filters applied\n",
    "        df_cache[\"filtered_df\"] = df\n",
    "        return \"‚ö†Ô∏è No filters selected. Using full dataset.\"\n",
    "\n",
    "    for i, col in enumerate(cat_cols[:3]):\n",
    "        selected_vals = category_filters[i]\n",
    "        if selected_vals:\n",
    "            filtered_df = filtered_df[filtered_df[col].isin(selected_vals)]\n",
    "\n",
    "    df_cache[\"filtered_df\"] = filtered_df\n",
    "    return f\"‚úÖ Filter applied. Rows remaining: {len(filtered_df)}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4a4e433",
   "metadata": {},
   "source": [
    "# üéÆüóÑÔ∏è Logic control of Data Tab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "582ab70e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_categorical_warning(check):\n",
    "    if check:\n",
    "        gr.Info(\"The maximum number of categorical columns for filter is 3.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d48d6db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def toggle_preview(check):\n",
    "    df = df_cache.get(\"df\")\n",
    "    if check:\n",
    "        return df.head(5), gr.update(visible=True)\n",
    "    else:\n",
    "        return pd.DataFrame(), gr.update(visible=False) # csv_preview, csv_preview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efaf923a",
   "metadata": {},
   "source": [
    "# üñ•Ô∏è üóÑÔ∏è GUI of Data Tab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "216a8e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_data_tab():\n",
    "    with gr.Group():\n",
    "        gr.Markdown(\"# üìÅ File Explorer\")\n",
    "        \n",
    "        with gr.Row():\n",
    "            file_input = gr.File(file_types=[\".csv\"], label=\"Upload CSV\")\n",
    "            status_output = gr.Textbox(label=\"Status\", interactive=False)\n",
    "            preview_checkbox = gr.Checkbox(label=\"Show CSV Preview\", value=False)\n",
    "            \n",
    "        csv_preview = gr.Dataframe(label=\"CSV Preview\", visible=False)\n",
    "\n",
    "    with gr.Group():\n",
    "        gr.Markdown(\"# üßæ Dataset Summary\")\n",
    "        with gr.Accordion(open=False):\n",
    "\n",
    "            overview_button = gr.Button(\"üîç Show Data Overview\")\n",
    "\n",
    "            desc_output = gr.Dataframe(label=\"Descriptive Summary\", visible=False)\n",
    "            dtypes_output = gr.Dataframe(label=\"Variable Types\", visible=False)\n",
    "\n",
    "    with gr.Group():\n",
    "        gr.Markdown(\"# üõ†Ô∏è Fix Variable Type\")\n",
    "        with gr.Accordion(open=False):\n",
    "            with gr.Row(elem_id=\"row_centered\"):\n",
    "                # Reclassify numeric ‚ûù categorical\n",
    "                num_override_dropdown = gr.Dropdown(label=\"Reclassify Numeric Column as Categorical\", elem_classes=\"data_related\", elem_id=\"custom_dropdown\")\n",
    "                fix_to_categorical_button = gr.Button(\"Reclassify as Categorical\")\n",
    "\n",
    "                # Reclassify categorical ‚ûù numeric\n",
    "                cat_override_dropdown = gr.Dropdown(label=\"Reclassify Categorical Column as Numeric\", elem_classes=\"data_related\", elem_id=\"custom_dropdown\")\n",
    "                fix_to_numeric_button = gr.Button(\"Reclassify as Numeric\")\n",
    "\n",
    "                fix_dtype_status = gr.Textbox(label=\"Status\", interactive=False)        \n",
    "\n",
    "    with gr.Group():\n",
    "        gr.Markdown(\"# ‚ûñ Filter Data\") \n",
    "        with gr.Accordion(open=False):       \n",
    "            with gr.Row():\n",
    "                cat_col_dropdown = gr.Dropdown(label=\"Select Categorical Columns for Filter\", multiselect=True, max_choices=3, elem_classes=\"data_related\", elem_id=\"custom_dropdown\")\n",
    "                cat_val_multiselect_1 = gr.Dropdown(label=\"Categories for Filter 1\", multiselect=True, visible=False, interactive=True, elem_classes=\"data_related\", elem_id=\"custom_dropdown\")\n",
    "                cat_val_multiselect_2 = gr.Dropdown(label=\"Categories for Filter 2\", multiselect=True, visible=False, interactive=True, elem_classes=\"data_related\", elem_id=\"custom_dropdown\")\n",
    "                cat_val_multiselect_3 = gr.Dropdown(label=\"Categories for Filter 3\", multiselect=True, visible=False, interactive=True, elem_classes=\"data_related\", elem_id=\"custom_dropdown\")\n",
    "    \n",
    "            with gr.Row(elem_id=\"row_centered\"):\n",
    "                apply_filter_button = gr.Button(\"üöÄ Apply Filter\")\n",
    "                filter_status = gr.Textbox(label=\"Filter Status\", interactive=False)\n",
    "\n",
    "    # --- Modify behavior of components of the GUI ---\n",
    "    file_input.change(\n",
    "        fn=load_csv,\n",
    "        inputs=[file_input],\n",
    "        outputs=[\n",
    "            cat_col_dropdown,\n",
    "            num_override_dropdown,\n",
    "            cat_override_dropdown,\n",
    "            cat_val_multiselect_1,\n",
    "            cat_val_multiselect_2,\n",
    "            cat_val_multiselect_3,\n",
    "            status_output\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    preview_checkbox.change(\n",
    "        fn=toggle_preview,\n",
    "        inputs=preview_checkbox,\n",
    "        outputs=[csv_preview, csv_preview]\n",
    "    )\n",
    "\n",
    "    overview_button.click(\n",
    "        fn=show_data_overview,\n",
    "        inputs=[],\n",
    "        outputs=[desc_output, dtypes_output]\n",
    "    )\n",
    "\n",
    "    overview_button.click(\n",
    "        fn=lambda check: 2*[gr.update(visible=check)],\n",
    "        inputs=[overview_button],\n",
    "        outputs=[desc_output, dtypes_output]\n",
    "    )\n",
    "\n",
    "    fix_to_categorical_button.click(\n",
    "        fn=reclassify_as_categorical,\n",
    "        inputs=[num_override_dropdown],\n",
    "        outputs=[\n",
    "            cat_col_dropdown,\n",
    "            num_override_dropdown,\n",
    "            cat_override_dropdown,\n",
    "            fix_dtype_status\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    fix_to_numeric_button.click(\n",
    "        fn=reclassify_as_numeric,\n",
    "        inputs=[cat_override_dropdown],\n",
    "        outputs=[\n",
    "            cat_col_dropdown,\n",
    "            num_override_dropdown,\n",
    "            cat_override_dropdown,\n",
    "            fix_dtype_status\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    cat_col_dropdown.change(\n",
    "        fn=max_categorical_warning,\n",
    "        inputs=cat_col_dropdown,\n",
    "        outputs=[]\n",
    "    )\n",
    "\n",
    "    cat_col_dropdown.change(\n",
    "        fn=update_category_filters,\n",
    "        inputs=cat_col_dropdown,\n",
    "        outputs=[cat_val_multiselect_1, cat_val_multiselect_2, cat_val_multiselect_3]\n",
    "    )\n",
    "\n",
    "    apply_filter_button.click(\n",
    "        fn=apply_filters,\n",
    "        inputs=[\n",
    "            cat_col_dropdown,\n",
    "            cat_val_multiselect_1,\n",
    "            cat_val_multiselect_2,\n",
    "            cat_val_multiselect_3\n",
    "        ],\n",
    "        outputs=[filter_status]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "902a9052",
   "metadata": {},
   "source": [
    "# üéÆ üìä Logic control of Graph Tab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a9821215",
   "metadata": {},
   "outputs": [],
   "source": [
    "def histo_add_ci_warning(check):\n",
    "    if check:\n",
    "        gr.Warning(\"If you haven't done it yet, run first a statistical inference for confidence interval.\")\n",
    "\n",
    "def histo_add_pi_warning(check):\n",
    "    if check:\n",
    "        gr.Warning(\"If you haven't done it yet, run first a statistical inference for prediction interval.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "57436c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def toggle_graph_stat(graph_stat, histo_add_normal, histo_add_ci, histo_add_pi, ecdf_add_normal):\n",
    "    if graph_stat == \"Histogram\":\n",
    "        return (\n",
    "            gr.update(visible=True), # histo_add_kde\n",
    "            gr.update(visible=True), # histo_add_data\n",
    "            gr.update(visible=True, value=histo_add_normal), # histo_add_normal\n",
    "            gr.update(visible=True, value=histo_add_ci), # histo_add_ci\n",
    "            gr.update(visible=True, value=histo_add_pi), # histo_add_pi\n",
    "            gr.update(visible=False, value=False), # ecdf_add_normal\n",
    "            gr.update(visible=False), # ecdf_add_conf\n",
    "            gr.update(visible=False), # ecdf_alpha\n",
    "        )\n",
    "    elif graph_stat == \"Empirical Cumulative Distribution Function (ECDF)\":\n",
    "        return ( \n",
    "            gr.update(visible=False), \n",
    "            gr.update(visible=False),\n",
    "            gr.update(visible=False, value=False),\n",
    "            gr.update(visible=False, value=False),\n",
    "            gr.update(visible=False, value=False),\n",
    "            gr.update(visible=True, value=ecdf_add_normal),\n",
    "            gr.update(visible=True),\n",
    "            gr.update(visible=True),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6b68ef61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_graph_stat(\n",
    "        column,\n",
    "        graph_stat,\n",
    "        histo_add_kde_check, histo_add_data_check,\n",
    "        histo_add_ci, histo_choose_ci,\n",
    "        histo_add_pi, histo_choose_pi,\n",
    "        histo_add_normal,\n",
    "        histo_hat_mu, histo_hat_mu_text,\n",
    "        histo_hat_sigma, histo_hat_sigma_text,\n",
    "        ecdf_add_conf,\n",
    "        ecdf_alpha,\n",
    "        ecdf_add_normal,\n",
    "        ecdf_hat_mu, ecdf_hat_mu_text,\n",
    "        ecdf_hat_sigma, ecdf_hat_sigma_text\n",
    "        ):\n",
    "    \n",
    "    df, data, stats, error_df, error_plot = prepare_data(column)\n",
    "    if error_df:\n",
    "        return gr.update(visible=True), error_df, gr.update(visible=False), error_plot\n",
    "\n",
    "    # --- Graphical Analysis ---\n",
    "    if graph_stat == \"Histogram\":\n",
    "        hat_mu, hat_sigma = None, None\n",
    "\n",
    "        if histo_add_normal:\n",
    "            hat_mu = choose_mu(histo_hat_mu, stats, histo_hat_mu_text)\n",
    "            hat_sigma = choose_sigma(histo_hat_sigma, stats, histo_hat_sigma_text)\n",
    "\n",
    "        fig = stats.PlotHistogram(\n",
    "            column,\n",
    "            histo_add_kde_check,\n",
    "            histo_add_data_check,\n",
    "            histo_add_ci, histo_choose_ci,\n",
    "            histo_add_pi, histo_choose_pi,\n",
    "            histo_add_normal,\n",
    "            hat_mu,\n",
    "            hat_sigma\n",
    "        )\n",
    "        \n",
    "    elif graph_stat == \"Empirical Cumulative Distribution Function (ECDF)\":\n",
    "\n",
    "        alpha = parse_text(ecdf_alpha)\n",
    "        alpha = 1 -alpha\n",
    "        if alpha is None or not (0 < alpha < 1):\n",
    "            return pd.DataFrame([[\"Invalid alpha value.\"]], columns=[\"Error\"])\n",
    "\n",
    "        hat_mu, hat_sigma = None, None\n",
    "\n",
    "        if ecdf_add_normal:\n",
    "            hat_mu = choose_mu(ecdf_hat_mu, stats, ecdf_hat_mu_text)\n",
    "            hat_sigma = choose_sigma(ecdf_hat_sigma, stats, ecdf_hat_sigma_text)\n",
    "\n",
    "        fig = stats.PlotEcdf(\n",
    "            column,\n",
    "            alpha,\n",
    "            ecdf_add_conf,\n",
    "            ecdf_add_normal,\n",
    "            hat_mu,\n",
    "            hat_sigma\n",
    "        )\n",
    "    \n",
    "    #export_cache[\"table\"] = None\n",
    "    export_cache[\"figure\"] = fig\n",
    "\n",
    "    # output_table_group, output_table, output_plot_group, output_plot\n",
    "    return gr.update(visible=False), pd.DataFrame(), gr.update(visible=True), fig "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c28f4d67",
   "metadata": {},
   "source": [
    "# üñ•Ô∏è üìä GUI of Graph Tab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "38f51fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_graphical_tab():\n",
    "    with gr.Group():\n",
    "        gr.Markdown(\"# üìä Graphical Analysis\")\n",
    "        with gr.Row(elem_id=\"row_centered\"):\n",
    "            refresh_columns_button = gr.Button(\"üîÑ Refresh Numeric Columns\")\n",
    "            column_dropdown = gr.Dropdown(label=\"Select Numeric Column\", choices=[], interactive=True, elem_classes=\"data_related\", elem_id=\"custom_dropdown\")\n",
    "\n",
    "            graph_stat_dropdown = gr.Dropdown(\n",
    "                label=\"Select Graph\",\n",
    "                choices=[\n",
    "                    \"Histogram\",\n",
    "                    \"Empirical Cumulative Distribution Function (ECDF)\"\n",
    "                ],\n",
    "                value=\"Histogram\",\n",
    "                interactive=True\n",
    "            )\n",
    "\n",
    "            histo_add_kde = gr.Checkbox(label=\"Add KDE\", value=True, visible=True, interactive=True)\n",
    "            histo_add_data = gr.Checkbox(label=\"Show data\", value=False, visible=True, interactive=True)\n",
    "\n",
    "            ecdf_add_conf = gr.Checkbox(label=\"Add CI for the ECDF\", value=True, visible=False, interactive=True)\n",
    "            ecdf_alpha = gr.Textbox(label=\"Confidence level (e.g. 0.95)\", value=0.95, interactive=True, visible=False)\n",
    "\n",
    "        with gr.Row():\n",
    "            histo_add_normal = gr.Checkbox(label=\"Add Normal Density\", value=False)\n",
    "\n",
    "            histo_hat_mu = gr.Dropdown(\n",
    "                label=\"Œº\",\n",
    "                choices=[\n",
    "                    'Sample Mean',\n",
    "                    'Sample Median',\n",
    "                    'Geometric Mean',\n",
    "                    'Harmonic Mean',\n",
    "                    'Weighted Mean',\n",
    "                    'Trimmed Mean',\n",
    "                    'Interquartile Mean',\n",
    "                    'Winsorized Mean',\n",
    "                    \"Other\"\n",
    "                ],\n",
    "                value=\"Sample Mean\",\n",
    "                interactive=True,\n",
    "                visible=False\n",
    "            )\n",
    "            histo_hat_mu_text = gr.Textbox(label=\"Write the value of a consistent estimator\", visible=False)\n",
    "\n",
    "            histo_hat_sigma = gr.Dropdown(\n",
    "                label=\"œÉ\",\n",
    "                choices=[\n",
    "                    \"Deviation (1 ddof)\",\n",
    "                    \"Range (bias corrected)\",\n",
    "                    \"IQR (bias corrected)\",\n",
    "                    \"MAD (bias corrected)\",\n",
    "                    \"AAD (bias corrected)\",\n",
    "                    \"Other\"\n",
    "                ],\n",
    "                value=\"Deviation (1 ddof)\",\n",
    "                interactive=True,\n",
    "                visible=False\n",
    "            )\n",
    "            histo_hat_sigma_text = gr.Textbox(label=\"Write the value of a consistent estimator\", visible=False)\n",
    "\n",
    "        with gr.Row():\n",
    "            histo_add_ci = gr.Checkbox(label=\"Add Confidence Interval\", value=False)\n",
    "\n",
    "            histo_choose_ci = gr.Radio(\n",
    "                label=\"Confidence Interval\",\n",
    "                choices=[\"Mean\", \"Median\", \"Both\"],\n",
    "                value=\"Mean\",\n",
    "                interactive=True,\n",
    "                visible=False\n",
    "            )\n",
    "\n",
    "        with gr.Row():                \n",
    "            histo_add_pi = gr.Checkbox(label=\"Add Prediction Interval\", value=False)\n",
    "            histo_choose_pi = gr.Radio(\n",
    "                label=\"Prediction Interval\",\n",
    "                choices=[\"Mean\", \"Median\", \"IQR\"],\n",
    "                value=\"Mean\",\n",
    "                interactive=True,\n",
    "                visible=False\n",
    "            )\n",
    "\n",
    "        with gr.Row():\n",
    "            ecdf_add_normal = gr.Checkbox(label=\"Add Normal CDF\", value=False, visible=False)\n",
    "\n",
    "            ecdf_hat_mu = gr.Dropdown(\n",
    "                label=\"Œº\",\n",
    "                choices=[\n",
    "                    'Sample Mean',\n",
    "                    'Sample Median',\n",
    "                    'Geometric Mean',\n",
    "                    'Harmonic Mean',\n",
    "                    'Weighted Mean',\n",
    "                    'Trimmed Mean',\n",
    "                    'Interquartile Mean',\n",
    "                    'Winsorized Mean',\n",
    "                    \"Other\"\n",
    "                ],\n",
    "                value=\"Sample Mean\",\n",
    "                interactive=True,\n",
    "                visible=False\n",
    "            )\n",
    "            ecdf_hat_mu_text = gr.Textbox(label=\"Write the value of a consistent estimator\", visible=False)\n",
    "\n",
    "            ecdf_hat_sigma = gr.Dropdown(\n",
    "                label=\"œÉ\",\n",
    "                choices=[\n",
    "                    \"Deviation (1 ddof)\",\n",
    "                    \"Range (bias corrected)\",\n",
    "                    \"IQR (bias corrected)\",\n",
    "                    \"MAD (bias corrected)\",\n",
    "                    \"AAD (bias corrected)\",\n",
    "                    \"Other\"\n",
    "                ],\n",
    "                value=\"Deviation (1 ddof)\",\n",
    "                interactive=True,\n",
    "                visible=False\n",
    "            )\n",
    "            ecdf_hat_sigma_text = gr.Textbox(label=\"Write the value of a consistent estimator\", visible=False)\n",
    "\n",
    "        run_graph_stat_button = gr.Button(value=\" üöÄ Run Graphical Analysis\")\n",
    "\n",
    "    # --- Results ---\n",
    "    output_table_group, output_table, output_plot_group, output_plot = build_results_block(False, False)\n",
    "\n",
    "    # --- Modify behavior of components of the GUI ---\n",
    "    refresh_columns_button.click(\n",
    "        fn=load_numeric_cols,\n",
    "        inputs=[],\n",
    "        outputs=[column_dropdown]\n",
    "    )\n",
    "\n",
    "    graph_stat_dropdown.change(\n",
    "        fn=toggle_graph_stat,\n",
    "        inputs=[graph_stat_dropdown, histo_add_normal, histo_add_ci, histo_add_pi, ecdf_add_normal],\n",
    "        outputs=[\n",
    "            histo_add_kde,\n",
    "            histo_add_data,\n",
    "            histo_add_normal,\n",
    "            histo_add_ci,\n",
    "            histo_add_pi,\n",
    "            ecdf_add_normal,\n",
    "            ecdf_add_conf,\n",
    "            ecdf_alpha]\n",
    "    )\n",
    "\n",
    "    histo_add_ci.change(\n",
    "        fn=lambda check: gr.update(visible=check),\n",
    "        inputs=[histo_add_ci],\n",
    "        outputs=[histo_choose_ci]\n",
    "    )\n",
    "\n",
    "    histo_add_pi.change(\n",
    "        fn=lambda check: gr.update(visible=check),\n",
    "        inputs=[histo_add_pi],\n",
    "        outputs=[histo_choose_pi]\n",
    "    )\n",
    "\n",
    "    histo_add_ci.change(\n",
    "        fn=histo_add_ci_warning,\n",
    "        inputs=[histo_add_ci],\n",
    "        outputs=[]\n",
    "    )\n",
    "\n",
    "    histo_add_pi.change(\n",
    "        fn=histo_add_pi_warning,\n",
    "        inputs=[histo_add_pi],\n",
    "        outputs=[]\n",
    "    )\n",
    "\n",
    "    histo_add_normal.change(\n",
    "        fn=toggle_add_normal,\n",
    "        inputs=[histo_add_normal, histo_hat_mu, histo_hat_sigma],\n",
    "        outputs=[histo_hat_mu, histo_hat_mu_text, histo_hat_sigma, histo_hat_sigma_text]\n",
    "    )\n",
    "\n",
    "    histo_add_normal.change(\n",
    "        fn=add_normal_warning,\n",
    "        inputs=histo_add_normal,\n",
    "        outputs=[]\n",
    "    )\n",
    "\n",
    "    histo_hat_mu.change(\n",
    "        fn=lambda choice: gr.update(visible=(choice == \"Other\")),\n",
    "        inputs=histo_hat_mu,\n",
    "        outputs=histo_hat_mu_text\n",
    "    )\n",
    "\n",
    "    histo_hat_sigma.change(\n",
    "        fn=lambda choice: gr.update(visible=(choice == \"Other\")),\n",
    "        inputs=histo_hat_sigma,\n",
    "        outputs=histo_hat_sigma_text\n",
    "    )\n",
    "\n",
    "    ecdf_add_conf.change(\n",
    "        fn=lambda check: gr.update(visible=check),\n",
    "        inputs=ecdf_add_conf,\n",
    "        outputs=ecdf_alpha\n",
    "    )\n",
    "\n",
    "    ecdf_add_normal.change(\n",
    "        fn=toggle_add_normal,\n",
    "        inputs=[ecdf_add_normal, ecdf_hat_mu, ecdf_hat_sigma],\n",
    "        outputs=[ecdf_hat_mu, ecdf_hat_mu_text, ecdf_hat_sigma, ecdf_hat_sigma_text]\n",
    "    )\n",
    "\n",
    "    ecdf_add_normal.change(\n",
    "        fn=add_normal_warning,\n",
    "        inputs=ecdf_add_normal,\n",
    "        outputs=[]\n",
    "    )\n",
    "\n",
    "    ecdf_hat_mu.change(\n",
    "        fn=lambda choice: gr.update(visible=(choice == \"Other\")),\n",
    "        inputs=ecdf_hat_mu,\n",
    "        outputs=ecdf_hat_mu_text\n",
    "    )\n",
    "\n",
    "    ecdf_hat_sigma.change(\n",
    "        fn=lambda choice: gr.update(visible=(choice == \"Other\")),\n",
    "        inputs=ecdf_hat_sigma,\n",
    "        outputs=ecdf_hat_sigma_text\n",
    "    )\n",
    "\n",
    "    # --- Run Analysis Button ---\n",
    "    run_graph_stat_button.click(\n",
    "        run_graph_stat,\n",
    "        inputs=[\n",
    "            column_dropdown,\n",
    "            graph_stat_dropdown,\n",
    "            histo_add_kde, histo_add_data,\n",
    "            histo_add_ci, histo_choose_ci,\n",
    "            histo_add_pi, histo_choose_pi,\n",
    "            histo_add_normal,\n",
    "            histo_hat_mu, histo_hat_mu_text,\n",
    "            histo_hat_sigma, histo_hat_sigma_text,\n",
    "            ecdf_add_conf,\n",
    "            ecdf_alpha,\n",
    "            ecdf_add_normal,\n",
    "            ecdf_hat_mu, ecdf_hat_mu_text,\n",
    "            ecdf_hat_sigma, ecdf_hat_sigma_text          \n",
    "        ],\n",
    "        outputs=[output_table_group, output_table, output_plot_group, output_plot])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b2f7179",
   "metadata": {},
   "source": [
    "# üéÆ üßÆ Logic control of Descriptive Tab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6a13dab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_weights(input_str, length):\n",
    "    if not input_str.strip():\n",
    "        return None\n",
    "    weights = [float(w.strip()) for w in input_str.split(',') if w.strip()]\n",
    "    if len(weights) != length:\n",
    "        raise ValueError(f\"Number of weights ({len(weights)}) must match number of observations ({length})\")\n",
    "    return weights\n",
    "\n",
    "def parse_winsor(input_str):\n",
    "    if not input_str.strip():\n",
    "        return None\n",
    "    winsor_param = [float(w.strip()) for w in input_str.split(',') if w.strip()]\n",
    "    if len(winsor_param) != 2:\n",
    "        raise ValueError(f\"Length of winsorized input ({len(winsor_param)}) must be two (lower, and upper)\")\n",
    "    return winsor_param\n",
    "\n",
    "def parse_quantiles(input_str):\n",
    "    if ',' in input_str:\n",
    "        q = [float(x.strip()) for x in input_str.split(',') if x.strip()]\n",
    "    else:\n",
    "        q = float(input_str)\n",
    "    return q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2864a27a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def toggle_desc_params(desc_stat):\n",
    "    if desc_stat == \"Quantiles\":\n",
    "        return (\n",
    "            gr.update(visible=True),  # quantiles input\n",
    "            gr.update(visible=False) # central_tendecy_params\n",
    "        )\n",
    "    elif desc_stat in [\"Central Tendency\", \"All Descriptive Statistics\"]:\n",
    "        return (\n",
    "            gr.update(visible=False),  \n",
    "            gr.update(visible=True),\n",
    "        )\n",
    "    else:\n",
    "        return (\n",
    "            gr.update(visible=False),  \n",
    "            gr.update(visible=False)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d4bbfcdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_desc_stat(\n",
    "        column,\n",
    "        descriptive_stat,\n",
    "        quantiles_input, weights_input, trim_input, winsor_input\n",
    "        ):\n",
    "    \n",
    "    df, data, stats, error_df, error_plot = prepare_data(column)\n",
    "    if error_df:\n",
    "        return gr.update(visible=True), error_df, gr.update(visible=False), error_plot \n",
    "\n",
    "    # --- Descriptive Analysis ---\n",
    "    \n",
    "    if descriptive_stat == \"Quantiles\":\n",
    "        q = parse_quantiles(quantiles_input)\n",
    "        stats.CalculateQuantiles(q)\n",
    "        df_output = stats.quantiles.round(ROUND).reset_index().rename(columns={\"index\": \"Measure\"})\n",
    "\n",
    "    elif descriptive_stat == \"Quartiles\":\n",
    "        stats.CalculateQuartiles()\n",
    "        df_output = stats.quartiles.round(ROUND).reset_index().rename(columns={\"index\": \"Measure\"})\n",
    "\n",
    "    elif descriptive_stat == \"Central Tendency\":\n",
    "        trim_param = parse_text(trim_input)\n",
    "        winsor_param = parse_winsor(winsor_input)\n",
    "        weights = parse_weights(weights_input, len(data))\n",
    "\n",
    "        stats.CalculateCentralTendency(weights=weights, winsor_param=winsor_param, trim_param=trim_param)\n",
    "        df_output = stats.central_tendency.round(ROUND).reset_index().rename(columns={\"index\": \"Measure\"})\n",
    "\n",
    "    elif descriptive_stat == \"Dispersion\":\n",
    "        stats.CalculateDispersion()\n",
    "        df_output = stats.dispersion.round(ROUND).reset_index().rename(columns={\"index\": \"Measure\"})\n",
    "\n",
    "    elif descriptive_stat == \"Skewness\":\n",
    "        stats.CalculateSkewness()\n",
    "        df_output = stats.skew.round(ROUND).reset_index().rename(columns={\"index\": \"Measure\"})\n",
    "\n",
    "    elif descriptive_stat == \"Kurtosis\":\n",
    "        stats.CalculateKurtosis()\n",
    "        df_output = stats.kurtosis.round(ROUND).reset_index().rename(columns={\"index\": \"Measure\"})\n",
    "\n",
    "    elif descriptive_stat == \"All Descriptive Statistics\":\n",
    "        trim_param = parse_text(trim_input)\n",
    "        winsor_param = parse_winsor(winsor_input)\n",
    "        weights = parse_weights(weights_input, len(data))\n",
    "\n",
    "        stats.CalculateDescriptiveStatistics(weights=weights, winsor_param=winsor_param, trim_param=trim_param)\n",
    "\n",
    "        # Merge all tables with a hierarchical index\n",
    "        df_combined = pd.concat([\n",
    "            stats.quartiles,\n",
    "            stats.central_tendency,\n",
    "            stats.dispersion,\n",
    "            stats.skew,\n",
    "            stats.kurtosis\n",
    "        ], keys=[\"Quartiles\", \"Central Tendency\", \"Dispersion\", \"Skewness\", \"Kurtosis\"])\n",
    "\n",
    "        df_output = df_combined.round(ROUND).reset_index().rename(columns={\"level_0\": \"Statistic Type\", \"level_1\": \"Measure\"})\n",
    "\n",
    "    export_cache[\"table\"] = df_output\n",
    "    #export_cache[\"figure\"] = fig\n",
    "\n",
    "    # output_table_group, output_table, output_plot_group, output_plot\n",
    "    return gr.update(visible=True), df_output, gr.update(visible=False), None "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40df50f4",
   "metadata": {},
   "source": [
    "# üñ•Ô∏è üßÆ GUI of Descriptive Tab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3e2e9d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_descriptive_tab():\n",
    "    with gr.Group():\n",
    "        gr.Markdown(\"# üßÆ Descriptive Analysis\")\n",
    "        #with gr.Accordion(\"üî¢ Numeric Parameters\", open=True):\n",
    "        with gr.Row(elem_id=\"row_centered\"):\n",
    "            refresh_columns_button = gr.Button(\"üîÑ Refresh Numeric Columns\")\n",
    "            column_dropdown = gr.Dropdown(label=\"Select Numeric Column\", choices=[], elem_classes=\"data_related\", elem_id=\"custom_dropdown\")\n",
    "\n",
    "            descriptive_stat = gr.Dropdown(\n",
    "                label=\"Select Descriptive Statistic\",\n",
    "                choices=[\n",
    "                    \"Quantiles\",\n",
    "                    \"Quartiles\",\n",
    "                    \"Central Tendency\",\n",
    "                    \"Dispersion\",\n",
    "                    \"Skewness\",\n",
    "                    \"Kurtosis\",\n",
    "                    \"All Descriptive Statistics\"\n",
    "                ],\n",
    "                value=\"All Descriptive Statistics\",\n",
    "                interactive=True\n",
    "            )\n",
    "            quantiles_input = gr.Textbox(label=\"Quantiles (e.g., 0.25, 0.5, 0.75)\", value=\"0.25, 0.5, 0.75\", visible=False)\n",
    "\n",
    "        with gr.Row() as central_tendecy_params:\n",
    "            weights_input = gr.Textbox(label=\"Weights (comma-separated)\", placeholder=\"e.g., 1, 1, 0.5, 0.8\", visible=True)\n",
    "            trim_input = gr.Textbox(label=\"Trim percentage (e.g., 0.1)\", value=0.1, visible=True)\n",
    "            winsor_input = gr.Textbox(label=\"Winsorized percentages (e.g., 0.1, 0.1)\", value=\"0.1, 0.1\", visible=True)\n",
    "\n",
    "        run_desc_stat_button = gr.Button(value=\" üöÄ Run Descriptive Analysis\")\n",
    "\n",
    "    # --- Results ---\n",
    "    output_table_group, output_table, output_plot_group, output_plot = build_results_block(False, False)\n",
    "\n",
    "    # --- Modify behavior of components of the GUI ---\n",
    "    refresh_columns_button.click(\n",
    "        fn=load_numeric_cols,\n",
    "        inputs=[],\n",
    "        outputs=[column_dropdown]\n",
    "    )\n",
    "\n",
    "    descriptive_stat.change(\n",
    "        fn=toggle_desc_params,\n",
    "        inputs=descriptive_stat,\n",
    "        outputs=[quantiles_input, central_tendecy_params]\n",
    "    )\n",
    "\n",
    "    # --- Run Analysis Button ---\n",
    "    run_desc_stat_button.click(\n",
    "        run_desc_stat,\n",
    "        inputs=[\n",
    "            column_dropdown,\n",
    "            descriptive_stat,\n",
    "            quantiles_input, weights_input, trim_input, winsor_input\n",
    "        ],\n",
    "        outputs=[output_table_group, output_table, output_plot_group, output_plot]\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8da322cf",
   "metadata": {},
   "source": [
    "# üéÆ üí≠ Logic control of Statistical Inference Tab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b904f228",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stat_inf_warning(check):\n",
    "    if check:\n",
    "        gr.Warning(\"If you haven't done it yet, run first a descriptive analysis for central tendency and dispersion.\")\n",
    "\n",
    "def conf_interval_warning(check):\n",
    "    if check == \"Confidence Regions\":\n",
    "        gr.Warning(\"If you haven't done it yet, run first a statistical inference for CI.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1c6dbec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_probs(input_str):\n",
    "    if not input_str.strip():\n",
    "        return None\n",
    "    probs = [float(w.strip()) for w in input_str.split(',') if w.strip()]\n",
    "    return probs\n",
    "\n",
    "def parse_margin(input_str):\n",
    "    if not input_str.strip():\n",
    "        return None\n",
    "    eps = [float(w.strip()) for w in input_str.split(',') if w.strip()]\n",
    "    if len(eps) != 2:\n",
    "        raise ValueError(f\"Length of margin ({len(eps)}) must be two (Œº,œÉ)\")\n",
    "    return eps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "437e826d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def toggle_stat_inf(sel):\n",
    "    if sel in [\"Confidence Interval\", \"Prediction Interval\", \"Confidence and Prediction Intervals\"]:\n",
    "        return gr.update(visible=True), gr.update(visible=False)\n",
    "    elif sel == \"Confidence Regions\":\n",
    "        return gr.update(visible=False), gr.update(visible=True)\n",
    "    else:\n",
    "        return gr.update(visible=True), gr.update(visible=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c63d5484",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_stat_inf(\n",
    "        column,\n",
    "        statistical_inf,\n",
    "        alpha_input,\n",
    "        probs_input, eps_input,\n",
    "        like_add_interval,\n",
    "        mean_select, mean_estimate_text,\n",
    "        median_select, median_estimate_text,\n",
    "        sigma_select, sigma_estimate_text\n",
    "        ):\n",
    "    \n",
    "    df, data, stats, error_df, error_plot = prepare_data(column)\n",
    "    if error_df:\n",
    "        return gr.update(visible=True), error_df, gr.update(visible=False), error_plot \n",
    "\n",
    "    # --- Statistical Inference ---\n",
    "    \n",
    "    alpha = parse_text(alpha_input)\n",
    "    alpha = 1 - alpha\n",
    "    if alpha is None or not (0 < alpha < 1):\n",
    "        return pd.DataFrame([[\"Invalid alpha value.\"]], columns=[\"Error\"])\n",
    "\n",
    "    # Choose mean\n",
    "    hat_mean = choose_mu(mean_select, stats, mean_estimate_text)\n",
    "    \n",
    "    # Choose median\n",
    "    if median_select == \"Sample Median\":\n",
    "        hat_median = stats.median\n",
    "    elif  median_select == \"Other\":\n",
    "        hat_median = float(median_estimate_text)\n",
    "\n",
    "    # Choose sigma\n",
    "    hat_sigma = choose_sigma(sigma_select, stats, sigma_estimate_text)\n",
    "        \n",
    "    if (mean_select == \"Sample Mean\") and (sigma_select == \"Deviation (1 ddof)\"):\n",
    "        dist=\"t\"\n",
    "    else:\n",
    "        dist=\"norm\"\n",
    "\n",
    "    if statistical_inf == \"Confidence Interval\":\n",
    "        stats.CalculateConfidenceInterval(alpha, hat_mean, hat_median, hat_sigma, dist)\n",
    "        df_output = stats.confidence_intervals.round(ROUND).reset_index().rename(columns={\"index\": \"Measure\"})\n",
    "        fig = None\n",
    "        visible_table = True\n",
    "        visible_fig = False\n",
    "\n",
    "    elif statistical_inf == \"Prediction Interval\":\n",
    "        stats.CalculatePredictionInterval(alpha, hat_mean, hat_median, hat_sigma, dist)\n",
    "        df_output = stats.prediction_intervals.round(ROUND).reset_index().rename(columns={\"index\": \"Measure\"})\n",
    "        fig = None\n",
    "        visible_table = True\n",
    "        visible_fig = False\n",
    "\n",
    "    elif statistical_inf == \"Confidence and Prediction Intervals\":\n",
    "        stats.CalculateConfidenceInterval(alpha, hat_mean, hat_median, hat_sigma, dist)\n",
    "        stats.CalculatePredictionInterval(alpha, hat_mean, hat_median, hat_sigma, dist)\n",
    "\n",
    "        # Merge all tables with a hierarchical index\n",
    "        df_combined = pd.concat([\n",
    "            stats.confidence_intervals,\n",
    "            stats.prediction_intervals\n",
    "        ], keys=[\"Confidence\", \"Prediction\"])\n",
    "    \n",
    "        df_output = df_combined.round(ROUND).reset_index().rename(columns={\"level_0\": \"Interval Type\", \"level_1\": \"Measure\"})\n",
    "        fig = None\n",
    "        visible_table = True\n",
    "        visible_fig = False\n",
    "\n",
    "    elif statistical_inf == \"Confidence Regions\":\n",
    "        probs = parse_probs(probs_input)\n",
    "        eps = parse_margin(eps_input)\n",
    "        fig = stats.PlotConfidenceRegions(probs, eps, like_add_interval)\n",
    "        df_output = pd.DataFrame()\n",
    "        visible_table = False \n",
    "        visible_fig = True\n",
    "    \n",
    "    elif statistical_inf == \"Confidence Interval and Regions\":\n",
    "        probs = parse_probs(probs_input)\n",
    "        eps = parse_margin(eps_input)\n",
    "        stats.CalculateConfidenceInterval(alpha, hat_mean, hat_median, hat_sigma, dist)\n",
    "        df_output = stats.confidence_intervals.round(ROUND).reset_index().rename(columns={\"index\": \"Measure\"})\n",
    "        fig = stats.PlotConfidenceRegions(probs, eps, like_add_interval)\n",
    "        visible_table = True\n",
    "        visible_fig = True\n",
    "\n",
    "    export_cache[\"table\"] = df_output\n",
    "    export_cache[\"figure\"] = fig\n",
    "\n",
    "    # output_table_group, output_table, output_plot_group, output_plot\n",
    "    return gr.update(visible=visible_table), df_output, gr.update(visible=visible_fig), fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dccce95f",
   "metadata": {},
   "source": [
    "# üñ•Ô∏è üí≠ GUI of Statistical Inference Tab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "467c4bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_inference_tab():\n",
    "    with gr.Group():\n",
    "        gr.Markdown(\"# üí≠ Statistical Inference\")\n",
    "\n",
    "        with gr.Accordion(\"üß† Technical Information\", open=False):\n",
    "            gr.Markdown(\n",
    "                \"\"\"\n",
    "                - All intervals are calculated assuming the observations are i.i.d. from a Normal distribution.  \n",
    "                - If the sample mean and the sample deviation with one degree of freedom are selected as estimators for the mean and standard deviation, \n",
    "                then a *t*-distribution is used to compute the Confidence Interval (CI) for the mean and the Prediction Interval (PI) based on the mean.  \n",
    "                - The asymptotic Normal distribution is used for the CI and PI based on the median.\n",
    "                \"\"\"\n",
    "            )\n",
    "\n",
    "        with gr.Row(elem_id=\"row_centered\"):\n",
    "            refresh_columns_button = gr.Button(\"üîÑ Refresh Numeric Columns\")\n",
    "            column_dropdown = gr.Dropdown(label=\"Select Numeric Column\", choices=[], elem_classes=\"data_related\", elem_id=\"custom_dropdown\")\n",
    "            \n",
    "            stat_inf_dropdown = gr.Dropdown(\n",
    "                label=\"Type of Estimation\",\n",
    "                choices=[\n",
    "                    \"Confidence Interval\",\n",
    "                    \"Prediction Interval\",\n",
    "                    \"Confidence and Prediction Intervals\",\n",
    "                    \"Confidence Regions\",\n",
    "                    \"Confidence Interval and Regions\"\n",
    "                ],\n",
    "                value=\"Confidence and Prediction Intervals\",\n",
    "                interactive=True\n",
    "            )\n",
    "\n",
    "        with gr.Row(visible=True) as stat_inf_intervals:\n",
    "            alpha_input = gr.Textbox(label=\"Confidence level (e.g. 0.95)\", value=0.95, interactive=True)\n",
    "            mean_select = gr.Dropdown(\n",
    "                choices=[\n",
    "                    \"Sample Mean\",\n",
    "                    \"Geometric Mean\",\n",
    "                    \"Harmonic Mean\",\n",
    "                    \"Weighted Mean\",\n",
    "                    \"Trimmed Mean\",\n",
    "                    \"Interquartile Mean\",\n",
    "                    \"Winsorized Mean\",\n",
    "                    \"Other\"\n",
    "                    ],\n",
    "                label=\"Mean Estimate\",\n",
    "                value=\"Sample Mean\"\n",
    "            )\n",
    "\n",
    "            mean_estimate_text = gr.Textbox(label=\"Write the value of a consistent estimator\", visible=False)\n",
    "\n",
    "            median_select = gr.Dropdown(\n",
    "                choices=[\"Sample Median\", \"Other\"],\n",
    "                label=\"Median Estimate\", value=\"Sample Median\"\n",
    "            )\n",
    "            median_estimate_text = gr.Textbox(label=\"Write the value of a consistent estimator\", visible=False)\n",
    "\n",
    "            sigma_select = gr.Dropdown(\n",
    "                choices=[\n",
    "                    \"Deviation (1 ddof)\",\n",
    "                    \"Range (bias corrected)\",\n",
    "                    \"IQR (bias corrected)\",\n",
    "                    \"MAD (bias corrected)\",\n",
    "                    \"AAD (bias corrected)\",\n",
    "                    \"Other\"\n",
    "                ],\n",
    "                label=\"Deviation Estimate\",\n",
    "                value=\"Deviation (1 ddof)\"\n",
    "            )\n",
    "            sigma_estimate_text = gr.Textbox(label=\"Write the value of a consistent estimator\", visible=False)\n",
    "\n",
    "        with gr.Row(visible=False) as stat_inf_regions:\n",
    "            like_probs = gr.Textbox(label=\"Confidence levels (from lower to higher)\", value=\"0.1, 0.5, 0.75, 0.89, 0.95\", interactive=True, visible=True)\n",
    "            like_eps = gr.Textbox(label=\"Extra margin for Œº and œÉ\", value=\"0.1, 0.05\", interactive=True, visible=True)\n",
    "            like_add_interval = gr.Checkbox(label=\"Add CI for Œº and œÉ\", value=True)\n",
    "\n",
    "        run_stat_inf_button = gr.Button(value=\" üöÄ Run Statistical Inference\")\n",
    "    \n",
    "    # --- Results ---\n",
    "    output_table_group, output_table, output_plot_group, output_plot = build_results_block(False, False)\n",
    "\n",
    "    # --- Modify behavior of components of the GUI ---\n",
    "    refresh_columns_button.click(\n",
    "        fn=load_numeric_cols,\n",
    "        inputs=[],\n",
    "        outputs=[column_dropdown]\n",
    "    )\n",
    "\n",
    "    column_dropdown.change(\n",
    "        fn=stat_inf_warning,\n",
    "        inputs=[column_dropdown],\n",
    "        outputs=[]\n",
    "    )\n",
    "\n",
    "    stat_inf_dropdown.change(\n",
    "        fn=conf_interval_warning,\n",
    "        inputs=[stat_inf_dropdown],\n",
    "        outputs=[]\n",
    "    )\n",
    "\n",
    "    stat_inf_dropdown.change(\n",
    "        fn=toggle_stat_inf,\n",
    "        inputs=stat_inf_dropdown,\n",
    "        outputs=[stat_inf_intervals, stat_inf_regions]\n",
    "    )\n",
    "\n",
    "    mean_select.change(\n",
    "        fn=lambda choice: gr.update(visible=(choice == \"Other\")),\n",
    "        inputs=mean_select,\n",
    "        outputs=mean_estimate_text\n",
    "    )\n",
    "\n",
    "    median_select.change(\n",
    "        fn=lambda choice: gr.update(visible=(choice == \"Other\")),\n",
    "        inputs=median_select,\n",
    "        outputs=median_estimate_text\n",
    "    )\n",
    "\n",
    "    sigma_select.change(\n",
    "        fn=lambda choice: gr.update(visible=(choice == \"Other\")),\n",
    "        inputs=sigma_select,\n",
    "        outputs=sigma_estimate_text\n",
    "    )\n",
    "\n",
    "    # --- Run Analysis Button ---\n",
    "    run_stat_inf_button.click(\n",
    "        run_stat_inf,\n",
    "        inputs=[\n",
    "            column_dropdown,\n",
    "            stat_inf_dropdown,\n",
    "            alpha_input,\n",
    "            like_probs, like_eps,\n",
    "            like_add_interval,\n",
    "            mean_select, mean_estimate_text,\n",
    "            median_select, median_estimate_text,\n",
    "            sigma_select, sigma_estimate_text\n",
    "        ],\n",
    "        outputs=[output_table_group, output_table, output_plot_group, output_plot]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28f822a0",
   "metadata": {},
   "source": [
    "# üß† üß™ Brain of Hypothesis Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c12d488f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_ttest_mean_distribution(numeric_col, sample, mu0, df_output, alternative, bootstrap_samples):\n",
    "    plt.style.use(\"seaborn-v0_8-whitegrid\")\n",
    "\n",
    "    # --- t-test using Pingouin ---\n",
    "    t_val = df_output[\"T\"].values[0]\n",
    "    p_val = df_output[\"p-val\"].values[0]\n",
    "    df = df_output[\"dof\"].values[0]\n",
    "\n",
    "    # --- Sample stats ---\n",
    "    n = len(sample)\n",
    "    sample_mean = np.mean(sample)\n",
    "    sample_std = np.std(sample, ddof=1)\n",
    "    se = sample_std / np.sqrt(n)\n",
    "\n",
    "    # --- Theoretical t-distribution under H‚ÇÄ ---\n",
    "    x = np.linspace(mu0 - 5 * se, mu0 + 5 * se, 1000)\n",
    "    t_density = t.pdf((x - mu0) / se, df) / se\n",
    "\n",
    "    # --- Bootstrap sampling distribution of the mean ---\n",
    "    boot_means = np.array([\n",
    "        np.mean(np.random.choice(sample, size=n, replace=True))\n",
    "        for _ in range(bootstrap_samples)\n",
    "    ])\n",
    "    kde = sns.kdeplot(boot_means, bw_adjust=1.2)\n",
    "    x_kde, y_kde = kde.get_lines()[0].get_data()\n",
    "    plt.close()\n",
    "\n",
    "    # --- Plot ---\n",
    "    fig, ax = plt.subplots(figsize=(8, 5))\n",
    "\n",
    "    # Plot bootstrap KDE\n",
    "    ax.plot(x_kde, y_kde, color=\"rebeccapurple\", label=\"Bootstrap sampling dist.\", linewidth=2)\n",
    "\n",
    "    # Plot theoretical t-distribution under H‚ÇÄ\n",
    "    ax.plot(x, t_density, color=\"gray\", linestyle=\"--\", linewidth=2, label=fr\"$t$-distribution ($H_0$)\")\n",
    "\n",
    "    # --- Shade p-value region under t-distribution ---\n",
    "    if alternative == \"two-sided\":\n",
    "        delta = abs(sample_mean - mu0)\n",
    "        lower = mu0 - delta\n",
    "        upper = mu0 + delta\n",
    "        mask = (x <= lower) | (x >= upper)\n",
    "    elif alternative == \"greater\":\n",
    "        mask = x >= sample_mean\n",
    "    elif alternative == \"less\":\n",
    "        mask = x <= sample_mean\n",
    "    else:\n",
    "        raise ValueError(\"alternative must be 'two-sided', 'greater', or 'less'\")\n",
    "\n",
    "    ax.fill_between(x, 0, t_density, where=mask, color=\"red\", alpha=0.3,\n",
    "                    label=f\"p-value ‚âà {p_val:.3f}\")\n",
    "\n",
    "    # --- Reference lines ---\n",
    "    ax.axvline(mu0, color=\"tab:orange\", linestyle=\"--\", linewidth=2, label=fr\"$\\mu_0 = {mu0}$\")\n",
    "    ax.axvline(sample_mean, color=\"black\", linestyle=\"-\", linewidth=1.5,\n",
    "               label=fr\"Sample mean = {sample_mean:.2f}\")\n",
    "\n",
    "    # --- Formatting ---\n",
    "    ax.set_title(f\"Sampling Distribution of the Mean ({numeric_col})\", fontsize=14)\n",
    "    ax.set_xlabel(\"Sample Mean\", fontsize=12)\n",
    "    ax.set_ylabel(\"Density\", fontsize=12)\n",
    "    ax.grid(True, linestyle='--', alpha=0.5)\n",
    "    ax.legend()\n",
    "    plt.tight_layout()\n",
    "\n",
    "    return fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7ac09c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_sample_ttest(numeric_col, mu0_text, alternative, graph_check, bootstrap_samples):\n",
    "\n",
    "    df, data, stats, error_df, error_plot = prepare_data(numeric_col)\n",
    "    if error_df:\n",
    "        return gr.update(visible=True), error_df, gr.update(visible=False), error_plot \n",
    "\n",
    "    mu0 = float(mu0_text)\n",
    "\n",
    "    try:\n",
    "        sample = df[numeric_col].dropna()\n",
    "        if sample.empty:\n",
    "            return plt.figure(), pd.DataFrame([[\"No valid data in the selected column.\"]], columns=[\"Error\"])\n",
    "\n",
    "        # --- One-sample t-test ---\n",
    "        df_output = pg.ttest(sample, mu0, alternative=alternative, paired=False).round(4)\n",
    "\n",
    "        # --- Plot ---\n",
    "        if graph_check:\n",
    "            fig = plot_ttest_mean_distribution(numeric_col, sample, mu0, df_output, alternative, bootstrap_samples)\n",
    "        else:\n",
    "            fig = None\n",
    "\n",
    "        export_cache[\"table\"] = df_output\n",
    "        export_cache[\"figure\"] = fig\n",
    "\n",
    "        # output_table_group, output_table, output_plot_group, output_plot\n",
    "        return gr.update(visible=True), df_output, gr.update(visible=True), fig\n",
    "\n",
    "    except Exception as e:\n",
    "        return gr.update(visible=True), pd.DataFrame([[f\"‚ùå Error: {e}\"]], gr.update(visible=False), columns=[\"Error\"]), None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "35901676",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mirror_plot(numeric_col, group1, name_group1, group2, name_group2, df_output):\n",
    "    # Extract test results from df_output\n",
    "    t_val = df_output[\"T\"].values[0]\n",
    "    p_val = df_output[\"p-val\"].values[0]\n",
    "\n",
    "    # Means\n",
    "    mean1 = np.mean(group1)\n",
    "    mean2 = np.mean(group2)\n",
    "\n",
    "    # Setup plot\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "    # Shared binning and KDE range\n",
    "    combined = np.concatenate([group1, group2])\n",
    "    x_min, x_max = min(combined), max(combined)\n",
    "    bin_range = np.linspace(x_min, x_max, 30)\n",
    "    bin_centers = (bin_range[:-1] + bin_range[1:]) / 2\n",
    "    bin_width = np.diff(bin_range)[0]\n",
    "    x_vals = np.linspace(x_min, x_max, 200)\n",
    "\n",
    "    # --- Group 1 (top) ---\n",
    "    sns.histplot(group1, bins=bin_range, stat=\"density\", kde=False,\n",
    "                 color=\"rebeccapurple\", label=name_group1, alpha=0.6, ax=ax)\n",
    "    kde1 = gaussian_kde(group1)\n",
    "    ax.plot(x_vals, kde1(x_vals), color=\"rebeccapurple\", linewidth=2)\n",
    "    ax.axvline(mean1, color=\"rebeccapurple\", linestyle=\"--\", linewidth=2,\n",
    "               label=f\"{name_group1} mean = {mean1:.2f}\")\n",
    "\n",
    "    # --- Group 2 (bottom, mirrored) ---\n",
    "    heights2, _ = np.histogram(group2, bins=bin_range, density=True)\n",
    "    ax.bar(bin_centers, -heights2, width=bin_width,\n",
    "           color=\"tab:orange\", edgecolor=\"black\", alpha=0.6, label=name_group2)\n",
    "    kde2 = gaussian_kde(group2)\n",
    "    ax.plot(x_vals, -kde2(x_vals), color=\"tab:orange\", linewidth=2)\n",
    "    ax.axvline(mean2, color=\"tab:orange\", linestyle=\"--\", linewidth=2,\n",
    "               label=f\"{name_group2} mean = {mean2:.2f}\")\n",
    "\n",
    "    # Baseline\n",
    "    ax.axhline(0, color=\"black\", linewidth=1)\n",
    "\n",
    "    # Title, labels\n",
    "    ax.set_title(\"Mirror Plot: Two-Sample Distribution Comparison\", fontsize=14)\n",
    "    ax.set_xlabel(numeric_col)\n",
    "    ax.set_ylabel(\"Density (Top ‚Üë vs. Bottom ‚Üì)\", fontsize=11)\n",
    "\n",
    "    # Annotate t-test result\n",
    "    ax.text(0.01, 0.95,\n",
    "            f\"p = {p_val:.3f}\",\n",
    "            transform=ax.transAxes,\n",
    "            fontsize=11,\n",
    "            verticalalignment='top',\n",
    "            bbox=dict(boxstyle=\"round\", facecolor=\"white\", alpha=0.6))\n",
    "\n",
    "    ax.legend()\n",
    "    plt.tight_layout()\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fd788680",
   "metadata": {},
   "outputs": [],
   "source": [
    "def two_sample_ttest(numeric_col, alternative, cat_col1, cat_vals1, name_group1, cat_col2, cat_vals2, name_group2, correction):\n",
    "\n",
    "    df, data, stats, error_df, error_plot = prepare_data(numeric_col)\n",
    "    if error_df:\n",
    "        return gr.update(visible=True), error_df, gr.update(visible=False), error_plot \n",
    "\n",
    "    try:\n",
    "        group1 = df[df[cat_col1].isin(cat_vals1)][numeric_col].dropna()\n",
    "        group2 = df[df[cat_col2].isin(cat_vals2)][numeric_col].dropna()\n",
    "\n",
    "        if group1.empty or group2.empty:\n",
    "            return gr.update(visible=True), pd.DataFrame([[\"One or both groups are empty after filtering.\"]], columns=[\"Error\"]), gr.update(visible=False), error_plot\n",
    "\n",
    "        # --- t-test ---\n",
    "        df_output = pg.ttest(group1, group2, alternative=alternative, paired=False, correction=correction).round(ROUND)\n",
    "\n",
    "        # --- Plot ---\n",
    "        fig = mirror_plot(numeric_col, group1, name_group1, group2, name_group2, df_output)\n",
    "\n",
    "        export_cache[\"table\"] = df_output\n",
    "        export_cache[\"figure\"] = fig\n",
    "\n",
    "        # output_table_group, output_table, output_plot_group, output_plot\n",
    "        return gr.update(visible=True), df_output, gr.update(visible=True), fig\n",
    "\n",
    "    except Exception as e:\n",
    "        return gr.update(visible=True), pd.DataFrame([[f\"‚ùå Error: {e}\"]], gr.update(visible=False), columns=[\"Error\"]), None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5fc7a4af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def variance_test(numeric_col, cat_col1, cat_vals1, name_group1,\n",
    "                  cat_col2, cat_vals2, name_group2,\n",
    "                  test_type, graph_check, bootstrap_samples):\n",
    "\n",
    "    df, data, stats, error_df, error_plot = prepare_data(numeric_col)\n",
    "    if error_df:\n",
    "        return gr.update(visible=True), error_df, gr.update(visible=False), error_plot\n",
    "\n",
    "    try:\n",
    "        group1 = df[df[cat_col1].isin(cat_vals1)][numeric_col].dropna()\n",
    "        group2 = df[df[cat_col2].isin(cat_vals2)][numeric_col].dropna()\n",
    "\n",
    "        if group1.empty or group2.empty:\n",
    "            err = pd.DataFrame([[\"One or both groups are empty after filtering.\"]], columns=[\"Error\"])\n",
    "            return gr.update(visible=True), err, gr.update(visible=False), error_plot\n",
    "\n",
    "        # --- Apply variance test ---\n",
    "        if test_type == \"Bartlett\":\n",
    "            stat, p = bartlett(group1, group2)\n",
    "            method = \"Bartlett's test\"\n",
    "        elif test_type == \"Levene\":\n",
    "            stat, p = levene(group1, group2, center=\"mean\")\n",
    "            method = \"Levene's test\"\n",
    "        else:\n",
    "            err = pd.DataFrame([[\"Invalid test type selected.\"]], columns=[\"Error\"])\n",
    "            return gr.update(visible=True), err, gr.update(visible=False), error_plot\n",
    "\n",
    "        # --- Observed variances ---\n",
    "        var1 = np.var(group1, ddof=1)\n",
    "        var2 = np.var(group2, ddof=1)\n",
    "\n",
    "        # --- Create result table ---\n",
    "        df_output = pd.DataFrame({\n",
    "            \"Test\": [method],\n",
    "            \"Statistic\": [round(stat, ROUND)],\n",
    "            \"p-value\": [round(p, ROUND)],\n",
    "            f\"Var({name_group1})\": [round(var1, ROUND)],\n",
    "            f\"Var({name_group2})\": [round(var2, ROUND)]\n",
    "        })\n",
    "\n",
    "        # --- Bootstrap Plot ---\n",
    "        fig = None\n",
    "        if graph_check:\n",
    "            # Bootstrap variances\n",
    "            boot1 = [np.var(np.random.choice(group1, size=len(group1), replace=True), ddof=1)\n",
    "                     for _ in range(bootstrap_samples)]\n",
    "            boot2 = [np.var(np.random.choice(group2, size=len(group2), replace=True), ddof=1)\n",
    "                     for _ in range(bootstrap_samples)]\n",
    "\n",
    "            # Plot\n",
    "            fig, ax = plt.subplots(figsize=(8, 5))\n",
    "            sns.kdeplot(boot1, label=f\"{name_group1} variance\", fill=True, color=\"rebeccapurple\", alpha=0.6, ax=ax)\n",
    "            sns.kdeplot(boot2, label=f\"{name_group2} variance\", fill=True, color=\"tab:orange\", alpha=0.6, ax=ax)\n",
    "\n",
    "            ax.axvline(var1, color=\"rebeccapurple\", linestyle=\"--\", linewidth=2)\n",
    "            ax.axvline(var2, color=\"tab:orange\", linestyle=\"--\", linewidth=2)\n",
    "\n",
    "            ax.set_title(f\"Bootstrap Variance Distributions\\n{method}\", fontsize=14)\n",
    "            ax.set_xlabel(\"Variance\", fontsize=12)\n",
    "            ax.set_ylabel(\"Density\", fontsize=12)\n",
    "            ax.grid(True, linestyle=\"--\", alpha=0.5)\n",
    "\n",
    "            # Annotate test result\n",
    "            ax.text(0.98, 0.95,\n",
    "                    f\"{method}\\n\"\n",
    "                    f\"p = {round(p, 3)}\\n\"\n",
    "                    f\"Var({name_group1}) = {round(var1, 2)}\\n\"\n",
    "                    f\"Var({name_group2}) = {round(var2, 2)}\",\n",
    "                    transform=ax.transAxes,\n",
    "                    ha=\"right\", va=\"top\",\n",
    "                    bbox=dict(boxstyle=\"round\", facecolor=\"white\", alpha=0.7),\n",
    "                    fontsize=11)\n",
    "\n",
    "            ax.legend()\n",
    "            plt.tight_layout()\n",
    "\n",
    "        export_cache[\"table\"] = df_output\n",
    "        export_cache[\"figure\"] = fig\n",
    "\n",
    "        return gr.update(visible=True), df_output, gr.update(visible=True), fig\n",
    "\n",
    "    except Exception as e:\n",
    "        err = pd.DataFrame([[f\"‚ùå Error: {e}\"]], columns=[\"Error\"])\n",
    "        return gr.update(visible=True), err, gr.update(visible=False), None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "da466086",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_way_anova_plot(data_group, numeric_col, cat_col, df_output):\n",
    "\n",
    "    f_val = df_output[\"F\"].values[0]\n",
    "    p_val = df_output[\"p-unc\"].values[0]\n",
    "\n",
    "    # Unique groups and color palette\n",
    "    groups = sorted(data_group[cat_col].dropna().unique())\n",
    "    palette = sns.color_palette(\"tab10\", n_colors=len(groups))\n",
    "    group_color_map = {group: color for group, color in zip(groups, palette)}\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(8, 5))\n",
    "\n",
    "    # Plot KDEs manually, one per group\n",
    "    for group in groups:\n",
    "        subset = data_group[data_group[cat_col] == group][numeric_col].dropna()\n",
    "        sns.kdeplot(\n",
    "            subset,\n",
    "            fill=True,\n",
    "            common_norm=False,\n",
    "            color=group_color_map[group],\n",
    "            alpha=0.5,\n",
    "            linewidth=1,\n",
    "            label=str(group),\n",
    "            ax=ax\n",
    "        )\n",
    "\n",
    "    # Overall mean\n",
    "    overall_mean = data_group[numeric_col].mean()\n",
    "    ax.axvline(overall_mean, color=\"black\", linestyle=\":\", linewidth=1.2, label=\"Overall mean\")\n",
    "\n",
    "    ax.legend(title=cat_col)\n",
    "\n",
    "    # Add group means with matching colors\n",
    "    group_means = data_group.groupby(cat_col)[numeric_col].mean()\n",
    "    for group, mean_val in group_means.items():\n",
    "        ax.axvline(mean_val, color=group_color_map[group], linestyle=\"--\", linewidth=1.5, label=f\"{group} mean\")\n",
    "\n",
    "    # Annotation with F and p\n",
    "    ax.text(0.98, 0.95,\n",
    "            f\"p = {p_val:.3f}\",\n",
    "            transform=ax.transAxes,\n",
    "            ha=\"right\", va=\"top\",\n",
    "            bbox=dict(boxstyle=\"round\", facecolor=\"white\", alpha=0.7),\n",
    "            fontsize=11)\n",
    "\n",
    "    # Labels and title\n",
    "    ax.set_title(\"Group Distributions for One-way ANOVA\", fontsize=14)\n",
    "    ax.set_xlabel(numeric_col, fontsize=12)\n",
    "    ax.set_ylabel(\"Density\", fontsize=12)\n",
    "    ax.grid(True, linestyle=\"--\", alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    return fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "473e7ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_way_anova(numeric_col, cat_col, cat_vals):\n",
    "    df, data, stats, error_df, error_plot = prepare_data(numeric_col)\n",
    "    if error_df:\n",
    "        return gr.update(visible=True), error_df, gr.update(visible=False), error_plot \n",
    "\n",
    "    try:\n",
    "        data_group = df[df[cat_col].isin(cat_vals)][[numeric_col, cat_col]].dropna()\n",
    "\n",
    "        if data_group.empty:\n",
    "            err = pd.DataFrame([[\"Dataset is empty after filtering.\"]], columns=[\"Error\"])\n",
    "            return gr.update(visible=True), err, gr.update(visible=False), error_plot\n",
    "\n",
    "        # --- One-way ANOVA ---\n",
    "        df_output = pg.anova(dv=numeric_col, between=cat_col, data=data_group, detailed=True).round(ROUND)\n",
    "\n",
    "        # --- Plot setup ---\n",
    "        fig = one_way_anova_plot(data_group, numeric_col, cat_col, df_output)\n",
    "\n",
    "        export_cache[\"table\"] = df_output\n",
    "        export_cache[\"figure\"] = fig\n",
    "\n",
    "        return gr.update(visible=True), df_output, gr.update(visible=True), fig\n",
    "\n",
    "    except Exception as e:\n",
    "        err = pd.DataFrame([[f\"‚ùå Error: {e}\"]], columns=[\"Error\"])\n",
    "        return gr.update(visible=True), err, gr.update(visible=False), None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6130ee39",
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    def one_way_anova(numeric_col, cat_col, cat_vals):\n",
    "\n",
    "        df, data, stats, error_df, error_plot = prepare_data(numeric_col)\n",
    "        if error_df:\n",
    "            return gr.update(visible=True), error_df, gr.update(visible=False), error_plot \n",
    "\n",
    "        try:\n",
    "            data_group = df[df[cat_col].isin(cat_vals)][[numeric_col, cat_col]].dropna()\n",
    "\n",
    "            if data_group.empty:\n",
    "                return gr.update(visible=True), pd.DataFrame([[\"Dataset is empty after filtering.\"]], columns=[\"Error\"]), gr.update(visible=False), error_plot\n",
    "\n",
    "            # --- One-way ANOVA ---\n",
    "            df_output = pg.anova(dv=numeric_col, between=cat_col, data=data_group, detailed=True).round(ROUND)\n",
    "\n",
    "            # --- Plot ---\n",
    "            fig, ax = plt.subplots(figsize=(8, 5))\n",
    "\n",
    "            # KDE Plot\n",
    "            sns.kdeplot(\n",
    "                data=data_group,\n",
    "                x=numeric_col,\n",
    "                hue=cat_col,\n",
    "                fill=True,\n",
    "                common_norm=False,\n",
    "                palette='tab10',\n",
    "                alpha=0.5,\n",
    "                linewidth=1,\n",
    "                ax=ax\n",
    "            )\n",
    "\n",
    "            # Add group means as vertical lines\n",
    "            group_means = data_group.groupby(cat_col)[numeric_col].mean()\n",
    "            colors = sns.color_palette(\"tab10\", n_colors=len(group_means))\n",
    "\n",
    "            for i, (group, mean_val) in enumerate(group_means.items()):\n",
    "                ax.axvline(mean_val, color=colors[i], linestyle=\"--\", linewidth=1.5, label=f\"{group} mean\")\n",
    "\n",
    "            # Labels and title\n",
    "            ax.set_title(\"Group Distributions for One-way ANOVA\", fontsize=14)\n",
    "            ax.set_xlabel(numeric_col, fontsize=12)\n",
    "            ax.set_ylabel(\"Density\", fontsize=12)\n",
    "\n",
    "            # Optional: set legend title\n",
    "            handles, labels = ax.get_legend_handles_labels()\n",
    "            by_group = [h for h, lbl in zip(handles, labels) if \"mean\" not in lbl]\n",
    "            means = [h for h, lbl in zip(handles, labels) if \"mean\" in lbl]\n",
    "            ax.legend(by_group + means, [l for l in labels if \"mean\" not in l] + [l for l in labels if \"mean\" in l], title=cat_col)\n",
    "\n",
    "            ax.grid(True, linestyle=\"--\", alpha=0.3)\n",
    "            plt.tight_layout()\n",
    "\n",
    "            export_cache[\"table\"] = df_output\n",
    "            export_cache[\"figure\"] = fig\n",
    "\n",
    "            # output_table_group, output_table, output_plot_group, output_plot\n",
    "            return gr.update(visible=True), df_output, gr.update(visible=True), fig\n",
    "\n",
    "        except Exception as e:\n",
    "            return gr.update(visible=True), pd.DataFrame([[f\"‚ùå Error: {e}\"]], gr.update(visible=False), columns=[\"Error\"]), None\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c5d9fcb",
   "metadata": {},
   "source": [
    "# üéÆ üß™ Logic control of Hypothesis Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ca04a49b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def refresh_categorical_columns():\n",
    "    df = df_cache.get(\"df\")\n",
    "    if df is None:\n",
    "        return [gr.update(choices=[])] * 6\n",
    "\n",
    "    cat_cols = df_cache.get(\"categorical_cols\", [])\n",
    "    return [\n",
    "        gr.update(choices=cat_cols, value=None),  # cat_column_dropdown_1\n",
    "        gr.update(choices=cat_cols, value=None),  # cat_column_dropdown_2\n",
    "        gr.update(choices=cat_cols, value=None),  # cat_column_dropdown_3\n",
    "        gr.update(choices=[], value=[]),          # cat_values_dropdown_1\n",
    "        gr.update(choices=[], value=[]),          # cat_values_dropdown_2\n",
    "        gr.update(choices=[], value=[])           # cat_values_dropdown_3\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "acc10a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_category_options(col):\n",
    "    df = df_cache.get(\"df\")\n",
    "    if df is None:\n",
    "        return gr.update(choices=[], value=[])\n",
    "\n",
    "    values = sorted(df[col].dropna().unique()) if col else []\n",
    "\n",
    "    return gr.update(choices=values, value=[])\n",
    "\n",
    "def update_group_name(cat_vals, current_input, default_label):\n",
    "    # If exactly one category is selected, use it directly\n",
    "    if len(cat_vals) >= 1:\n",
    "        return gr.update(value=cat_vals[0])\n",
    "\n",
    "    # If nothing is selected, also fallback to default label\n",
    "    return gr.update(value=default_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3efd95c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def toggle_hypo_test(sel):\n",
    "    if sel == \"One sample Student's t-test\":\n",
    "        return [\n",
    "            gr.update(visible=True),  # mu0_input\n",
    "            gr.update(visible=True),  # alternative\n",
    "            gr.update(visible=True),  # ttest_graph_option\n",
    "            gr.update(visible=False), # ttest_correction_variance\n",
    "            gr.update(visible=False), # select_variance_test\n",
    "            gr.update(visible=False), # category_group\n",
    "            gr.update(visible=False), # group1\n",
    "            gr.update(visible=False), # group2\n",
    "            gr.update(visible=False)  # group_anova\n",
    "        ]\n",
    "    elif sel == \"Equal variance between two groups\":\n",
    "        return [\n",
    "            gr.update(visible=False),\n",
    "            gr.update(visible=False),\n",
    "            gr.update(visible=True),  \n",
    "            gr.update(visible=False), \n",
    "            gr.update(visible=True), \n",
    "            gr.update(visible=True), \n",
    "            gr.update(visible=True), \n",
    "            gr.update(visible=True), \n",
    "            gr.update(visible=False)  \n",
    "        ]\n",
    "    elif sel == \"Two samples Student's t-test\":\n",
    "        return [\n",
    "            gr.update(visible=False),\n",
    "            gr.update(visible=True),\n",
    "            gr.update(visible=False),  \n",
    "            gr.update(visible=True), \n",
    "            gr.update(visible=False), \n",
    "            gr.update(visible=True), \n",
    "            gr.update(visible=True), \n",
    "            gr.update(visible=True), \n",
    "            gr.update(visible=False)  \n",
    "        ]\n",
    "    elif sel == \"One-way ANOVA\":\n",
    "        return [\n",
    "            gr.update(visible=False),\n",
    "            gr.update(visible=False),\n",
    "            gr.update(visible=False),  \n",
    "            gr.update(visible=False), \n",
    "            gr.update(visible=False), \n",
    "            gr.update(visible=True), \n",
    "            gr.update(visible=False), \n",
    "            gr.update(visible=False), \n",
    "            gr.update(visible=True)  \n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2a3fa4c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_hypothesis_testing(\n",
    "        numeric_col,\n",
    "        hypo_test,\n",
    "        mu0_text,\n",
    "        alternative,\n",
    "        graph_check, bootstrap_samples,\n",
    "        cat_col1, cat_vals1, name_group1,\n",
    "        cat_col2, cat_vals2, name_group2,\n",
    "        cat_col3, cat_vals3,\n",
    "        correction,\n",
    "        test_type\n",
    "    ):\n",
    "\n",
    "    if hypo_test == \"One sample Student's t-test\":\n",
    "        return one_sample_ttest(numeric_col, mu0_text, alternative, graph_check, bootstrap_samples)\n",
    "    elif hypo_test == \"Two samples Student's t-test\":\n",
    "        return two_sample_ttest(numeric_col, alternative, cat_col1, cat_vals1, name_group1, cat_col2, cat_vals2, name_group2, correction)\n",
    "    elif hypo_test == \"Equal variance between two groups\":\n",
    "        return variance_test(numeric_col, cat_col1, cat_vals1, name_group1, cat_col2, cat_vals2, name_group2, test_type, graph_check, bootstrap_samples)\n",
    "    elif hypo_test == \"One-way ANOVA\":\n",
    "        return one_way_anova(numeric_col, cat_col3, cat_vals3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bcc2acf",
   "metadata": {},
   "source": [
    "# üñ•Ô∏è üß™ GUI of Hypothesis Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6ba6208d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_hypothesis_tab():\n",
    "    with gr.Group():\n",
    "        gr.Markdown(\"# üß™ Hypothesis Testing\")\n",
    "\n",
    "        with gr.Row(elem_id=\"row_centered\"):\n",
    "            refresh_columns_button = gr.Button(\"üîÑ Refresh Numeric Columns\")\n",
    "            column_dropdown = gr.Dropdown(label=\"Select Numeric Column\", choices=[], interactive=True, elem_classes=\"data_related\", elem_id=\"custom_dropdown\")\n",
    "            \n",
    "            hypo_test_dropdown = gr.Dropdown(\n",
    "                label=\"Type of Hypothesis\",\n",
    "                choices=[\n",
    "                    \"One sample Student's t-test\",\n",
    "                    \"Equal variance between two groups\",\n",
    "                    \"Two samples Student's t-test\",\n",
    "                    \"One-way ANOVA\"\n",
    "                ],\n",
    "                value=\"One sample Student's t-test\",\n",
    "                interactive=True\n",
    "            )\n",
    "\n",
    "            mu0_input = gr.Textbox(label=\"Œº‚ÇÄ (Null Hypothesis Mean)\", value=\"\", visible=True)\n",
    "            alternative = gr.Radio(label=\"Alternative hypothesis\", choices=[\"two-sided\", \"greater\", \"less\"], value=\"two-sided\", interactive=True, visible=True)\n",
    "            ttest_correction_check = gr.Checkbox(label=\"Correct for unequal variances (Welch's t-test)\", value=True, visible=False)\n",
    "            equal_var_dropdown = gr.Dropdown(label=\"Select Variance Test\", choices=[\"Bartlett\", \"Levene\"], value=\"Levene\", visible=False)\n",
    "\n",
    "        with gr.Row() as ttest_graph_option:\n",
    "            ttest_graph_check = gr.Checkbox(label=\"Include graph\", value=True, interactive=True)\n",
    "            ttest_boots_sample = gr.Slider(minimum=100, maximum=5000, value=1000, step=100, label=\"Bootstrap Samples\")\n",
    "\n",
    "        with gr.Group(visible=False) as category_group:\n",
    "            refresh_categorical_button = gr.Button(\"üîÑ Refresh Categorical Columns\")\n",
    "\n",
    "            with gr.Row() as group1:\n",
    "                cat_column_dropdown_1 = gr.Dropdown(label=\"Categorical Column 1\", choices=[], elem_classes=\"data_related\", elem_id=\"custom_dropdown\")\n",
    "                cat_values_dropdown_1 = gr.Dropdown(label=\"Categories for Column 1\", multiselect=True, choices=[], interactive=True, elem_classes=\"data_related\", elem_id=\"custom_dropdown\")\n",
    "                name_group1 = gr.Textbox(label=\"Name of Group 1\", value=\"Group 1\", visible=True, interactive=True)\n",
    "\n",
    "            with gr.Row() as group2:\n",
    "                cat_column_dropdown_2 = gr.Dropdown(label=\"Categorical Column 2\", choices=[], elem_classes=\"data_related\", elem_id=\"custom_dropdown\")\n",
    "                cat_values_dropdown_2 = gr.Dropdown(label=\"Categories for Column 2\", multiselect=True, choices=[], interactive=True, elem_classes=\"data_related\", elem_id=\"custom_dropdown\")\n",
    "                name_group2 = gr.Textbox(label=\"Name of Group 2\", value=\"Group 2\", visible=True, interactive=True)\n",
    "\n",
    "            with gr.Row() as group_anova:\n",
    "                cat_column_dropdown_3 = gr.Dropdown(label=\"Categorical Column\", choices=[], elem_classes=\"data_related\", elem_id=\"custom_dropdown\")\n",
    "                cat_values_dropdown_3 = gr.Dropdown(label=\"Categories for Column\", multiselect=True, choices=[], interactive=True, elem_classes=\"data_related\", elem_id=\"custom_dropdown\")\n",
    "\n",
    "    run_hypo_test_button = gr.Button(value=\" üöÄ Run Hypothesis Testing\")\n",
    "\n",
    "    # --- Results ---\n",
    "    output_table_group, output_table, output_plot_group, output_plot = build_results_block(False, False)\n",
    "\n",
    "    # --- Modify behavior of components of the GUI ---\n",
    "    hypo_test_dropdown.change(\n",
    "        fn=toggle_hypo_test,\n",
    "        inputs=[hypo_test_dropdown],\n",
    "        outputs=[mu0_input, alternative, ttest_graph_option, ttest_correction_check, equal_var_dropdown, category_group, group1, group2, group_anova]\n",
    "    )\n",
    "\n",
    "    refresh_columns_button.click(\n",
    "        fn=load_numeric_cols,\n",
    "        inputs=[],\n",
    "        outputs=[column_dropdown]\n",
    "    )\n",
    "\n",
    "    ttest_graph_check.change(\n",
    "        fn=lambda check: gr.update(visible=check),\n",
    "        inputs=[ttest_graph_check],\n",
    "        outputs=[ttest_boots_sample],\n",
    "    )\n",
    "\n",
    "    refresh_categorical_button.click(\n",
    "        fn=refresh_categorical_columns,\n",
    "        outputs=[\n",
    "            cat_column_dropdown_1,\n",
    "            cat_column_dropdown_2,\n",
    "            cat_column_dropdown_3,\n",
    "            cat_values_dropdown_1,\n",
    "            cat_values_dropdown_2,\n",
    "            cat_values_dropdown_3\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    cat_column_dropdown_1.change(\n",
    "        fn=update_category_options,\n",
    "        inputs=[cat_column_dropdown_1],\n",
    "        outputs=[cat_values_dropdown_1]\n",
    "    )\n",
    "\n",
    "    cat_column_dropdown_2.change(\n",
    "        fn=update_category_options,\n",
    "        inputs=[cat_column_dropdown_2],\n",
    "        outputs=[cat_values_dropdown_2]\n",
    "    )\n",
    "\n",
    "    cat_column_dropdown_3.change(\n",
    "        fn=update_category_options,\n",
    "        inputs=[cat_column_dropdown_3],\n",
    "        outputs=[cat_values_dropdown_3]\n",
    "    )\n",
    "\n",
    "    cat_values_dropdown_1.change(\n",
    "        fn=update_group_name,\n",
    "        inputs=[cat_values_dropdown_1, name_group1, gr.State(\"Group 1\")],\n",
    "        outputs=name_group1\n",
    "    )\n",
    "\n",
    "    cat_values_dropdown_2.change(\n",
    "        fn=update_group_name,\n",
    "        inputs=[cat_values_dropdown_2, name_group2, gr.State(\"Group 2\")],\n",
    "        outputs=name_group2\n",
    "    )\n",
    "\n",
    "    # --- Run Analysis Button ---\n",
    "    run_hypo_test_button.click(\n",
    "        fn=run_hypothesis_testing,\n",
    "        inputs=[\n",
    "            column_dropdown,\n",
    "            hypo_test_dropdown,\n",
    "            mu0_input,\n",
    "            alternative,\n",
    "            ttest_graph_check, ttest_boots_sample,\n",
    "            cat_column_dropdown_1, cat_values_dropdown_1, name_group1,\n",
    "            cat_column_dropdown_2, cat_values_dropdown_2, name_group2,\n",
    "            cat_column_dropdown_3, cat_values_dropdown_3,\n",
    "            ttest_correction_check,\n",
    "            equal_var_dropdown\n",
    "        ],\n",
    "        outputs=[output_table_group, output_table, output_plot_group, output_plot]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de26827f",
   "metadata": {},
   "source": [
    "# üß† üìà Brain of Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "93432bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def PlotSimpleRegression(data, x, y, intercept, formula_check, formula_latex, model, alpha, show_ci, show_pi, fit_to_obs, x_vect):\n",
    "\n",
    "    # Prepare prediction input\n",
    "    if fit_to_obs:\n",
    "        data = data.copy().sort_values(x).reset_index(drop=True)\n",
    "        x_plot = data[x]\n",
    "        X_pred = data[[x]]\n",
    "    else:\n",
    "        x_plot = x_vect\n",
    "        X_pred = pd.DataFrame({x: x_vect})\n",
    "\n",
    "    # Add intercept if needed\n",
    "    if intercept:\n",
    "        X_pred = sm.add_constant(X_pred)\n",
    "\n",
    "    # Get predictions and intervals\n",
    "    pred_table = model.get_prediction(X_pred).summary_frame(alpha=alpha)\n",
    "\n",
    "    # --- Plotting ---\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(8, 5.5))\n",
    "    # Scatter plot of data\n",
    "    sns.scatterplot(data=data, x=x, y=y, ax=ax,\n",
    "                    s=50, edgecolor=\"black\", linewidth=0.5,\n",
    "                    zorder=3, label=\"Data\")\n",
    "\n",
    "    # Regression line\n",
    "    ax.plot(x_plot, pred_table[\"mean\"], color=\"royalblue\", linewidth=2, label=\"Prediction\")\n",
    "\n",
    "    # Confidence interval\n",
    "    if show_ci:\n",
    "        ax.fill_between(\n",
    "            x_plot,\n",
    "            pred_table[\"mean_ci_lower\"],\n",
    "            pred_table[\"mean_ci_upper\"],\n",
    "            color=\"pink\",\n",
    "            alpha=0.5,\n",
    "            label=\"Confidence Interval (mean)\"\n",
    "        )\n",
    "\n",
    "    # Prediction interval\n",
    "    if show_pi:\n",
    "        ax.fill_between(\n",
    "            x_plot,\n",
    "            pred_table[\"obs_ci_lower\"],\n",
    "            pred_table[\"obs_ci_upper\"],\n",
    "            color=\"mediumpurple\",\n",
    "            alpha=0.4,\n",
    "            label=\"Prediction Interval (new obs)\"\n",
    "        )\n",
    "\n",
    "    # Highlight extrapolation region (if applicable)\n",
    "    if not fit_to_obs:\n",
    "        xmin, xmax = data[x].min(), data[x].max()\n",
    "        ax.axvspan(x_vect[0], xmin, color=\"gray\", alpha=0.1)\n",
    "        ax.axvspan(xmax, x_vect[-1], color=\"gray\", alpha=0.1)\n",
    "\n",
    "    # Title with formula\n",
    "    if formula_check:\n",
    "        if formula_latex:\n",
    "            ax.set_title(f\"Linear Regression: ${formula_latex}$\", fontsize=14)\n",
    "        else:\n",
    "            ax.set_title(f\"Linear Regression: {y} ~ {x}\", fontsize=14)\n",
    "    else:\n",
    "        ax.set_title(f\"Linear Regression: {y} ~ {x}\", fontsize=14)\n",
    "\n",
    "    # R-squared annotation\n",
    "    r2 = model.rsquared\n",
    "    ax.text(0.05, 0.95, f\"$R^2 = {r2:.3f}$\", transform=ax.transAxes,\n",
    "            ha=\"left\", va=\"top\", fontsize=11,\n",
    "            bbox=dict(boxstyle=\"round\", facecolor=\"white\", alpha=0.8))\n",
    "\n",
    "    # Axis labels\n",
    "    ax.set_xlabel(x, fontsize=12)\n",
    "    ax.set_ylabel(y, fontsize=12)\n",
    "\n",
    "    # Deduplicate legend\n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    by_label = dict(zip(labels, handles))\n",
    "    ax.legend(by_label.values(), by_label.keys(), frameon=False)\n",
    "\n",
    "    ax.grid(True, linestyle=\"--\", alpha=0.3)\n",
    "    \n",
    "    return fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4a96ae91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def PlotCompareYHatY(data, y, model, alpha):\n",
    "    pred_table = model.get_prediction().summary_frame(alpha=alpha)\n",
    "    y_true = data[y]\n",
    "    y_pred = pred_table[\"mean\"]\n",
    "    y_err = pred_table[\"obs_ci_upper\"] - y_pred\n",
    "\n",
    "    residuals = y_true - y_pred\n",
    "    abs_residuals = np.abs(residuals)\n",
    "    max_error = np.max(abs_residuals)\n",
    "\n",
    "    # Create figure\n",
    "    fig, ax = plt.subplots(figsize=(7.5, 5.5))\n",
    "\n",
    "    # Scatter with residual magnitude color-coded, fixed color scale\n",
    "    sc = ax.scatter(\n",
    "        y_true,\n",
    "        y_pred,\n",
    "        c=abs_residuals,\n",
    "        cmap=\"Reds\",\n",
    "        vmin=0,\n",
    "        vmax=max_error,\n",
    "        edgecolor=\"black\",\n",
    "        alpha=0.6,\n",
    "        s=60,\n",
    "        label=\"Predicted vs Observed\",\n",
    "        zorder=3\n",
    "    )\n",
    "\n",
    "    # Error bars\n",
    "    ax.errorbar(\n",
    "        y_true,\n",
    "        y_pred,\n",
    "        yerr=y_err,\n",
    "        fmt=\"none\",\n",
    "        ecolor=\"gray\",\n",
    "        elinewidth=1,\n",
    "        alpha=0.4,\n",
    "        capsize=3,\n",
    "        zorder=1\n",
    "    )\n",
    "\n",
    "    # Reference line\n",
    "    min_val = min(y_true.min(), y_pred.min())\n",
    "    max_val = max(y_true.max(), y_pred.max())\n",
    "    buffer = 0.05 * (max_val - min_val)\n",
    "    ax.plot([min_val, max_val], [min_val, max_val], 'r--', label=\"Perfect Fit\", zorder=2)\n",
    "    ax.set_xlim(min_val - buffer, max_val + buffer)\n",
    "    ax.set_ylim(min_val - buffer, max_val + buffer)\n",
    "\n",
    "    # Title, labels, R¬≤\n",
    "    ax.set_title(\"Observed vs Predicted\", fontsize=14)\n",
    "    ax.set_xlabel(f\"Observed {y}\", fontsize=12)\n",
    "    ax.set_ylabel(f\"Predicted {y}\", fontsize=12)\n",
    "    r2 = model.rsquared\n",
    "    ax.text(0.05, 0.95, f\"$R^2 = {r2:.3f}$\",\n",
    "            transform=ax.transAxes,\n",
    "            ha=\"left\", va=\"top\",\n",
    "            fontsize=11,\n",
    "            bbox=dict(boxstyle=\"round\", facecolor=\"white\", alpha=0.7))\n",
    "\n",
    "    # Colorbar with same scale\n",
    "    cbar = plt.colorbar(sc, ax=ax)\n",
    "    cbar.set_label(\"|Residual|\", rotation=270, labelpad=15)\n",
    "\n",
    "    # Legend and grid\n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    ax.legend(handles, labels, frameon=False)\n",
    "    ax.grid(True, linestyle=\"--\", alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    return fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "06ec4655",
   "metadata": {},
   "outputs": [],
   "source": [
    "def PlotCompareYHatY(data, y, model, alpha=0.05):\n",
    "    pred_table = model.get_prediction().summary_frame(alpha=alpha)\n",
    "    y_true = data[y]\n",
    "    y_pred = pred_table[\"mean\"]\n",
    "    y_err = pred_table[\"obs_ci_upper\"] - y_pred\n",
    "\n",
    "    residuals = y_true - y_pred  # Signed residuals (can use abs below)\n",
    "\n",
    "    # Create figure\n",
    "    fig, ax = plt.subplots(figsize=(7.5, 5.5))\n",
    "\n",
    "    # Scatter plot with sequential colormap (residual magnitude)\n",
    "    sc = ax.scatter(\n",
    "        y_true,\n",
    "        y_pred,\n",
    "        c=np.abs(residuals),\n",
    "        cmap=\"Reds\",  # Sequential colormap\n",
    "        edgecolor=\"black\",\n",
    "        alpha=0.6,\n",
    "        s=60,\n",
    "        label=\"Predicted vs Observed\",\n",
    "        zorder=3\n",
    "    )\n",
    "\n",
    "    # Error bars\n",
    "    ax.errorbar(\n",
    "        y_true,\n",
    "        y_pred,\n",
    "        yerr=y_err,\n",
    "        fmt=\"none\",\n",
    "        ecolor=\"gray\",\n",
    "        elinewidth=1,\n",
    "        alpha=0.4,\n",
    "        capsize=3,\n",
    "        zorder=1\n",
    "    )\n",
    "\n",
    "    # Reference line (perfect prediction)\n",
    "    min_val = min(y_true.min(), y_pred.min())\n",
    "    max_val = max(y_true.max(), y_pred.max())\n",
    "    buffer = 0.05 * (max_val - min_val)\n",
    "    ax.plot([min_val, max_val], [min_val, max_val], 'r--', label=\"Perfect Fit\", zorder=2)\n",
    "    ax.set_xlim(min_val - buffer, max_val + buffer)\n",
    "    ax.set_ylim(min_val - buffer, max_val + buffer)\n",
    "\n",
    "    # Labels and title\n",
    "    ax.set_title(\"Observed vs Predicted\", fontsize=14)\n",
    "    ax.set_xlabel(f\"Observed {y}\", fontsize=12)\n",
    "    ax.set_ylabel(f\"Predicted {y}\", fontsize=12)\n",
    "\n",
    "    # R-squared\n",
    "    r2 = model.rsquared\n",
    "    ax.text(0.05, 0.95, f\"$R^2 = {r2:.3f}$\",\n",
    "            transform=ax.transAxes,\n",
    "            ha=\"left\", va=\"top\",\n",
    "            fontsize=11,\n",
    "            bbox=dict(boxstyle=\"round\", facecolor=\"white\", alpha=0.7))\n",
    "\n",
    "    # Colorbar\n",
    "    cbar = plt.colorbar(sc, ax=ax)\n",
    "    cbar.set_label(\"|Residual|\", rotation=270, labelpad=15)\n",
    "\n",
    "    # Legend\n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    ax.legend(handles, labels, frameon=False)\n",
    "    ax.grid(True, linestyle=\"--\", alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    return fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "10ed386c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_regression(\n",
    "        formula_check,\n",
    "        formula_text,\n",
    "        formula_latex,\n",
    "        dependent_var,\n",
    "        independent_vars,\n",
    "        alpha_input,\n",
    "        intercept,\n",
    "        graph_check,\n",
    "        graph_type,\n",
    "        show_ci,\n",
    "        show_pi,\n",
    "        fit_to_obs,\n",
    "        range_text):\n",
    "\n",
    "    # --- Read data and validate ---\n",
    "    original_df = df_cache.get(\"df\")\n",
    "    filtered_df = df_cache.get(\"filtered_df\")\n",
    "\n",
    "    if original_df is None:\n",
    "        return gr.update(visible=True), \"<b>Error:</b> No dataset loaded.\", gr.update(visible=False), None\n",
    "\n",
    "    # --- Use filtered data if it differs from original ---\n",
    "    df = filtered_df if filtered_df is not None and not filtered_df.equals(original_df) else original_df\n",
    "\n",
    "    alpha = parse_text(alpha_input)\n",
    "    alpha = 1 - alpha\n",
    "    if alpha is None or not (0 < alpha < 1):\n",
    "        return gr.update(visible=True), \"<b>Error:</b> Invalid alpha value.\", gr.update(visible=False), None\n",
    "\n",
    "    # Check variable validity\n",
    "    if dependent_var not in df.columns or not all(col in df.columns for col in independent_vars):\n",
    "        return gr.update(visible=True), \"<b>Error:</b> Invalid variable selection.\", gr.update(visible=False), None\n",
    "\n",
    "    # Drop rows with missing data\n",
    "    data = df[[dependent_var] + independent_vars].dropna()\n",
    "    y = data[dependent_var]\n",
    "    X = data[independent_vars]\n",
    "    try:\n",
    "        if formula_check:\n",
    "            try:\n",
    "                model = smf.ols(data=data, formula=formula_text).fit()\n",
    "            except Exception as e:\n",
    "                return gr.update(visible=True), f\"<b>‚ùå Please enter a valid regression formula:</b> {e}\", gr.update(visible=False), None\n",
    "        else:\n",
    "            if intercept:\n",
    "                X = sm.add_constant(X)\n",
    "            model = sm.OLS(y, X).fit()\n",
    "\n",
    "        summary = model.summary2(alpha=alpha)\n",
    "        summary_html = summary.as_html()\n",
    "        df_output = summary.tables[1].round(ROUND).reset_index().rename({\"index\":\"Variable\"}, axis=1)\n",
    "        \n",
    "    except Exception as e:\n",
    "        df_output = None\n",
    "        return gr.update(visible=True), f\"<b>Regression failed:</b> {e}\", gr.update(visible=False), None\n",
    "\n",
    "    # Only plot if 1 independent variable\n",
    "    fig = None\n",
    "\n",
    "    if graph_check:\n",
    "        if graph_type == \"Simple Regression\":\n",
    "            x_col = independent_vars[0]\n",
    "\n",
    "            if not range_text:\n",
    "                x_vect = None\n",
    "            else:\n",
    "                x_min, x_max = [float(val.strip()) for val in range_text.split(\",\")]\n",
    "                x_vect = np.linspace(x_min, x_max, 100)\n",
    "                \n",
    "            fig = PlotSimpleRegression(\n",
    "                data, x_col, dependent_var, intercept, formula_check, formula_latex,\n",
    "                model, alpha, show_ci, show_pi, fit_to_obs, x_vect\n",
    "            )\n",
    "\n",
    "        elif graph_type == \"Observed vs Predicted\":\n",
    "            fig = PlotCompareYHatY(data, dependent_var, model, alpha)\n",
    "\n",
    "    export_cache[\"table\"] = df_output\n",
    "    export_cache[\"figure\"] = fig\n",
    "\n",
    "    return gr.update(visible=True), summary_html, gr.update(visible=True), fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e410c11",
   "metadata": {},
   "source": [
    "# üéÆ üìà Logic control of Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "30ec32b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_graph_choices(independent_vars):\n",
    "    if len(independent_vars) == 1:\n",
    "        return gr.update(choices=[\"Simple Regression\", \"Observed vs Predicted\"], value=\"Simple Regression\")\n",
    "    else:\n",
    "        return gr.update(choices=[\"Observed vs Predicted\"], value=\"Observed vs Predicted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "073b91bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def toggle_graph_reg(sel, fit_to_obs):\n",
    "    if sel == \"Simple Regression\":\n",
    "        return [\n",
    "            gr.update(visible=True), # show_ci_check\n",
    "            gr.update(visible=True), # show_pi_check\n",
    "            gr.update(visible=True, value=fit_to_obs) # fit_to_obs\n",
    "        ]\n",
    "    elif sel == \"Observed vs Predicted\":\n",
    "        return [\n",
    "            gr.update(visible=False),\n",
    "            gr.update(visible=False),\n",
    "            gr.update(visible=False, value=True)\n",
    "        ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbfea3e2",
   "metadata": {},
   "source": [
    "# üñ•Ô∏è üìà GUI of Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e48d978b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_regression_tab():\n",
    "    with gr.Group():\n",
    "        gr.Markdown(\"# üìà Linear Regression\")\n",
    "\n",
    "        with gr.Row(elem_id=\"row_centered\"):\n",
    "            refresh_columns_button = gr.Button(\"üîÑ Refresh Numeric Columns\")\n",
    "            dependent_dropdown = gr.Dropdown(label=\"Dependent Variable\", choices=[], interactive=True, elem_classes=\"data_related\", elem_id=\"custom_dropdown\")\n",
    "            independent_dropdown = gr.Dropdown(label=\"Independent Variable(s)\", multiselect=True, choices=[], interactive=True, elem_classes=\"data_related\", elem_id=\"custom_dropdown\")\n",
    "        \n",
    "        with gr.Row():\n",
    "            formula_check = gr.Checkbox(label=\"Would you like to write down the regression formula?\", value=False, interactive=True)\n",
    "            formula_text = gr.Textbox(label=\"Write the formula\", placeholder=\"Y ~ X + np.sin(X) + I((X-5)**2)\", interactive=True, visible=False)\n",
    "            formula_latex = gr.Textbox(label=\"Write the formula in LaTeX (Optional)\", placeholder=\"Y = X + \\sin(X) + (X-5)^2\", interactive=True, visible=False)\n",
    "\n",
    "        with gr.Row():\n",
    "            alpha_input = gr.Textbox(label=\"Confidence level (e.g. 0.95)\", value=0.95, interactive=True)\n",
    "            intercept_check = gr.Checkbox(label=\"Include intercept\", value=True, interactive=True)\n",
    "            graph_check = gr.Checkbox(label=\"Create graph\", value=True, interactive=True)\n",
    "            \n",
    "        with gr.Row() as graph_options:\n",
    "            graph_dropdown = gr.Dropdown(label=\"Graph\", choices=[\"Simple Regression\", \"Observed vs Predicted\"], interactive=True)\n",
    "            show_ci_check = gr.Checkbox(label=\"Include CI\", value=True, interactive=True)\n",
    "            show_pi_check = gr.Checkbox(label=\"Include PI\", value=True, interactive=True)\n",
    "            fit_to_obs_check = gr.Checkbox(label=\"Fit to observations\", value=True, interactive=True)\n",
    "            x_vect_input = gr.Textbox(label=\"Minimum and maximum of dependent variable \", value=\"\", visible=False, interactive=True)\n",
    "\n",
    "    run_regression_button = gr.Button(value=\" üöÄ Run Linear Regression\")\n",
    "\n",
    "    # --- Results ---\n",
    "    output_table_group, output_table, output_plot_group, output_plot = build_results_block_2(False, False)\n",
    "\n",
    "    # --- Modify behavior of components of the GUI ---\n",
    "    formula_check.change(\n",
    "        fn=lambda check: 2*[gr.update(visible=check)] + [gr.update(visible=not check, value=not check)],\n",
    "        inputs=[formula_check],\n",
    "        outputs=[formula_text, formula_latex, intercept_check]\n",
    "    )\n",
    "\n",
    "    refresh_columns_button.click(\n",
    "        fn=load_numeric_cols,\n",
    "        inputs=[],\n",
    "        outputs=[dependent_dropdown]\n",
    "    )\n",
    "\n",
    "    refresh_columns_button.click(\n",
    "        fn=load_numeric_cols,\n",
    "        inputs=[],\n",
    "        outputs=[independent_dropdown]\n",
    "    )\n",
    "\n",
    "    independent_dropdown.change(\n",
    "        fn=update_graph_choices,\n",
    "        inputs=[independent_dropdown],\n",
    "        outputs=[graph_dropdown]\n",
    "    )\n",
    "\n",
    "    graph_check.change(\n",
    "        fn=lambda check: gr.update(visible=check),\n",
    "        inputs=[graph_check],\n",
    "        outputs=[graph_options]\n",
    "    )\n",
    "\n",
    "    graph_dropdown.change(\n",
    "        fn=toggle_graph_reg,\n",
    "        inputs=[graph_dropdown, fit_to_obs_check],\n",
    "        outputs=[show_ci_check, show_pi_check, fit_to_obs_check]\n",
    "    )\n",
    "\n",
    "    fit_to_obs_check.change(\n",
    "        fn=lambda check: gr.update(visible=not check),\n",
    "        inputs=[fit_to_obs_check],\n",
    "        outputs=[x_vect_input]\n",
    "    )\n",
    "\n",
    "    # --- Run Analysis Button ---\n",
    "    run_regression_button.click(\n",
    "        fn=linear_regression,\n",
    "        inputs=[\n",
    "            formula_check, formula_text, formula_latex,\n",
    "            dependent_dropdown, independent_dropdown,\n",
    "            alpha_input, intercept_check,\n",
    "            graph_check, graph_dropdown, show_ci_check, show_pi_check,\n",
    "            fit_to_obs_check, x_vect_input\n",
    "        ],\n",
    "        outputs=[output_table_group, output_table, output_plot_group, output_plot]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff8d6205",
   "metadata": {},
   "source": [
    "# üñ•Ô∏è GUI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4b391ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "css = \"\"\"\n",
    ".data_related li{color: orange}\n",
    "#custom_dropdown [data-testid=\"block-info\"] {\n",
    "    color: orange;\n",
    "    /* font-weight: bold; */\n",
    "}\n",
    "\n",
    "#custom_dropdown input {\n",
    "    color: orange; /* !important; */\n",
    "    /* font-weight: bold; */\n",
    "}\n",
    "\n",
    "#row_centered { \n",
    "    align-items: center;\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "63520ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with gr.Blocks(theme=gr.themes.Soft(), css=css) as demo:\n",
    "    with gr.Tabs():\n",
    "        with gr.TabItem(\"üóÑÔ∏è Data\"):\n",
    "            build_data_tab()\n",
    "        with gr.TabItem(\"üìê Estimation\"):\n",
    "            with gr.Tabs():    \n",
    "                with gr.TabItem(\"üìä Graphical Analysis\"):\n",
    "                    build_graphical_tab()\n",
    "                with gr.TabItem(\"üßÆ Descriptive Analysis\"):\n",
    "                    build_descriptive_tab()\n",
    "                with gr.TabItem(\"üí≠ Statistical Inference\"):\n",
    "                    build_inference_tab()\n",
    "        with gr.TabItem(\"üß™ Hypothesis Testing\"):\n",
    "            build_hypothesis_tab()\n",
    "        with gr.TabItem(\"üìà Linear Regression\"):\n",
    "            build_regression_tab()\n",
    "        #with gr.TabItem(\"üíÄ Survival Analysis\"):\n",
    "        #    gr.Markdown(\"# üöß Upcoming\")\n",
    "        #with gr.TabItem(\"‚åö Time Series\"):\n",
    "        #    gr.Markdown(\"# üöß Upcoming\")\n",
    "        #with gr.TabItem(\"üó∫Ô∏è Spatial Analysis\"):\n",
    "        #    gr.Markdown(\"# üöß Upcoming\")\n",
    "        #with gr.TabItem(\"üè≠ Industrial Statistics\"):\n",
    "        #    gr.Markdown(\"# üöß Upcoming\")\n",
    "        #with gr.TabItem(\"üÖ±Ô∏è Bayesian Statistics\"):\n",
    "        #    gr.Markdown(\"# üöß Upcoming\")\n",
    "\n",
    "    gr.Markdown(\"### ü§ì Created by Irving G√≥mez M√©ndez, version 3.2.2, June 2025.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ffafe234",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Dmitri\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\gradio\\queueing.py\", line 625, in process_events\n",
      "    response = await route_utils.call_process_api(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Dmitri\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\gradio\\route_utils.py\", line 322, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Dmitri\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\gradio\\blocks.py\", line 2136, in process_api\n",
      "    result = await self.call_function(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Dmitri\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\gradio\\blocks.py\", line 1662, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(  # type: ignore\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Dmitri\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\anyio\\to_thread.py\", line 56, in run_sync\n",
      "    return await get_async_backend().run_sync_in_worker_thread(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Dmitri\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\anyio\\_backends\\_asyncio.py\", line 2470, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Dmitri\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\anyio\\_backends\\_asyncio.py\", line 967, in run\n",
      "    result = context.run(func, *args)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Dmitri\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\gradio\\utils.py\", line 884, in wrapper\n",
      "    response = f(*args, **kwargs)\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Dmitri\\AppData\\Local\\Temp\\ipykernel_143572\\500632540.py\", line 13, in run_stat_inf\n",
      "    if error_df:\n",
      "  File \"C:\\Users\\Dmitri\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\generic.py\", line 1577, in __nonzero__\n",
      "    raise ValueError(\n",
      "ValueError: The truth value of a DataFrame is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Dmitri\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\gradio\\queueing.py\", line 625, in process_events\n",
      "    response = await route_utils.call_process_api(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Dmitri\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\gradio\\route_utils.py\", line 322, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Dmitri\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\gradio\\blocks.py\", line 2136, in process_api\n",
      "    result = await self.call_function(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Dmitri\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\gradio\\blocks.py\", line 1662, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(  # type: ignore\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Dmitri\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\anyio\\to_thread.py\", line 56, in run_sync\n",
      "    return await get_async_backend().run_sync_in_worker_thread(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Dmitri\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\anyio\\_backends\\_asyncio.py\", line 2470, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Dmitri\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\anyio\\_backends\\_asyncio.py\", line 967, in run\n",
      "    result = context.run(func, *args)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Dmitri\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\gradio\\utils.py\", line 884, in wrapper\n",
      "    response = f(*args, **kwargs)\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Dmitri\\AppData\\Local\\Temp\\ipykernel_143572\\500632540.py\", line 24, in run_stat_inf\n",
      "    hat_mean = choose_mu(mean_select, stats, mean_estimate_text)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Dmitri\\AppData\\Local\\Temp\\ipykernel_143572\\3098279144.py\", line 3, in choose_mu\n",
      "    hat_mu = stats.mean\n",
      "             ^^^^^^^^^^\n",
      "AttributeError: 'Statistics' object has no attribute 'mean'\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Dmitri\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\gradio\\queueing.py\", line 625, in process_events\n",
      "    response = await route_utils.call_process_api(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Dmitri\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\gradio\\route_utils.py\", line 322, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Dmitri\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\gradio\\blocks.py\", line 2136, in process_api\n",
      "    result = await self.call_function(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Dmitri\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\gradio\\blocks.py\", line 1662, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(  # type: ignore\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Dmitri\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\anyio\\to_thread.py\", line 56, in run_sync\n",
      "    return await get_async_backend().run_sync_in_worker_thread(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Dmitri\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\anyio\\_backends\\_asyncio.py\", line 2470, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Dmitri\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\anyio\\_backends\\_asyncio.py\", line 967, in run\n",
      "    result = context.run(func, *args)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Dmitri\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\gradio\\utils.py\", line 884, in wrapper\n",
      "    response = f(*args, **kwargs)\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Dmitri\\AppData\\Local\\Temp\\ipykernel_143572\\500632540.py\", line 24, in run_stat_inf\n",
      "    hat_mean = choose_mu(mean_select, stats, mean_estimate_text)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Dmitri\\AppData\\Local\\Temp\\ipykernel_143572\\3098279144.py\", line 3, in choose_mu\n",
      "    hat_mu = stats.mean\n",
      "             ^^^^^^^^^^\n",
      "AttributeError: 'Statistics' object has no attribute 'mean'\n"
     ]
    }
   ],
   "source": [
    "demo.launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
