{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21f60193",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# To plot\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# To create GUI\n",
    "import gradio as gr\n",
    "\n",
    "# To integrate a function\n",
    "from scipy import integrate\n",
    "\n",
    "# Gamma function\n",
    "from scipy.special import gamma\n",
    "\n",
    "# To calculate statistics\n",
    "from scipy.stats import norm, t, chi2\n",
    "from scipy.stats import hmean, trim_mean, iqr, median_abs_deviation, skew, kurtosis\n",
    "from scipy.stats.mstats import gmean, winsorize\n",
    "from statsmodels.distributions import ECDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b49df773",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROUND = 4 # Number of decimals to round the results\n",
    "\n",
    "df_cache = {\n",
    "    \"df\": None,\n",
    "    \"filtered_df\": None,\n",
    "    \"stats\": None,\n",
    "    \"numeric_cols\": [],\n",
    "    \"categorical_cols\": [],\n",
    "    \"overrides\": {\n",
    "        \"num_to_cat\": [],\n",
    "        \"cat_to_num\": []\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a4c315",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cac4b5c",
   "metadata": {},
   "source": [
    "## Statistics class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dea68472",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Statistics():\n",
    "    def __init__(self, data):\n",
    "        self.data = data    \n",
    "        self.n = len(data)  \n",
    "\n",
    "    # --- Descriptive Statistics ---    \n",
    "\n",
    "    # --- Quantiles ---\n",
    "    def CalculateQuantiles(self, prob):\n",
    "        if type(prob) is list:\n",
    "            self.quantiles = pd.DataFrame({'Value': np.quantile(self.data, prob)}, ['Q{}'.format(p) for p in prob])\n",
    "        else:\n",
    "            self.quantiles = pd.DataFrame({'Value': np.quantile(self.data, prob)}, ['Q{}'.format(prob)])\n",
    "\n",
    "    # --- Quartiles ---\n",
    "    def CalculateQuartiles(self):\n",
    "        self.quartiles = pd.DataFrame({'Value': np.quantile(self.data, [0.25,0.5,0.75])},['Q1', 'Q2', 'Q3'])\n",
    "\n",
    "    # --- Central Tendency ---\n",
    "    def CalculateCentralTendency(self, trim_param=0.1, winsor_param=[0.1,0.1], weights=None):\n",
    "\n",
    "        #Mode = mode(data) # To calculate the mode \n",
    "        self.mean = self.data.mean()\n",
    "        self.median = np.median(self.data)\n",
    "        self.interquartile_mean = trim_mean(self.data, 0.25)\n",
    "        \n",
    "        if trim_param is None:\n",
    "            self.trimmed_mean = np.nan\n",
    "        else:\n",
    "            self.trimmed_mean = trim_mean(self.data, trim_param)\n",
    "\n",
    "        if winsor_param is None:\n",
    "            self.winsorized_mean = np.nan\n",
    "        else:\n",
    "            # Winsorized data\n",
    "            data_winsorized = winsorize(self.data, winsor_param)\n",
    "            self.winsorized_mean = data_winsorized.mean()\n",
    "            \n",
    "        if np.all(self.data > 0): # If all observations are greater than zero, calculate geometric and harmonic mean\n",
    "            self.geometric_mean = gmean(self.data)\n",
    "            self.harmonic_mean = hmean(self.data)\n",
    "        else:\n",
    "            self.geometric_mean = np.nan\n",
    "            self.harmonic_mean = np.nan\n",
    "\n",
    "        if weights is None:\n",
    "            self.weighted_mean = np.nan\n",
    "        else:\n",
    "            self.weighted_mean = np.average(self.data, weights=weights)\n",
    "\n",
    "        # Write the statistics in a list\n",
    "        central_tendency = [\n",
    "            self.mean,\n",
    "            self.median,\n",
    "            self.geometric_mean,\n",
    "            self.harmonic_mean,\n",
    "            self.weighted_mean,\n",
    "            self.trimmed_mean,\n",
    "            self.interquartile_mean,\n",
    "            self.winsorized_mean\n",
    "        ]\n",
    "\n",
    "        # Return the statistics as a table\n",
    "        labels = ['Mean', 'Median', 'Geometric Mean', 'Harmonic Mean', 'Weighted Mean', 'Trimmed Mean', 'Interquartile Mean', 'Winsorized Mean']\n",
    "        self.central_tendency = pd.DataFrame({'Value':central_tendency, 'Robust':[1, 0, 0, 0, 0, 1, 1, 1]}, labels)\n",
    "\n",
    "    # --- Dispersion ---\n",
    "    # Auxiliary functions to correct the bias\n",
    "    def c4(self, n):\n",
    "        return np.sqrt(2/(n-1)) * gamma(n/2) / gamma((n-1)/2)\n",
    "\n",
    "    def d2(self, n):\n",
    "        f = lambda x, n: 1 - (1 - norm.cdf(x))**n - (norm.cdf(x))**n\n",
    "        return round(integrate.quad(f, -np.inf, np.inf, args=(n,))[0], 3)\n",
    "    \n",
    "    def CalculateDispersion(self):\n",
    "        # Original estimators\n",
    "        self.S0 = np.std(self.data)             # By default the standard deviation is calculated with zero degrees of freedom\n",
    "        self.S1 = np.std(self.data, ddof=1)     # Standard deviation with one degree of freedom\n",
    "        R = self.data.max() - self.data.min()\n",
    "        IQR = iqr(self.data)                \n",
    "        MAD = median_abs_deviation(self.data)   \n",
    "        AAD = abs(self.data - self.data.mean()).mean()\n",
    "\n",
    "        # Bias correction\n",
    "        S0_bias_correct = self.S0 * np.sqrt(self.n/(self.n-1)) / self.c4(self.n)\n",
    "        S1_bias_corrected = self.S1 / self.c4(self.n)\n",
    "        self.R_bias_corrected = R / self.d2(self.n)\n",
    "        self.IQR_bias_corrected = IQR / (2 * norm.ppf(0.75))\n",
    "        self.MAD_bias_corrected = MAD / norm.ppf(0.75)\n",
    "        self.AAD_bias_corrected = AAD * np.sqrt(np.pi/2)\n",
    "\n",
    "        # Write the statistics in a list\n",
    "        sigma_biased = [self.S0, self.S1, R, IQR, MAD, AAD]\n",
    "        sigma_unbiased = [\n",
    "            S0_bias_correct,\n",
    "            S1_bias_corrected,\n",
    "            self.R_bias_corrected,\n",
    "            self.IQR_bias_corrected,\n",
    "            self.MAD_bias_corrected,\n",
    "            self.AAD_bias_corrected\n",
    "        ] \n",
    "\n",
    "        # Return the statistics as a table\n",
    "        labels = ['Deviation, ddof=0', 'Deviation, ddof=1', 'Range', 'IQR', 'MAD', 'AAD']\n",
    "        self.dispersion = pd.DataFrame({'Value':sigma_biased, 'Value_bias_corrected':sigma_unbiased, 'Robust':[0,0,0,1,1,1]}, labels)\n",
    "\n",
    "    # --- Skew ---\n",
    "    def CalculateSkewness(self):\n",
    "        SkewCentralMoments = skew(self.data)\n",
    "        SkewKStatistics = skew(self.data, bias=False)\n",
    "\n",
    "        self.skew = pd.DataFrame({'Value':[SkewCentralMoments, SkewKStatistics]}, ['Skew Central Moments', 'Skew K Statistics'])\n",
    "    \n",
    "    # --- Kurtosis ---\n",
    "    def CalculateKurtosis(self):\n",
    "        KurtosisCentralMoments = kurtosis(self.data, fisher=False)\n",
    "        KurtosisKStatistics = kurtosis(self.data, fisher=False, bias=False)\n",
    "\n",
    "        self.kurtosis = pd.DataFrame(\n",
    "            {'Value':[KurtosisCentralMoments, KurtosisKStatistics], 'Excess Kurtosis':[KurtosisCentralMoments-3, KurtosisKStatistics-3]},\n",
    "            ['Kurtosis CentralMoments', 'Kurtosis K Statistics']\n",
    "        )\n",
    "\n",
    "    def CalculateDescriptiveStatistics(self, trim_param, winsor_param, weights):\n",
    "        self.CalculateQuartiles()\n",
    "        self.CalculateCentralTendency(trim_param, winsor_param, weights)\n",
    "        self.CalculateDispersion()\n",
    "        self.CalculateSkewness()\n",
    "        self.CalculateKurtosis()\n",
    "\n",
    "    # --- Statistical Inference ---\n",
    "\n",
    "    # --- Confidence Intervals ---\n",
    "    def CalculateCiMean(self, alpha, hat_mean, hat_sigma, dist):\n",
    "        # Calculate confidence interval for the mean\n",
    "        scale = hat_sigma / np.sqrt(self.n)\n",
    "\n",
    "        if dist==\"norm\":\n",
    "            self.ci_mean = norm.ppf(alpha/2, hat_mean, scale), norm.ppf(1-alpha/2, hat_mean, scale)\n",
    "        if dist==\"t\":\n",
    "            # Only if we are using standard deviaiton with one degree of freedom without correction\n",
    "            self.ci_mean = t.ppf(alpha/2, self.n-1, hat_mean, scale), t.ppf(1-alpha/2, self.n-1, hat_mean, scale)\n",
    "        \n",
    "    def CalculateCiMedian(self, alpha, hat_median, hat_sigma):\n",
    "        # Calculate confidence interval based on the median\n",
    "        scale = hat_sigma * np.sqrt(np.pi/(2*self.n))\n",
    "        self.ci_median = norm.ppf(alpha/2, hat_median, scale), norm.ppf(1-alpha/2, hat_median, scale)\n",
    "\n",
    "    def CalculateCiDeviation(self, alpha):\n",
    "        # Calculate confidence interval for the standard deviation\n",
    "        num = self.S1 * np.sqrt(self.n-1)\n",
    "        den_low = np.sqrt(chi2.ppf(1-alpha/2, self.n-1))\n",
    "        den_upp = np.sqrt(chi2.ppf(alpha/2, self.n-1))\n",
    "\n",
    "        self.ci_deviation = num/den_low, num/den_upp\n",
    "\n",
    "    def CalculateConfidenceInterval(self, alpha, hat_mean, hat_median, hat_sigma, dist):\n",
    "        self.CalculateCiMean(alpha, hat_mean, hat_sigma, dist)\n",
    "        self.CalculateCiMedian(alpha, hat_median, hat_sigma)\n",
    "        self.CalculateCiDeviation(alpha)\n",
    "\n",
    "        # Return the statistics as a table\n",
    "        labels = ['Mean', 'Median', 'Deviation']\n",
    "        self.confidence_intervals = pd.DataFrame(\n",
    "            [self.ci_mean, self.ci_median, self.ci_deviation],\n",
    "            index=labels, columns=[\"Lower\", \"Upper\"]\n",
    "        )\n",
    "\n",
    "    # --- Prediction Intervals ---\n",
    "    def CalculatePiMean(self, alpha, hat_mean, hat_sigma, dist):\n",
    "        # Calculate prediction interval based on the mean\n",
    "        scale = np.sqrt(hat_sigma**2 + hat_sigma**2/self.n)\n",
    "\n",
    "        if dist == \"norm\":\n",
    "            self.pi_mean = norm.ppf(alpha/2, hat_mean, scale), norm.ppf(1-alpha/2, hat_mean, scale)\n",
    "        if dist == \"t\":\n",
    "            # Only if we are using standard deviaiton with one degree of freedom without correction\n",
    "            self.pi_mean = t.ppf(alpha/2, self.n-1, hat_mean, scale), t.ppf(1-alpha/2, self.n-1, hat_mean, scale)\n",
    "    \n",
    "    def CalculatePiMedian(self, alpha, hat_median=None, hat_sigma=None):\n",
    "        scale = np.sqrt(hat_sigma**2 + np.pi*hat_sigma**2/(2*self.n))\n",
    "        self.pi_median = norm.ppf(alpha/2, hat_median, scale), norm.ppf(1-alpha/2, hat_median, scale)\n",
    "\n",
    "    def CalculatePiIqr(self, alpha):\n",
    "        # Calculate prediction interval based on the first and third quartile\n",
    "        q1, q3 = np.quantile(self.data, [0.25, 0.75])\n",
    "        iqr = q3-q1\n",
    "        delta = 0.5 * (norm.ppf(1-alpha/2)/norm.ppf(0.75)-1)\n",
    "\n",
    "        self.pi_iqr = q1 - delta * iqr, q3 + delta * iqr\n",
    "\n",
    "    def CalculatePredictionInterval(self, alpha, hat_mean, hat_median, hat_sigma, dist):\n",
    "        self.CalculatePiMean(alpha, hat_mean, hat_sigma, dist)\n",
    "        self.CalculatePiMedian(alpha, hat_median, hat_sigma)\n",
    "        self.CalculatePiIqr(alpha)\n",
    "\n",
    "        # Return the statistics as a table\n",
    "        labels = ['Mean', 'Median', 'IQR']\n",
    "        self.prediction_intervals = pd.DataFrame(\n",
    "            [self.pi_mean, self.pi_median, self.pi_iqr],\n",
    "            index=labels, columns=[\"Lower\", \"Upper\"]\n",
    "        )\n",
    "\n",
    "    # --- Relative Likelihood ---\n",
    "    def RelativeLogLikelihood(self, mu, sigma):\n",
    "        return self.n * (np.log(self.S0 / sigma) + 0.5 * (1 - (np.mean(self.data**2) - 2 * mu * np.mean(self.data) + mu**2) / sigma**2))\n",
    "\n",
    "    def RelativeLikelihood(self, mu, sigma):\n",
    "        return np.exp(self.RelativeLogLikelihood(mu, sigma))\n",
    "\n",
    "    # --- Graphical Analysis ---\n",
    "    \n",
    "    # --- Plot Histogram ---\n",
    "    def PlotHistogram(self, kde, show_data, histo_add_ci, histo_choose_ci, histo_add_pi, histo_choose_pi, add_normal, hat_mu, hat_sigma):\n",
    "        \n",
    "        if histo_add_ci or histo_add_pi:\n",
    "            fig, (ax1, ax2) = plt.subplots(2, 1, sharex=True)\n",
    "\n",
    "            # Create histogram\n",
    "            sns.histplot(self.data, kde=kde, stat=\"density\", color=\"rebeccapurple\", alpha=0.5, ax=ax1)\n",
    "\n",
    "            if histo_add_ci:\n",
    "                if histo_choose_ci == \"Mean\":\n",
    "                    ax2.hlines(0.2, self.ci_mean[0], self.ci_mean[1], color='k')\n",
    "                    ax2.scatter((self.ci_mean[0] + self.ci_mean[1])/2, 0.2, marker=\"o\", color=\"k\")\n",
    "                    ax2.text(self.ci_mean[1], 0.2, \" Mean\", va=\"center\",\n",
    "                             bbox=dict(boxstyle='square', facecolor='lightgray', edgecolor='black'))\n",
    "                elif  histo_choose_ci == \"Median\":\n",
    "                    ax2.hlines(0.3, self.ci_median[0], self.ci_median[1], color='k')\n",
    "                    ax2.scatter((self.ci_median[0] + self.ci_median[1])/2, 0.3, marker=\"o\", color=\"k\")\n",
    "                    ax2.text(self.ci_median[1], 0.3, \" Median\", va=\"center\",\n",
    "                             bbox=dict(boxstyle='square', facecolor='lightgray', edgecolor='black'))\n",
    "                elif  histo_choose_ci == \"Both\":\n",
    "                    ax2.hlines(0.2, self.ci_mean[0], self.ci_mean[1], color='k')\n",
    "                    ax2.scatter((self.ci_mean[0] + self.ci_mean[1])/2, 0.2, marker=\"o\", color=\"k\")\n",
    "                    ax2.text(self.ci_mean[1], 0.2, \" Mean\", va=\"center\",\n",
    "                             bbox=dict(boxstyle='square', facecolor='lightgray', edgecolor='black'))\n",
    "                    ax2.hlines(0.3, self.ci_median[0], self.ci_median[1], color='k')\n",
    "                    ax2.scatter((self.ci_median[0] + self.ci_median[1])/2, 0.3, marker=\"o\", color=\"k\")\n",
    "                    ax2.text(self.ci_median[1], 0.3, \" Median\", va=\"center\",\n",
    "                             bbox=dict(boxstyle='square', facecolor='lightgray', edgecolor='black'))\n",
    "            if histo_add_pi:\n",
    "                if histo_choose_pi == \"Mean\": # If a prediction interval is given, add it to the plot\n",
    "                    ax2.hlines(0.1, self.pi_mean[0], self.pi_mean[1], color='k')\n",
    "                    ax2.scatter((self.pi_mean[0] + self.pi_mean[1])/2, 0.1, marker=\"o\", color=\"k\")\n",
    "                    ax2.text(self.pi_mean[1], 0.1, \" PI\", va=\"center\",\n",
    "                             bbox=dict(boxstyle='square', facecolor='lightgray', edgecolor='black'))\n",
    "                elif histo_choose_pi == \"Median\":\n",
    "                    ax2.hlines(0.1, self.pi_median[0], self.pi_median[1], color='k')\n",
    "                    ax2.scatter((self.pi_median[0] + self.pi_median[1])/2, 0.1, marker=\"o\", color=\"k\")\n",
    "                    ax2.text(self.pi_median[1], 0.1, \" PI\", va=\"center\",\n",
    "                             bbox=dict(boxstyle='square', facecolor='lightgray', edgecolor='black'))\n",
    "                elif histo_choose_pi == \"IQR\":\n",
    "                    ax2.hlines(0.1, self.pi_iqr[0], self.pi_iqr[1], color='k')\n",
    "                    ax2.scatter((self.pi_iqr[0] + self.pi_iqr[1])/2, 0.1, marker=\"o\", color=\"k\")\n",
    "                    ax2.text(self.pi_iqr[1], 0.1, \" PI\", va=\"center\",\n",
    "                             bbox=dict(boxstyle='square', facecolor='lightgray', edgecolor='black'))\n",
    "            \n",
    "            ax2.spines[['left', 'right', 'top']].set_visible(False)\n",
    "            ax2.set_yticks([])\n",
    "\n",
    "            if histo_add_pi:\n",
    "                y_lower = 0\n",
    "                if histo_add_ci:\n",
    "                    if histo_choose_ci in [\"Median\", \"Both\"]:\n",
    "                        y_upper = 0.4\n",
    "                    elif histo_choose_ci == \"Mean\":\n",
    "                        y_upper = 0.3\n",
    "                else:\n",
    "                    y_upper = 0.2\n",
    "            else:\n",
    "                if histo_choose_ci == \"Mean\":\n",
    "                    y_lower, y_upper = 0.1, 0.3\n",
    "                elif histo_choose_ci == \"Median\":\n",
    "                    y_lower, y_upper = 0.2, 0.4\n",
    "                elif histo_choose_ci == \"Both\":\n",
    "                    y_lower, y_upper = 0.1, 0.4\n",
    "\n",
    "            ax2.set_ylim(y_lower, y_upper)\n",
    "        else:\n",
    "            fig, ax1 = plt.subplots(1, 1)\n",
    "\n",
    "            # Create histogram\n",
    "            sns.histplot(self.data, kde=kde, stat=\"density\", color=\"rebeccapurple\", alpha=0.5, ax=ax1)\n",
    "\n",
    "        if add_normal:\n",
    "            y_vect = np.linspace(hat_mu - 3*hat_sigma, hat_mu + 3*hat_sigma, 100)\n",
    "            ax1.plot(y_vect, norm.pdf(y_vect, hat_mu, hat_sigma), color=\"k\", ls=\"--\",  label=\"Normal density\")\n",
    "            ax1.legend()\n",
    "\n",
    "        if show_data: # Show the observations\n",
    "            _, upper = ax1.get_ylim()\n",
    "            sns.rugplot(self.data, height=0.1*upper, ax=ax1,  color='k')\n",
    "\n",
    "        ax1.spines[['right', 'top']].set_visible(False)\n",
    "        return fig\n",
    "    \n",
    "    # --- Plot ECDF ---\n",
    "    def PlotEcdf(self, alpha, confidence, add_normal, hat_mu, hat_sigma):\n",
    "        ecdf = ECDF(self.data)\n",
    "\n",
    "        fig, ax = plt.subplots(1, 1)\n",
    "\n",
    "        # In the second subfigure we show the ECDF\n",
    "        ax.spines[['right', 'top']].set_visible(False) # Do not plot the right and top margins\n",
    "\n",
    "        # Plot the ECDF\n",
    "        ax.scatter(ecdf.x, ecdf.y, color='rebeccapurple')        \n",
    "        ax.step(ecdf.x, ecdf.y, where='post', color='rebeccapurple', label=\"ECDF\")\n",
    "\n",
    "        if confidence:\n",
    "            epsilon = np.sqrt(np.log(2/alpha)/(2*self.n))\n",
    "            upper = ecdf.y + epsilon\n",
    "            lower = ecdf.y - epsilon\n",
    "\n",
    "            upper[upper>1] = 1\n",
    "            lower[lower<0] = 0\n",
    "\n",
    "            ax.fill_between(ecdf.x, lower, upper, step='post', color='rebeccapurple', alpha=0.5)\n",
    "\n",
    "        if add_normal:\n",
    "            y_vect = np.linspace(hat_mu - 3*hat_sigma, hat_mu + 3*hat_sigma, 100)\n",
    "            ax.plot(y_vect, norm.cdf(y_vect, hat_mu, hat_sigma), color=\"k\", ls=\"--\", label=\"Normal CDF\")\n",
    "            ax.set_xlim(min(self.data.min(), y_vect.min())-0.05, max(self.data.max(), y_vect.max())+0.05)\n",
    "        else:\n",
    "            ax.set_xlim(self.data.min()-0.05, self.data.max()+0.05)\n",
    "\n",
    "        # Add title and labels to the plot\n",
    "        ax.set_title(\"Empirical Cumulative Distribution Function\", fontsize=12)\n",
    "        ax.set_xlabel(r'$x$')\n",
    "        ax.set_ylabel(r'$F_n(x)$')\n",
    "        ax.set_ylim(0, 1.05)\n",
    "        ax.legend()\n",
    "\n",
    "        return fig\n",
    "\n",
    "    # --- Plot Confidence Regions ---\n",
    "    def PlotConfidenceRegions(self, probs, eps, add):\n",
    "        probs = probs[::-1] # We need to write the probabilities in a dicreasing order\n",
    "        \n",
    "        levels = np.exp(-0.5 * chi2.ppf(probs, 2))\n",
    "\n",
    "        mu_vect = np.linspace(self.ci_mean[0] - eps[0], self.ci_mean[1] + eps[0], 100)\n",
    "        sigma_vect = np.linspace(self.ci_deviation[0] - eps[1], self.ci_deviation[1] + eps[1], 100)\n",
    "\n",
    "        mu_grid, sigma_grid = np.meshgrid(mu_vect, sigma_vect)\n",
    "\n",
    "        fig, ax = plt.subplots(1, 1)\n",
    "\n",
    "        cnt = ax.contour(mu_grid, sigma_grid, self.RelativeLikelihood(mu_grid, sigma_grid), levels)\n",
    "        ax.scatter(x=self.mean, y=self.S0, color='k')\n",
    "\n",
    "        if add:\n",
    "            ax.plot(\n",
    "                [self.ci_mean[0], self.ci_mean[0], self.ci_mean[1], self.ci_mean[1], self.ci_mean[0]],\n",
    "                [self.ci_deviation[0], self.ci_deviation[1], self.ci_deviation[1], self.ci_deviation[0], self.ci_deviation[0]],\n",
    "                color='r', ls='--')\n",
    "\n",
    "        ax.set_title(r\"Confidence regions for $\\mu$ and $\\sigma$\")\n",
    "        ax.set_xlabel(r\"$\\mu$\")\n",
    "        ax.set_ylabel(r\"$\\sigma$\")\n",
    "\n",
    "        _, labels = cnt.legend_elements()\n",
    "        ax.legend(_, probs, loc=\"upper right\", frameon=False)\n",
    "\n",
    "        ax.spines[['right', 'top']].set_visible(False)\n",
    "\n",
    "        return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2638106",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee47afaa",
   "metadata": {},
   "source": [
    "## Auxiliary functions to control logic of GUI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0cecaeaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_numeric_cols():\n",
    "    numeric_cols = df_cache.get(\"numeric_cols\", [])\n",
    "    selected = numeric_cols[0] if numeric_cols else None\n",
    "    return gr.update(choices=numeric_cols, value=selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "beaef79b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def blank_plot():\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.axis('off')\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2650afd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(column):\n",
    "    # --- Read data and validate ---\n",
    "    original_df = df_cache.get(\"df\")\n",
    "    filtered_df = df_cache.get(\"filtered_df\")\n",
    "\n",
    "    if original_df is None:\n",
    "        return None, None, None, pd.DataFrame([[\"Please upload a valid CSV.\"]], columns=[\"Error\"]), blank_plot()\n",
    "\n",
    "    # --- Use filtered data if it differs from original ---\n",
    "    df = filtered_df if filtered_df is not None and not filtered_df.equals(original_df) else original_df\n",
    "\n",
    "    # --- Select numeric column ---\n",
    "    if column not in df.columns:\n",
    "        return None, None, None, pd.DataFrame([[\"Selected column is not in the dataframe.\"]], columns=[\"Error\"]), blank_plot()\n",
    "\n",
    "    data = df[column].dropna()\n",
    "\n",
    "    # --- Initialize or reuse Statistics object ---\n",
    "    stats = df_cache.get(\"stats\")\n",
    "    if stats is None or not np.array_equal(stats.data, data.to_numpy()):\n",
    "        stats = Statistics(data)\n",
    "        df_cache[\"stats\"] = stats\n",
    "\n",
    "    return df, data, stats, None, None  # df, data, stats, error_df, error_plot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "995fe369",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_normal_warning(check):\n",
    "    if check:\n",
    "        gr.Warning(\"If you haven't done it yet, run first a descriptive analysis for central tendency and dispersion.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c9978559",
   "metadata": {},
   "outputs": [],
   "source": [
    "def toggle_add_normal(check, sel_mu, sel_sigma):\n",
    "    if check:\n",
    "        if sel_mu == \"Other\":\n",
    "            if sel_sigma == \"Other\":\n",
    "                return [\n",
    "                    gr.update(visible=True), # hat_mu\n",
    "                    gr.update(visible=True), # hat_mu_text\n",
    "                    gr.update(visible=True), # hat_sigma\n",
    "                    gr.update(visible=True)  # hat_sigma_text\n",
    "                ]\n",
    "            else:\n",
    "                return (\n",
    "                    gr.update(visible=True),\n",
    "                    gr.update(visible=True),\n",
    "                    gr.update(visible=True),\n",
    "                    gr.update(visible=False)\n",
    "                )\n",
    "        else:\n",
    "            if sel_sigma == \"Other\":\n",
    "                return (\n",
    "                    gr.update(visible=True), \n",
    "                    gr.update(visible=False), \n",
    "                    gr.update(visible=True), \n",
    "                    gr.update(visible=True)\n",
    "                )\n",
    "            else:\n",
    "                return (\n",
    "                    gr.update(visible=True),\n",
    "                    gr.update(visible=False),\n",
    "                    gr.update(visible=True),\n",
    "                    gr.update(visible=False)\n",
    "                )\n",
    "    else:\n",
    "        return (\n",
    "            gr.update(visible=False),\n",
    "            gr.update(visible=False),\n",
    "            gr.update(visible=False),\n",
    "            gr.update(visible=False)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bb7c9a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_text(input_str):   \n",
    "        return float(input_str) if input_str.strip() else None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3b8f8cd",
   "metadata": {},
   "source": [
    "## Logic control of Data Tab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8fe9bb46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def blank_plot():\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.axis('off')\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "319a71b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_effective_column_types(df):\n",
    "    all_numeric = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    all_categorical = df.select_dtypes(exclude=[np.number]).columns.tolist()\n",
    "    overrides = df_cache.get(\"overrides\", {\"num_to_cat\": [], \"cat_to_num\": []})\n",
    "\n",
    "    numeric = [col for col in all_numeric if col not in overrides[\"num_to_cat\"]]\n",
    "    categorical = [col for col in all_categorical if col not in overrides[\"cat_to_num\"]]\n",
    "\n",
    "    numeric += [col for col in overrides[\"cat_to_num\"] if col in df.columns]\n",
    "    categorical += [col for col in overrides[\"num_to_cat\"] if col in df.columns]\n",
    "\n",
    "    return sorted(set(numeric)), sorted(set(categorical))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5d21ea60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_csv(file):\n",
    "    try:\n",
    "        df = pd.read_csv(file.name)\n",
    "\n",
    "        if df.empty:\n",
    "            raise ValueError(\"The uploaded CSV file is empty.\")\n",
    "\n",
    "        df_cache[\"df\"] = df\n",
    "        df_cache[\"filtered_df\"] = df\n",
    "        df_cache[\"stats\"] = None\n",
    "\n",
    "        numeric_cols, categorical_cols = get_effective_column_types(df)\n",
    "\n",
    "        df_cache[\"numeric_cols\"] = numeric_cols\n",
    "        df_cache[\"categorical_cols\"] = categorical_cols\n",
    "\n",
    "        return (\n",
    "            gr.update(choices=categorical_cols, value=[]),            # cat_col_dropdown\n",
    "            gr.update(choices=numeric_cols, value=None),              # num_override_dropdown\n",
    "            gr.update(choices=categorical_cols, value=None),          # cat_override_dropdown\n",
    "            gr.update(choices=[], value=[], visible=False),           # cat_val_multiselect_1\n",
    "            gr.update(choices=[], value=[], visible=False),           # cat_val_multiselect_2\n",
    "            gr.update(choices=[], value=[], visible=False),           # cat_val_multiselect_3\n",
    "            \"CSV loaded successfully.\"                                # status_output (Textbox!)\n",
    "        )\n",
    "    except Exception as e:\n",
    "        return tuple([gr.update(choices=[], value=None)] * 7 + [f\"Error: {e}\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c2384f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reclassify_as_categorical(column):\n",
    "    numeric_cols = df_cache.get(\"numeric_cols\", [])\n",
    "    categorical_cols = df_cache.get(\"categorical_cols\", [])\n",
    "\n",
    "    if column and column in numeric_cols:\n",
    "        numeric_cols.remove(column)\n",
    "        categorical_cols.append(column)\n",
    "        df_cache[\"numeric_cols\"] = numeric_cols\n",
    "        df_cache[\"categorical_cols\"] = categorical_cols\n",
    "\n",
    "        return (\n",
    "            gr.update(choices=categorical_cols),                      # cat_col_dropdown\n",
    "            gr.update(choices=numeric_cols),                          # num_override_dropdown\n",
    "            gr.update(choices=categorical_cols),                      # cat_override_dropdown\n",
    "            f\"Column '{column}' reclassified as categorical.\"         # status\n",
    "        )\n",
    "    else:\n",
    "        return (\n",
    "            gr.update(), gr.update(), gr.update(), gr.update(),\n",
    "            f\"Column '{column}' is not currently classified as numeric.\"\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4d2c1bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reclassify_as_numeric(column):\n",
    "    numeric_cols = df_cache.get(\"numeric_cols\", [])\n",
    "    categorical_cols = df_cache.get(\"categorical_cols\", [])\n",
    "\n",
    "    if column and column in categorical_cols:\n",
    "        categorical_cols.remove(column)\n",
    "        numeric_cols.append(column)\n",
    "        df_cache[\"categorical_cols\"] = categorical_cols\n",
    "        df_cache[\"numeric_cols\"] = numeric_cols\n",
    "\n",
    "        return (\n",
    "            gr.update(choices=categorical_cols),                      # cat_col_dropdown\n",
    "            gr.update(choices=numeric_cols),                          # num_override_dropdown\n",
    "            gr.update(choices=categorical_cols),                      # cat_override_dropdown\n",
    "            f\"Column '{column}' reclassified as numeric.\"             # status\n",
    "        )\n",
    "    else:\n",
    "        return (\n",
    "            gr.update(), gr.update(), gr.update(), gr.update(),\n",
    "            f\"Column '{column}' is not currently classified as categorical.\"\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "03c84847",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only 3 category filters are supported.\n",
    "def update_category_filters(selected_columns):\n",
    "    df = df_cache.get(\"df\")\n",
    "\n",
    "    if df is None or not selected_columns:\n",
    "        # Hide all category selectors if nothing is selected\n",
    "        return [gr.update(visible=False, choices=[], value=[]) for _ in range(3)]\n",
    "\n",
    "    updates = []\n",
    "    for i in range(3):\n",
    "        if i < len(selected_columns):\n",
    "            col = selected_columns[i]\n",
    "            if col in df.columns:\n",
    "                values = sorted(df[col].dropna().unique().tolist())\n",
    "                updates.append(gr.update(visible=True, choices=values, value=[]))\n",
    "            else:\n",
    "                updates.append(gr.update(visible=False, choices=[], value=[]))\n",
    "        else:\n",
    "            updates.append(gr.update(visible=False, choices=[], value=[]))\n",
    "\n",
    "    return updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "50a3647f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_filters(cat_cols, val1, val2, val3):\n",
    "    df = df_cache.get(\"df\")\n",
    "    if df is None:\n",
    "        return \"❌ No data loaded.\"\n",
    "\n",
    "    filtered_df = df.copy()\n",
    "    category_filters = [val1, val2, val3]\n",
    "\n",
    "    if not cat_cols or all(not vals for vals in category_filters):\n",
    "        # No filters applied\n",
    "        df_cache[\"filtered_df\"] = df\n",
    "        return \"⚠️ No filters selected. Using full dataset.\"\n",
    "\n",
    "    for i, col in enumerate(cat_cols[:3]):\n",
    "        selected_vals = category_filters[i]\n",
    "        if selected_vals:\n",
    "            filtered_df = filtered_df[filtered_df[col].isin(selected_vals)]\n",
    "\n",
    "    df_cache[\"filtered_df\"] = filtered_df\n",
    "    return f\"✅ Filter applied. Rows remaining: {len(filtered_df)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d48d6db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def toggle_preview(check):\n",
    "    df = df_cache.get(\"df\")\n",
    "    if check:\n",
    "        return df.head(5), gr.update(visible=True)\n",
    "    else:\n",
    "        return pd.DataFrame(), gr.update(visible=False) # csv_preview, csv_preview\n",
    "    \n",
    "def max_categorical_warning(check):\n",
    "    if check:\n",
    "        gr.Info(\"The maximum number of categorical columns for filter is 3.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efaf923a",
   "metadata": {},
   "source": [
    "## GUI of Data Tab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "216a8e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_data_tab():\n",
    "    with gr.TabItem(\"🗄️ Data\"):\n",
    "\n",
    "        with gr.Group():\n",
    "            gr.Markdown(\"# 📁 File Explorer\")\n",
    "            \n",
    "            with gr.Row():\n",
    "                file_input = gr.File(file_types=[\".csv\"], label=\"Upload CSV\")\n",
    "                status_output = gr.Textbox(label=\"Status\", interactive=False)\n",
    "                preview_checkbox = gr.Checkbox(label=\"Show CSV Preview\", value=False)\n",
    "                \n",
    "            csv_preview = gr.Dataframe(label=\"CSV Preview\", visible=False)\n",
    "\n",
    "        with gr.Group():\n",
    "            gr.Markdown(\"# 🛠️ Fix Variable Type\")\n",
    "            with gr.Accordion(open=False):\n",
    "                with gr.Row():\n",
    "                    # Reclassify numeric ➝ categorical\n",
    "                    num_override_dropdown = gr.Dropdown(label=\"Reclassify Numeric Column as Categorical\")\n",
    "                    fix_to_categorical_button = gr.Button(\"Reclassify as Categorical\")\n",
    "\n",
    "                    # Reclassify categorical ➝ numeric\n",
    "                    cat_override_dropdown = gr.Dropdown(label=\"Reclassify Categorical Column as Numeric\")\n",
    "                    fix_to_numeric_button = gr.Button(\"Reclassify as Numeric\")\n",
    "\n",
    "                    fix_dtype_status = gr.Textbox(label=\"Status\", interactive=False)        \n",
    "\n",
    "        with gr.Group():\n",
    "            gr.Markdown(\"# ➖ Filter Data\") \n",
    "            with gr.Accordion(open=False):       \n",
    "                with gr.Row():\n",
    "                    cat_col_dropdown = gr.Dropdown(label=\"Select Categorical Columns for Filter\", multiselect=True, max_choices=3)\n",
    "                    cat_val_multiselect_1 = gr.Dropdown(label=\"Categories for Filter 1\", multiselect=True, visible=False, interactive=True)\n",
    "                    cat_val_multiselect_2 = gr.Dropdown(label=\"Categories for Filter 2\", multiselect=True, visible=False, interactive=True)\n",
    "                    cat_val_multiselect_3 = gr.Dropdown(label=\"Categories for Filter 3\", multiselect=True, visible=False, interactive=True)\n",
    "        \n",
    "                with gr.Row():\n",
    "                    apply_filter_button = gr.Button(\"🚀 Apply Filter\")\n",
    "                    filter_status = gr.Textbox(label=\"Filter Status\", interactive=False)\n",
    "\n",
    "    # --- Modify behavior of components of the GUI ---\n",
    "    file_input.change(\n",
    "        fn=load_csv,\n",
    "        inputs=[file_input],\n",
    "        outputs=[\n",
    "            cat_col_dropdown,\n",
    "            num_override_dropdown,\n",
    "            cat_override_dropdown,\n",
    "            cat_val_multiselect_1,\n",
    "            cat_val_multiselect_2,\n",
    "            cat_val_multiselect_3,\n",
    "            status_output\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    preview_checkbox.change(\n",
    "        fn=toggle_preview,\n",
    "        inputs=preview_checkbox,\n",
    "        outputs=[csv_preview, csv_preview]\n",
    "    )\n",
    "\n",
    "    fix_to_categorical_button.click(\n",
    "        fn=reclassify_as_categorical,\n",
    "        inputs=[num_override_dropdown],\n",
    "        outputs=[\n",
    "            cat_col_dropdown,\n",
    "            num_override_dropdown,\n",
    "            cat_override_dropdown,\n",
    "            fix_dtype_status\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    fix_to_numeric_button.click(\n",
    "        fn=reclassify_as_numeric,\n",
    "        inputs=[cat_override_dropdown],\n",
    "        outputs=[\n",
    "            cat_col_dropdown,\n",
    "            num_override_dropdown,\n",
    "            cat_override_dropdown,\n",
    "            fix_dtype_status\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    cat_col_dropdown.change(\n",
    "        fn=max_categorical_warning,\n",
    "        inputs=cat_col_dropdown,\n",
    "        outputs=[]\n",
    "    )\n",
    "\n",
    "    cat_col_dropdown.change(\n",
    "        fn=update_category_filters,\n",
    "        inputs=cat_col_dropdown,\n",
    "        outputs=[cat_val_multiselect_1, cat_val_multiselect_2, cat_val_multiselect_3]\n",
    "    )\n",
    "\n",
    "    apply_filter_button.click(\n",
    "        fn=apply_filters,\n",
    "        inputs=[\n",
    "            cat_col_dropdown,\n",
    "            cat_val_multiselect_1,\n",
    "            cat_val_multiselect_2,\n",
    "            cat_val_multiselect_3\n",
    "        ],\n",
    "        outputs=[filter_status]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "902a9052",
   "metadata": {},
   "source": [
    "## Logic control of Graphical Tab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a9821215",
   "metadata": {},
   "outputs": [],
   "source": [
    "def histo_add_ci_warning(check):\n",
    "    if check:\n",
    "        gr.Warning(\"If you haven't done it yet, run first a statistical inference for confidence interval.\")\n",
    "\n",
    "def histo_add_pi_warning(check):\n",
    "    if check:\n",
    "        gr.Warning(\"If you haven't done it yet, run first a statistical inference for prediction interval.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0761d2df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def toggle_graph_stat(graph_stat, histo_add_normal, histo_add_ci, histo_add_pi, ecdf_add_normal):\n",
    "    if graph_stat == \"Histogram\":\n",
    "        return (\n",
    "            gr.update(visible=True), # histo_add_kde\n",
    "            gr.update(visible=True), # histo_add_data\n",
    "            gr.update(visible=True, value=histo_add_normal), # histo_add_normal\n",
    "            gr.update(visible=True, value=histo_add_ci), # histo_add_ci\n",
    "            gr.update(visible=True, value=histo_add_pi), # histo_add_pi\n",
    "            gr.update(visible=False, value=False), # ecdf_add_normal\n",
    "            gr.update(visible=False), # ecdf_add_conf\n",
    "            gr.update(visible=False), # ecdf_alpha\n",
    "        )\n",
    "    elif graph_stat == \"Empirical Cumulative Distribution Function (ECDF)\":\n",
    "        return ( \n",
    "            gr.update(visible=False), \n",
    "            gr.update(visible=False),\n",
    "            gr.update(visible=False, value=False),\n",
    "            gr.update(visible=False, value=False),\n",
    "            gr.update(visible=False, value=False),\n",
    "            gr.update(visible=True, value=ecdf_add_normal),\n",
    "            gr.update(visible=True),\n",
    "            gr.update(visible=True),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "435632b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_graph_stat(\n",
    "        column,\n",
    "        graph_stat,\n",
    "        histo_add_kde_check, histo_add_data_check,\n",
    "        histo_add_ci, histo_choose_ci,\n",
    "        histo_add_pi, histo_choose_pi,\n",
    "        histo_add_normal,\n",
    "        histo_hat_mu, histo_hat_mu_text,\n",
    "        histo_hat_sigma, histo_hat_sigma_text,\n",
    "        ecdf_add_conf,\n",
    "        ecdf_alpha,\n",
    "        ecdf_add_normal,\n",
    "        ecdf_hat_mu, ecdf_hat_mu_text,\n",
    "        ecdf_hat_sigma, ecdf_hat_sigma_text,\n",
    "        ):\n",
    "    \n",
    "    df, data, stats, error_df, error_plot = prepare_data(column)\n",
    "    if error_df:\n",
    "        return error_df, error_plot\n",
    "\n",
    "    # --- Graphical Analysis ---\n",
    "    if graph_stat == \"Histogram\":\n",
    "        hat_mu, hat_sigma = None, None\n",
    "\n",
    "        if histo_add_normal:\n",
    "            # Choose mu\n",
    "            if histo_hat_mu == \"Sample Mean\":\n",
    "                hat_mu = stats.mean\n",
    "            elif histo_hat_mu == \"Sample Median\":\n",
    "                hat_mu = stats.median\n",
    "            elif histo_hat_mu == \"Geometric Mean\":\n",
    "                hat_mu = stats.geometric_mean\n",
    "            elif histo_hat_mu == \"Harmonic Mean\":\n",
    "                hat_mu = stats.harmonic_mean\n",
    "            elif histo_hat_mu == \"Weighted Mean\":\n",
    "                hat_mu = stats.weighted_mean\n",
    "            elif histo_hat_mu == \"Trimmed Mean\":\n",
    "                hat_mu = stats.trimmed_mean\n",
    "            elif histo_hat_mu == \"Interquartile Mean\":\n",
    "                hat_mu = stats.interquartile_mean\n",
    "            elif histo_hat_mu == \"Winsorized Mean\":\n",
    "                hat_mu = stats.winsorized_mean\n",
    "            elif histo_hat_mu == \"Other\":\n",
    "                hat_mu = float(histo_hat_mu_text)\n",
    "\n",
    "            # Choose sigma\n",
    "            if histo_hat_sigma == \"Deviation (1 ddof)\":\n",
    "                hat_sigma = stats.S1\n",
    "            elif histo_hat_sigma == \"Range (bias corrected)\":\n",
    "                hat_sigma = stats.R_bias_corrected\n",
    "            elif histo_hat_sigma == \"IQR (bias corrected)\":\n",
    "                hat_sigma = stats.IQR_bias_corrected\n",
    "            elif histo_hat_sigma == \"MAD (bias corrected)\":\n",
    "                hat_sigma = stats.MAD_bias_corrected\n",
    "            elif histo_hat_sigma == \"AAD (bias corrected)\":\n",
    "                hat_sigma = stats.AAD_bias_corrected\n",
    "            elif histo_hat_sigma == \"Other\":\n",
    "                hat_sigma = float(histo_hat_sigma_text)\n",
    "\n",
    "        fig = stats.PlotHistogram(\n",
    "            histo_add_kde_check,\n",
    "            histo_add_data_check,\n",
    "            histo_add_ci, histo_choose_ci,\n",
    "            histo_add_pi, histo_choose_pi,\n",
    "            histo_add_normal,\n",
    "            hat_mu,\n",
    "            hat_sigma\n",
    "        )\n",
    "    elif graph_stat == \"Empirical Cumulative Distribution Function (ECDF)\":\n",
    "\n",
    "        alpha = parse_text(ecdf_alpha)\n",
    "        alpha = 1 -alpha\n",
    "        if alpha is None or not (0 < alpha < 1):\n",
    "            return pd.DataFrame([[\"Invalid alpha value.\"]], columns=[\"Error\"])\n",
    "\n",
    "        hat_mu, hat_sigma = None, None\n",
    "\n",
    "        if ecdf_add_normal:\n",
    "            # Choose mu\n",
    "            if ecdf_hat_mu == \"Sample Mean\":\n",
    "                hat_mu = stats.mean\n",
    "            elif ecdf_hat_mu == \"Sample Median\":\n",
    "                hat_mu = stats.median\n",
    "            elif ecdf_hat_mu == \"Geometric Mean\":\n",
    "                hat_mu = stats.geometric_mean\n",
    "            elif ecdf_hat_mu == \"Harmonic Mean\":\n",
    "                hat_mu = stats.harmonic_mean\n",
    "            elif ecdf_hat_mu == \"Weighted Mean\":\n",
    "                hat_mu = stats.weighted_mean\n",
    "            elif ecdf_hat_mu == \"Trimmed Mean\":\n",
    "                hat_mu = stats.trimmed_mean\n",
    "            elif ecdf_hat_mu == \"Interquartile Mean\":\n",
    "                hat_mu = stats.interquartile_mean\n",
    "            elif ecdf_hat_mu == \"Winsorized Mean\":\n",
    "                hat_mu = stats.winsorized_mean\n",
    "            elif ecdf_hat_mu == \"Other\":\n",
    "                hat_mu = float(ecdf_hat_mu_text)\n",
    "            \n",
    "            # Choose sigma\n",
    "            if ecdf_hat_sigma == \"Deviation (1 ddof)\":\n",
    "                hat_sigma = stats.S1\n",
    "            elif ecdf_hat_sigma == \"Range (bias corrected)\":\n",
    "                hat_sigma = stats.R_bias_corrected\n",
    "            elif ecdf_hat_sigma == \"IQR (bias corrected)\":\n",
    "                hat_sigma = stats.IQR_bias_corrected\n",
    "            elif ecdf_hat_sigma == \"MAD (bias corrected)\":\n",
    "                hat_sigma = stats.MAD_bias_corrected\n",
    "            elif ecdf_hat_sigma == \"AAD (bias corrected)\":\n",
    "                hat_sigma = stats.AAD_bias_corrected\n",
    "            elif ecdf_hat_sigma == \"Other\":\n",
    "                hat_sigma = float(ecdf_hat_sigma_text)\n",
    "\n",
    "        fig = stats.PlotEcdf(\n",
    "            alpha,\n",
    "            ecdf_add_conf,\n",
    "            ecdf_add_normal,\n",
    "            hat_mu,\n",
    "            hat_sigma\n",
    "        )\n",
    "        \n",
    "    # results_block, output_table, output_table, output_plot, output_plot\n",
    "    return gr.update(visible=True), gr.update(visible=False), pd.DataFrame(), gr.update(visible=True), fig "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c28f4d67",
   "metadata": {},
   "source": [
    "## GUI of Graphical Tab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "38f51fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_graphical_tab():\n",
    "    with gr.TabItem(\"📊 Graphical Analysis\"):\n",
    "        with gr.Group():\n",
    "            gr.Markdown(\"# 📊 Graphical Analysis\")\n",
    "            with gr.Row():\n",
    "                refresh_columns_button = gr.Button(\"🔄 Refresh Numeric Columns\")\n",
    "                column_dropdown = gr.Dropdown(label=\"Select Numeric Column\", choices=[], interactive=True)\n",
    "\n",
    "                graph_stat_dropdown = gr.Dropdown(\n",
    "                    label=\"Select Graph\",\n",
    "                    choices=[\n",
    "                        \"Histogram\",\n",
    "                        \"Empirical Cumulative Distribution Function (ECDF)\"\n",
    "                    ],\n",
    "                    value=\"Histogram\",\n",
    "                    interactive=True\n",
    "                )\n",
    "\n",
    "                histo_add_kde = gr.Checkbox(label=\"Add KDE\", value=True, visible=True, interactive=True)\n",
    "                histo_add_data = gr.Checkbox(label=\"Show data\", value=False, visible=True, interactive=True)\n",
    "\n",
    "                ecdf_add_conf = gr.Checkbox(label=\"Add CI for the ECDF\", value=True, visible=False, interactive=True)\n",
    "                ecdf_alpha = gr.Textbox(label=\"Confidence level (e.g. 0.95)\", value=0.95, interactive=True, visible=False)\n",
    "\n",
    "            with gr.Row():\n",
    "                histo_add_normal = gr.Checkbox(label=\"Add Normal Density\", value=False)\n",
    "\n",
    "                histo_hat_mu = gr.Dropdown(\n",
    "                    label=\"μ\",\n",
    "                    choices=[\n",
    "                        'Sample Mean',\n",
    "                        'Sample Median',\n",
    "                        'Geometric Mean',\n",
    "                        'Harmonic Mean',\n",
    "                        'Weighted Mean',\n",
    "                        'Trimmed Mean',\n",
    "                        'Interquartile Mean',\n",
    "                        'Winsorized Mean',\n",
    "                        \"Other\"\n",
    "                    ],\n",
    "                    value=\"Sample Mean\",\n",
    "                    interactive=True,\n",
    "                    visible=False\n",
    "                )\n",
    "                histo_hat_mu_text = gr.Textbox(label=\"Write the value of a consistent estimator\", visible=False)\n",
    "\n",
    "                histo_hat_sigma = gr.Dropdown(\n",
    "                    label=\"σ\",\n",
    "                    choices=[\n",
    "                        \"Deviation (1 ddof)\",\n",
    "                        \"Range (bias corrected)\",\n",
    "                        \"IQR (bias corrected)\",\n",
    "                        \"MAD (bias corrected)\",\n",
    "                        \"AAD (bias corrected)\",\n",
    "                        \"Other\"\n",
    "                    ],\n",
    "                    value=\"Deviation (1 ddof)\",\n",
    "                    interactive=True,\n",
    "                    visible=False\n",
    "                )\n",
    "                histo_hat_sigma_text = gr.Textbox(label=\"Write the value of a consistent estimator\", visible=False)\n",
    "\n",
    "            with gr.Row():\n",
    "                histo_add_ci = gr.Checkbox(label=\"Add Confidence Interval\", value=False)\n",
    "\n",
    "                histo_choose_ci = gr.Radio(\n",
    "                    label=\"Confidence Interval\",\n",
    "                    choices=[\"Mean\", \"Median\", \"Both\"],\n",
    "                    value=\"Mean\",\n",
    "                    interactive=True,\n",
    "                    visible=False\n",
    "                )\n",
    "\n",
    "            with gr.Row():                \n",
    "                histo_add_pi = gr.Checkbox(label=\"Add Prediction Interval\", value=False)\n",
    "                histo_choose_pi = gr.Radio(\n",
    "                    label=\"Prediction Interval\",\n",
    "                    choices=[\"Mean\", \"Median\", \"IQR\"],\n",
    "                    value=\"Mean\",\n",
    "                    interactive=True,\n",
    "                    visible=False\n",
    "                )\n",
    "\n",
    "            with gr.Row():\n",
    "                ecdf_add_normal = gr.Checkbox(label=\"Add Normal CDF\", value=False, visible=False)\n",
    "\n",
    "                ecdf_hat_mu = gr.Dropdown(\n",
    "                    label=\"μ\",\n",
    "                    choices=[\n",
    "                        'Sample Mean',\n",
    "                        'Sample Median',\n",
    "                        'Geometric Mean',\n",
    "                        'Harmonic Mean',\n",
    "                        'Weighted Mean',\n",
    "                        'Trimmed Mean',\n",
    "                        'Interquartile Mean',\n",
    "                        'Winsorized Mean',\n",
    "                        \"Other\"\n",
    "                    ],\n",
    "                    value=\"Sample Mean\",\n",
    "                    interactive=True,\n",
    "                    visible=False\n",
    "                )\n",
    "                ecdf_hat_mu_text = gr.Textbox(label=\"Write the value of a consistent estimator\", visible=False)\n",
    "\n",
    "                ecdf_hat_sigma = gr.Dropdown(\n",
    "                    label=\"σ\",\n",
    "                    choices=[\n",
    "                        \"Deviation (1 ddof)\",\n",
    "                        \"Range (bias corrected)\",\n",
    "                        \"IQR (bias corrected)\",\n",
    "                        \"MAD (bias corrected)\",\n",
    "                        \"AAD (bias corrected)\",\n",
    "                        \"Other\"\n",
    "                    ],\n",
    "                    value=\"Deviation (1 ddof)\",\n",
    "                    interactive=True,\n",
    "                    visible=False\n",
    "                )\n",
    "                ecdf_hat_sigma_text = gr.Textbox(label=\"Write the value of a consistent estimator\", visible=False)\n",
    "\n",
    "            run_graph_stat_button = gr.Button(value=\" 🚀 Run Graphical Analysis\")\n",
    "\n",
    "        # --- Results ---\n",
    "        with gr.Group(visible=False) as results_block:\n",
    "            gr.Markdown(\"# 🎯 Results\")\n",
    "            output_table = gr.Dataframe()\n",
    "            output_plot = gr.Plot()\n",
    "\n",
    "    # --- Modify behavior of components of the GUI ---\n",
    "    refresh_columns_button.click(\n",
    "        fn=load_numeric_cols,\n",
    "        inputs=[],\n",
    "        outputs=[column_dropdown]\n",
    "    )\n",
    "\n",
    "    graph_stat_dropdown.change(\n",
    "        fn=toggle_graph_stat,\n",
    "        inputs=[graph_stat_dropdown, histo_add_normal, histo_add_ci, histo_add_pi, ecdf_add_normal],\n",
    "        outputs=[\n",
    "            histo_add_kde,\n",
    "            histo_add_data,\n",
    "            histo_add_normal,\n",
    "            histo_add_ci,\n",
    "            histo_add_pi,\n",
    "            ecdf_add_normal,\n",
    "            ecdf_add_conf,\n",
    "            ecdf_alpha]\n",
    "    )\n",
    "\n",
    "    histo_add_ci.change(\n",
    "        fn=lambda check: gr.update(visible=check),\n",
    "        inputs=[histo_add_ci],\n",
    "        outputs=[histo_choose_ci]\n",
    "    )\n",
    "\n",
    "    histo_add_pi.change(\n",
    "        fn=lambda check: gr.update(visible=check),\n",
    "        inputs=[histo_add_pi],\n",
    "        outputs=[histo_choose_pi]\n",
    "    )\n",
    "\n",
    "    histo_add_ci.change(\n",
    "        fn=histo_add_ci_warning,\n",
    "        inputs=[histo_add_ci],\n",
    "        outputs=[]\n",
    "    )\n",
    "\n",
    "    histo_add_pi.change(\n",
    "        fn=histo_add_pi_warning,\n",
    "        inputs=[histo_add_pi],\n",
    "        outputs=[]\n",
    "    )\n",
    "\n",
    "    histo_add_normal.change(\n",
    "        fn=toggle_add_normal,\n",
    "        inputs=[histo_add_normal, histo_hat_mu, histo_hat_sigma],\n",
    "        outputs=[histo_hat_mu, histo_hat_mu_text, histo_hat_sigma, histo_hat_sigma_text]\n",
    "    )\n",
    "\n",
    "    histo_add_normal.change(\n",
    "        fn=add_normal_warning,\n",
    "        inputs=histo_add_normal,\n",
    "        outputs=[]\n",
    "    )\n",
    "\n",
    "    histo_hat_mu.change(\n",
    "        fn=lambda choice: gr.update(visible=(choice == \"Other\")),\n",
    "        inputs=histo_hat_mu,\n",
    "        outputs=histo_hat_mu_text\n",
    "    )\n",
    "\n",
    "    histo_hat_sigma.change(\n",
    "        fn=lambda choice: gr.update(visible=(choice == \"Other\")),\n",
    "        inputs=histo_hat_sigma,\n",
    "        outputs=histo_hat_sigma_text\n",
    "    )\n",
    "\n",
    "    ecdf_add_conf.change(\n",
    "        fn=lambda check: gr.update(visible=check),\n",
    "        inputs=ecdf_add_conf,\n",
    "        outputs=ecdf_alpha\n",
    "    )\n",
    "\n",
    "    ecdf_add_normal.change(\n",
    "        fn=toggle_add_normal,\n",
    "        inputs=[ecdf_add_normal, ecdf_hat_mu, ecdf_hat_sigma],\n",
    "        outputs=[ecdf_hat_mu, ecdf_hat_mu_text, ecdf_hat_sigma, ecdf_hat_sigma_text]\n",
    "    )\n",
    "\n",
    "    ecdf_add_normal.change(\n",
    "        fn=add_normal_warning,\n",
    "        inputs=ecdf_add_normal,\n",
    "        outputs=[]\n",
    "    )\n",
    "\n",
    "    ecdf_hat_mu.change(\n",
    "        fn=lambda choice: gr.update(visible=(choice == \"Other\")),\n",
    "        inputs=ecdf_hat_mu,\n",
    "        outputs=ecdf_hat_mu_text\n",
    "    )\n",
    "\n",
    "    ecdf_hat_sigma.change(\n",
    "        fn=lambda choice: gr.update(visible=(choice == \"Other\")),\n",
    "        inputs=ecdf_hat_sigma,\n",
    "        outputs=ecdf_hat_sigma_text\n",
    "    )\n",
    "\n",
    "    # --- Run Analysis Button ---\n",
    "    run_graph_stat_button.click(\n",
    "        run_graph_stat,\n",
    "        inputs=[\n",
    "            column_dropdown,\n",
    "            graph_stat_dropdown,\n",
    "            histo_add_kde, histo_add_data,\n",
    "            histo_add_ci, histo_choose_ci,\n",
    "            histo_add_pi, histo_choose_pi,\n",
    "            histo_add_normal,\n",
    "            histo_hat_mu, histo_hat_mu_text,\n",
    "            histo_hat_sigma, histo_hat_sigma_text,\n",
    "            ecdf_add_conf,\n",
    "            ecdf_alpha,\n",
    "            ecdf_add_normal,\n",
    "            ecdf_hat_mu, ecdf_hat_mu_text,\n",
    "            ecdf_hat_sigma, ecdf_hat_sigma_text          \n",
    "        ],\n",
    "        outputs=[results_block, output_table, output_table, output_plot, output_plot])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b2f7179",
   "metadata": {},
   "source": [
    "## Logic control of Descriptive Tab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "03211694",
   "metadata": {},
   "outputs": [],
   "source": [
    "def toggle_desc_params(desc_stat):\n",
    "    if desc_stat == \"Quantiles\":\n",
    "        return (\n",
    "            gr.update(visible=True),  # quantiles input\n",
    "            gr.update(visible=False), # weights input\n",
    "            gr.update(visible=False), # trim input\n",
    "            gr.update(visible=False)  # winsorized input\n",
    "        )\n",
    "    elif desc_stat in [\"Central Tendency\", \"All Descriptive Statistics\"]:\n",
    "        return (\n",
    "            gr.update(visible=False),  \n",
    "            gr.update(visible=True), \n",
    "            gr.update(visible=True), \n",
    "            gr.update(visible=True)\n",
    "        )\n",
    "    else:\n",
    "        return (\n",
    "            gr.update(visible=False),  \n",
    "            gr.update(visible=False), \n",
    "            gr.update(visible=False), \n",
    "            gr.update(visible=False)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6a13dab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_weights(input_str, length):\n",
    "    if not input_str.strip():\n",
    "        return None\n",
    "    weights = [float(w.strip()) for w in input_str.split(',') if w.strip()]\n",
    "    if len(weights) != length:\n",
    "        raise ValueError(f\"Number of weights ({len(weights)}) must match number of observations ({length})\")\n",
    "    return weights\n",
    "\n",
    "def parse_winsor(input_str):\n",
    "    if not input_str.strip():\n",
    "        return None\n",
    "    winsor_param = [float(w.strip()) for w in input_str.split(',') if w.strip()]\n",
    "    if len(winsor_param) != 2:\n",
    "        raise ValueError(f\"Length of winsorized input ({len(winsor_param)}) must be two (lower, and upper)\")\n",
    "    return winsor_param\n",
    "\n",
    "def parse_quantiles(input_str):\n",
    "    if ',' in input_str:\n",
    "        q = [float(x.strip()) for x in input_str.split(',') if x.strip()]\n",
    "    else:\n",
    "        q = float(input_str)\n",
    "    return q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d4bbfcdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_desc_stat(\n",
    "        column,\n",
    "        descriptive_stat,\n",
    "        quantiles_input, weights_input, trim_input, winsor_input\n",
    "        ):\n",
    "    \n",
    "    df, data, stats, error_df, error_plot = prepare_data(column)\n",
    "    if error_df:\n",
    "        return error_df, error_plot\n",
    "\n",
    "    # --- Descriptive Analysis ---\n",
    "    \n",
    "    if descriptive_stat == \"Quantiles\":\n",
    "        q = parse_quantiles(quantiles_input)\n",
    "        stats.CalculateQuantiles(q)\n",
    "        df_output = stats.quantiles.round(ROUND).reset_index().rename(columns={\"index\": \"Measure\"})\n",
    "\n",
    "    elif descriptive_stat == \"Quartiles\":\n",
    "        stats.CalculateQuartiles()\n",
    "        df_output = stats.quartiles.round(ROUND).reset_index().rename(columns={\"index\": \"Measure\"})\n",
    "\n",
    "    elif descriptive_stat == \"Central Tendency\":\n",
    "        trim_param = parse_text(trim_input)\n",
    "        winsor_param = parse_winsor(winsor_input)\n",
    "        weights = parse_weights(weights_input, len(data))\n",
    "\n",
    "        stats.CalculateCentralTendency(weights=weights, winsor_param=winsor_param, trim_param=trim_param)\n",
    "        df_output = stats.central_tendency.round(ROUND).reset_index().rename(columns={\"index\": \"Measure\"})\n",
    "\n",
    "    elif descriptive_stat == \"Dispersion\":\n",
    "        stats.CalculateDispersion()\n",
    "        df_output = stats.dispersion.round(ROUND).reset_index().rename(columns={\"index\": \"Measure\"})\n",
    "\n",
    "    elif descriptive_stat == \"Skewness\":\n",
    "        stats.CalculateSkewness()\n",
    "        df_output = stats.skew.round(ROUND).reset_index().rename(columns={\"index\": \"Measure\"})\n",
    "\n",
    "    elif descriptive_stat == \"Kurtosis\":\n",
    "        stats.CalculateKurtosis()\n",
    "        df_output = stats.kurtosis.round(ROUND).reset_index().rename(columns={\"index\": \"Measure\"})\n",
    "\n",
    "    elif descriptive_stat == \"All Descriptive Statistics\":\n",
    "        trim_param = parse_text(trim_input)\n",
    "        winsor_param = parse_winsor(winsor_input)\n",
    "        weights = parse_weights(weights_input, len(data))\n",
    "\n",
    "        stats.CalculateDescriptiveStatistics(weights=weights, winsor_param=winsor_param, trim_param=trim_param)\n",
    "\n",
    "        # Merge all tables with a hierarchical index\n",
    "        df_combined = pd.concat([\n",
    "            stats.quartiles,\n",
    "            stats.central_tendency,\n",
    "            stats.dispersion,\n",
    "            stats.skew,\n",
    "            stats.kurtosis\n",
    "        ], keys=[\"Quartiles\", \"Central Tendency\", \"Dispersion\", \"Skewness\", \"Kurtosis\"])\n",
    "\n",
    "        df_output = df_combined.round(ROUND).reset_index().rename(columns={\"level_0\": \"Statistic Type\", \"level_1\": \"Measure\"})\n",
    "\n",
    "    # results_block, output_table, output_table, output_plot, output_plot\n",
    "    return gr.update(visible=True), gr.update(visible=True), df_output, gr.update(visible=False), None "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40df50f4",
   "metadata": {},
   "source": [
    "## GUI of Descriptive Tab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3e2e9d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_descriptive_tab():\n",
    "    with gr.TabItem(\"🧮 Descriptive Analysis\"):\n",
    "        with gr.Group():\n",
    "            gr.Markdown(\"# 🧮 Descriptive Analysis\")\n",
    "            #with gr.Accordion(\"🔢 Numeric Parameters\", open=True):\n",
    "            with gr.Row():\n",
    "                refresh_columns_button = gr.Button(\"🔄 Refresh Numeric Columns\")\n",
    "                column_dropdown = gr.Dropdown(label=\"Select Numeric Column\", choices=[])\n",
    "\n",
    "                descriptive_stat = gr.Dropdown(\n",
    "                    label=\"Select Descriptive Statistic\",\n",
    "                    choices=[\n",
    "                        \"Quantiles\",\n",
    "                        \"Quartiles\",\n",
    "                        \"Central Tendency\",\n",
    "                        \"Dispersion\",\n",
    "                        \"Skewness\",\n",
    "                        \"Kurtosis\",\n",
    "                        \"All Descriptive Statistics\"\n",
    "                    ],\n",
    "                    value=\"All Descriptive Statistics\",\n",
    "                    interactive=True\n",
    "                )\n",
    "                quantiles_input = gr.Textbox(label=\"Quantiles (e.g., 0.25, 0.5, 0.75)\", value=\"0.25, 0.5, 0.75\", visible=False)\n",
    "\n",
    "            with gr.Row() as desc_stat_options:\n",
    "                weights_input = gr.Textbox(label=\"Weights (comma-separated)\", placeholder=\"e.g., 1, 1, 0.5, 0.8\", visible=True)\n",
    "                trim_input = gr.Textbox(label=\"Trim percentage (e.g., 0.1)\", value=0.1, visible=True)\n",
    "                winsor_input = gr.Textbox(label=\"Winsorized percentages (e.g., 0.1, 0.1)\", value=\"0.1, 0.1\", visible=True)\n",
    "\n",
    "            run_desc_stat_button = gr.Button(value=\" 🚀 Run Descriptive Analysis\")\n",
    "\n",
    "        # --- Results ---\n",
    "        with gr.Group(visible=False) as results_block:\n",
    "            gr.Markdown(\"# 🎯 Results\")\n",
    "            output_table = gr.Dataframe()\n",
    "            output_plot = gr.Plot()\n",
    "\n",
    "    # --- Modify behavior of components of the GUI ---\n",
    "    refresh_columns_button.click(\n",
    "        fn=load_numeric_cols,\n",
    "        inputs=[],\n",
    "        outputs=[column_dropdown]\n",
    "    )\n",
    "\n",
    "    descriptive_stat.change(\n",
    "        fn=toggle_desc_params,\n",
    "        inputs=descriptive_stat,\n",
    "        outputs=[quantiles_input, weights_input, trim_input, winsor_input]\n",
    "    )\n",
    "\n",
    "    # --- Run Analysis Button ---\n",
    "    run_desc_stat_button.click(\n",
    "        run_desc_stat,\n",
    "        inputs=[\n",
    "            column_dropdown,\n",
    "            descriptive_stat,\n",
    "            quantiles_input, weights_input, trim_input, winsor_input\n",
    "        ],\n",
    "        outputs=[results_block, output_table, output_table, output_plot, output_plot]\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8da322cf",
   "metadata": {},
   "source": [
    "## Logic control of Statistical Inference Tab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b904f228",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stat_inf_warning(check):\n",
    "    if check:\n",
    "        gr.Warning(\"If you haven't done it yet, run first a descriptive analysis for central tendency and dispersion.\")\n",
    "\n",
    "def conf_interval_warning(check):\n",
    "    if check == \"Confidence Regions\":\n",
    "        gr.Warning(\"If you haven't done it yet, run first a statistical inference for CI.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "437e826d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def toggle_stat_inf(sel):\n",
    "    if sel in [\"Confidence Interval\", \"Prediction Interval\", \"Confidence and Prediction Intervals\"]:\n",
    "        return gr.update(visible=True), gr.update(visible=False)\n",
    "    elif sel == \"Confidence Regions\":\n",
    "        return gr.update(visible=False), gr.update(visible=True)\n",
    "    else:\n",
    "        return gr.update(visible=True), gr.update(visible=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "79bb3d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_probs(input_str):\n",
    "    if not input_str.strip():\n",
    "        return None\n",
    "    probs = [float(w.strip()) for w in input_str.split(',') if w.strip()]\n",
    "    return probs\n",
    "\n",
    "def parse_margin(input_str):\n",
    "    if not input_str.strip():\n",
    "        return None\n",
    "    eps = [float(w.strip()) for w in input_str.split(',') if w.strip()]\n",
    "    if len(eps) != 2:\n",
    "        raise ValueError(f\"Length of margin ({len(eps)}) must be two (μ,σ)\")\n",
    "    return eps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c63d5484",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_stat_inf(\n",
    "        column,\n",
    "        statistical_inf,\n",
    "        alpha_input,\n",
    "        probs_input, eps_input,\n",
    "        like_add_interval,\n",
    "        mean_select, mean_estimate_text,\n",
    "        median_select, median_estimate_text,\n",
    "        sigma_select, sigma_estimate_text\n",
    "        ):\n",
    "    \n",
    "    df, data, stats, error_df, error_plot = prepare_data(column)\n",
    "    if error_df:\n",
    "        return error_df, error_plot\n",
    "\n",
    "    # --- Statistical Inference ---\n",
    "    \n",
    "    alpha = parse_text(alpha_input)\n",
    "    alpha = 1 - alpha\n",
    "    if alpha is None or not (0 < alpha < 1):\n",
    "        return pd.DataFrame([[\"Invalid alpha value.\"]], columns=[\"Error\"])\n",
    "\n",
    "    # Choose mean\n",
    "    if mean_select == \"Sample Mean\":\n",
    "        hat_mean = stats.mean\n",
    "    if mean_select == \"Geometric Mean\":\n",
    "        hat_mean = stats.geometric_mean\n",
    "    if mean_select == \"Harmonic Mean\":\n",
    "        hat_mean = stats.harmonic_mean\n",
    "    if mean_select == \"Weighted Mean\":\n",
    "        hat_mean = stats.weighted_mean\n",
    "    if mean_select == \"Trimmed Mean\":\n",
    "        hat_mean = stats.trimmed_mean\n",
    "    if mean_select == \"Interquartile Mean\":\n",
    "        hat_mean = stats.interquartile_mean\n",
    "    if mean_select == \"Winsorized Mean\":\n",
    "        hat_mean = stats.winsorized_mean\n",
    "    elif mean_select == \"Other\":\n",
    "        hat_mean = float(mean_estimate_text)\n",
    "    \n",
    "    # Choose median\n",
    "    if median_select == \"Sample Median\":\n",
    "        hat_median = stats.median\n",
    "    elif  median_select == \"Other\":\n",
    "        hat_median = float(median_estimate_text)\n",
    "    \n",
    "    # Choose sigma\n",
    "    if sigma_select == \"Deviation (1 ddof)\":\n",
    "        hat_sigma = stats.S1\n",
    "    elif sigma_select == \"Range (bias corrected)\":\n",
    "        hat_sigma = stats.R_bias_corrected\n",
    "    elif sigma_select == \"IQR (bias corrected)\":\n",
    "        hat_sigma = stats.IQR_bias_corrected\n",
    "    elif sigma_select == \"MAD (bias corrected)\":\n",
    "        hat_sigma = stats.MAD_bias_corrected\n",
    "    elif sigma_select == \"AAD (bias corrected)\":\n",
    "        hat_sigma = stats.AAD_bias_corrected\n",
    "    elif sigma_select == \"Other\":\n",
    "        hat_sigma = float(sigma_estimate_text)\n",
    "        \n",
    "    if (mean_select == \"Sample Mean\") and (sigma_select == \"Deviation (1 ddof)\"):\n",
    "        dist=\"t\"\n",
    "    else:\n",
    "        dist=\"norm\"\n",
    "\n",
    "    if statistical_inf == \"Confidence Interval\":\n",
    "        stats.CalculateConfidenceInterval(alpha, hat_mean, hat_median, hat_sigma, dist)\n",
    "        df_output = stats.confidence_intervals.round(ROUND).reset_index().rename(columns={\"index\": \"Measure\"})\n",
    "        fig = None\n",
    "        visible_table = True\n",
    "        visible_fig = False\n",
    "\n",
    "    elif statistical_inf == \"Prediction Interval\":\n",
    "        stats.CalculatePredictionInterval(alpha, hat_mean, hat_median, hat_sigma, dist)\n",
    "        df_output = stats.prediction_intervals.round(ROUND).reset_index().rename(columns={\"index\": \"Measure\"})\n",
    "        fig = None\n",
    "        visible_table = True\n",
    "        visible_fig = False\n",
    "\n",
    "    elif statistical_inf == \"Confidence and Prediction Intervals\":\n",
    "        stats.CalculateConfidenceInterval(alpha, hat_mean, hat_median, hat_sigma, dist)\n",
    "        stats.CalculatePredictionInterval(alpha, hat_mean, hat_median, hat_sigma, dist)\n",
    "\n",
    "        # Merge all tables with a hierarchical index\n",
    "        df_combined = pd.concat([\n",
    "            stats.confidence_intervals,\n",
    "            stats.prediction_intervals\n",
    "        ], keys=[\"Confidence\", \"Prediction\"])\n",
    "    \n",
    "        df_output = df_combined.round(ROUND).reset_index().rename(columns={\"level_0\": \"Interval Type\", \"level_1\": \"Measure\"})\n",
    "        fig = None\n",
    "        visible_table = True\n",
    "        visible_fig = False\n",
    "\n",
    "    elif statistical_inf == \"Confidence Regions\":\n",
    "        probs = parse_probs(probs_input)\n",
    "        eps = parse_margin(eps_input)\n",
    "        fig = stats.PlotConfidenceRegions(probs, eps, like_add_interval)\n",
    "        df_output = pd.DataFrame()\n",
    "        visible_table = False \n",
    "        visible_fig = True\n",
    "    \n",
    "    elif statistical_inf == \"Confidence Interval and Regions\":\n",
    "        probs = parse_probs(probs_input)\n",
    "        eps = parse_margin(eps_input)\n",
    "        stats.CalculateConfidenceInterval(alpha, hat_mean, hat_median, hat_sigma, dist)\n",
    "        df_output = stats.confidence_intervals.round(ROUND).reset_index().rename(columns={\"index\": \"Measure\"})\n",
    "        fig = stats.PlotConfidenceRegions(probs, eps, like_add_interval)\n",
    "        visible_table = True\n",
    "        visible_fig = True\n",
    "\n",
    "    # results_block, output_table, output_table, output_plot, output_plot\n",
    "    return gr.update(visible=True), gr.update(visible=visible_table), df_output, gr.update(visible=visible_fig), fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dccce95f",
   "metadata": {},
   "source": [
    "## GUI of Statistical Inference Tab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "467c4bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_inference_tab():\n",
    "    with gr.TabItem(\"💭 Statistical Inference\"):\n",
    "        with gr.Group():\n",
    "            gr.Markdown(\"# 💭 Statistical Inference\")\n",
    "\n",
    "            with gr.Accordion(\"🧠 Technical Information\", open=False):\n",
    "                gr.Markdown(\n",
    "                    \"\"\"\n",
    "                    - All intervals are calculated assuming the observations are i.i.d. from a Normal distribution.  \n",
    "                    - If the sample mean and the sample deviation with one degree of freedom are selected as estimators for the mean and standard deviation, \n",
    "                    then a *t*-distribution is used to compute the Confidence Interval (CI) for the mean and the Prediction Interval (PI) based on the mean.  \n",
    "                    - The asymptotic Normal distribution is used for the CI and PI based on the median.\n",
    "                    \"\"\"\n",
    "                )\n",
    "\n",
    "            with gr.Row():\n",
    "                refresh_columns_button = gr.Button(\"🔄 Refresh Numeric Columns\")\n",
    "                column_dropdown = gr.Dropdown(label=\"Select Numeric Column\", choices=[])\n",
    "                \n",
    "                stat_inf_dropdown = gr.Dropdown(\n",
    "                    label=\"Type of Estimation\",\n",
    "                    choices=[\n",
    "                        \"Confidence Interval\",\n",
    "                        \"Prediction Interval\",\n",
    "                        \"Confidence and Prediction Intervals\",\n",
    "                        \"Confidence Regions\",\n",
    "                        \"Confidence Interval and Regions\"\n",
    "                    ],\n",
    "                    value=\"Confidence and Prediction Intervals\",\n",
    "                    interactive=True\n",
    "                )\n",
    "\n",
    "            with gr.Row(visible=True) as stat_inf_intervals:\n",
    "                alpha_input = gr.Textbox(label=\"Confidence level (e.g. 0.95)\", value=0.95, interactive=True)\n",
    "                mean_select = gr.Dropdown(\n",
    "                    choices=[\n",
    "                        \"Sample Mean\",\n",
    "                        \"Geometric Mean\",\n",
    "                        \"Harmonic Mean\",\n",
    "                        \"Weighted Mean\",\n",
    "                        \"Trimmed Mean\",\n",
    "                        \"Interquartile Mean\",\n",
    "                        \"Winsorized Mean\",\n",
    "                        \"Other\"\n",
    "                        ],\n",
    "                    label=\"Mean Estimate\",\n",
    "                    value=\"Sample Mean\"\n",
    "                )\n",
    "\n",
    "                mean_estimate_text = gr.Textbox(label=\"Write the value of a consistent estimator\", visible=False)\n",
    "\n",
    "                median_select = gr.Dropdown(\n",
    "                    choices=[\"Sample Median\", \"Other\"],\n",
    "                    label=\"Median Estimate\", value=\"Sample Median\"\n",
    "                )\n",
    "                median_estimate_text = gr.Textbox(label=\"Write the value of a consistent estimator\", visible=False)\n",
    "\n",
    "                sigma_select = gr.Dropdown(\n",
    "                    choices=[\n",
    "                        \"Deviation (1 ddof)\",\n",
    "                        \"Range (bias corrected)\",\n",
    "                        \"IQR (bias corrected)\",\n",
    "                        \"MAD (bias corrected)\",\n",
    "                        \"AAD (bias corrected)\",\n",
    "                        \"Other\"\n",
    "                    ],\n",
    "                    label=\"Deviation Estimate\",\n",
    "                    value=\"Deviation (1 ddof)\"\n",
    "                )\n",
    "                sigma_estimate_text = gr.Textbox(label=\"Write the value of a consistent estimator\", visible=False)\n",
    "\n",
    "            with gr.Row(visible=False) as stat_inf_regions:\n",
    "                like_probs = gr.Textbox(label=\"Confidence levels (from lower to higher)\", value=\"0.1, 0.5, 0.75, 0.89, 0.95\", interactive=True, visible=True)\n",
    "                like_eps = gr.Textbox(label=\"Extra margin for μ and σ\", value=\"0.1, 0.05\", interactive=True, visible=True)\n",
    "                like_add_interval = gr.Checkbox(label=\"Add CI for μ and σ\", value=True)\n",
    "\n",
    "            run_stat_inf_button = gr.Button(value=\" 🚀 Run Statistical Inference\")\n",
    "        \n",
    "        # --- Results ---\n",
    "        with gr.Group(visible=False) as results_block:\n",
    "            gr.Markdown(\"# 🎯 Results\")\n",
    "            output_table = gr.Dataframe()\n",
    "            output_plot = gr.Plot()\n",
    "\n",
    "    # --- Modify behavior of components of the GUI ---\n",
    "    refresh_columns_button.click(\n",
    "        fn=load_numeric_cols,\n",
    "        inputs=[],\n",
    "        outputs=[column_dropdown]\n",
    "    )\n",
    "\n",
    "    column_dropdown.change(\n",
    "        fn=stat_inf_warning,\n",
    "        inputs=[column_dropdown],\n",
    "        outputs=[]\n",
    "    )\n",
    "\n",
    "    stat_inf_dropdown.change(\n",
    "        fn=conf_interval_warning,\n",
    "        inputs=[stat_inf_dropdown],\n",
    "        outputs=[]\n",
    "    )\n",
    "\n",
    "    stat_inf_dropdown.change(\n",
    "        fn=toggle_stat_inf,\n",
    "        inputs=stat_inf_dropdown,\n",
    "        outputs=[stat_inf_intervals, stat_inf_regions]\n",
    "    )\n",
    "\n",
    "    mean_select.change(\n",
    "        fn=lambda choice: gr.update(visible=(choice == \"Other\")),\n",
    "        inputs=mean_select,\n",
    "        outputs=mean_estimate_text\n",
    "    )\n",
    "\n",
    "    median_select.change(\n",
    "        fn=lambda choice: gr.update(visible=(choice == \"Other\")),\n",
    "        inputs=median_select,\n",
    "        outputs=median_estimate_text\n",
    "    )\n",
    "\n",
    "    sigma_select.change(\n",
    "        fn=lambda choice: gr.update(visible=(choice == \"Other\")),\n",
    "        inputs=sigma_select,\n",
    "        outputs=sigma_estimate_text\n",
    "    )\n",
    "\n",
    "    # --- Run Analysis Button ---\n",
    "    run_stat_inf_button.click(\n",
    "        run_stat_inf,\n",
    "        inputs=[\n",
    "            column_dropdown,\n",
    "            stat_inf_dropdown,\n",
    "            alpha_input,\n",
    "            like_probs, like_eps,\n",
    "            like_add_interval,\n",
    "            mean_select, mean_estimate_text,\n",
    "            median_select, median_estimate_text,\n",
    "            sigma_select, sigma_estimate_text\n",
    "        ],\n",
    "        outputs=[results_block, output_table, output_table, output_plot, output_plot]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6ba6208d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_hypothesis_tab():\n",
    "    with gr.TabItem(\"🧪 Hypothesis Testing\"):\n",
    "        with gr.Group():\n",
    "            gr.Markdown(\"# 🧪 Hypothesis Testing\")\n",
    "            gr.Markdown(\"# 🚧 On construction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e48d978b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_regression_tab():\n",
    "    with gr.TabItem(\"📈 Linear Regression\"):\n",
    "        with gr.Group():\n",
    "            gr.Markdown(\"# 📈 Linear Regression\")\n",
    "            gr.Markdown(\"# 🚧 On construction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63520ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with gr.Blocks() as demo:\n",
    "    with gr.Tabs():\n",
    "        build_data_tab()\n",
    "        build_graphical_tab()\n",
    "        build_descriptive_tab()\n",
    "        build_inference_tab()\n",
    "        build_hypothesis_tab()\n",
    "        build_regression_tab()\n",
    "\n",
    "    gr.Markdown(\"### 🤓 Created by Irving Gómez Méndez, version 2.1.0, June 2025.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ffafe234",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demo.launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
