{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "21f60193",
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# To plot\n",
        "import seaborn as sns\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# To create GUI\n",
        "import gradio as gr\n",
        "\n",
        "# To integrate a function\n",
        "from scipy.integrate import quad, dblquad\n",
        "\n",
        "# Gamma function\n",
        "from scipy.special import gamma, loggamma\n",
        "\n",
        "# To calculate statistics\n",
        "from scipy.stats import norm, t, chi2\n",
        "from scipy.stats import hmean, trim_mean, iqr, median_abs_deviation, skew, kurtosis\n",
        "from scipy.stats.mstats import gmean, winsorize\n",
        "from statsmodels.distributions import ECDF\n",
        "\n",
        "# To make hypothesis testing\n",
        "import pingouin as pg\n",
        "from scipy.stats import bartlett, levene\n",
        "from scipy.stats import gaussian_kde\n",
        "\n",
        "# To make linear regression\n",
        "import statsmodels.api as sm\n",
        "import statsmodels.formula.api as smf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "b49df773",
      "metadata": {},
      "outputs": [],
      "source": [
        "ROUND = 4 # Number of decimals to round the results\n",
        "\n",
        "df_cache = {\n",
        "    \"df\": None,\n",
        "    \"filtered_df\": None,\n",
        "    \"stats\": None,\n",
        "    \"numeric_cols\": [],\n",
        "    \"categorical_cols\": [],\n",
        "    \"overrides\": {\n",
        "        \"num_to_cat\": [],\n",
        "        \"cat_to_num\": []\n",
        "    }\n",
        "}\n",
        "\n",
        "export_cache = {\n",
        "    \"table\": None,\n",
        "    \"figure\": None\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1cac4b5c",
      "metadata": {},
      "source": [
        "# ðŸ§  ðŸ“ ðŸ“Š ðŸ§® ðŸ’­ Statistics class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "dea68472",
      "metadata": {},
      "outputs": [],
      "source": [
        "class Statistics():\n",
        "    def __init__(self, data):\n",
        "        self.data = data    \n",
        "        self.n = len(data)  \n",
        "\n",
        "    # --- Descriptive Statistics ---    \n",
        "\n",
        "    # --- Quantiles ---\n",
        "    def CalculateQuantiles(self, prob):\n",
        "        prob = np.atleast_1d(prob)\n",
        "        self.quantiles = pd.DataFrame({\"Value\": np.quantile(self.data, prob)}, [f\"Q{p}\" for p in prob])\n",
        "\n",
        "    # --- Quartiles ---\n",
        "    def CalculateQuartiles(self):\n",
        "        self.quartiles = pd.DataFrame({'Value': np.quantile(self.data, [0.25,0.5,0.75])},['Q1', 'Q2', 'Q3'])\n",
        "\n",
        "    # --- Central Tendency ---\n",
        "    def CalculateCentralTendency(self, trim_param=0.1, winsor_param=[0.1,0.1], weights=None):\n",
        "\n",
        "        #Mode = mode(data) # To calculate the mode \n",
        "        self.mean = self.data.mean()\n",
        "        self.median = np.median(self.data)\n",
        "        self.interquartile_mean = trim_mean(self.data, 0.25)\n",
        "        \n",
        "        if trim_param is None:\n",
        "            self.trim_param = None\n",
        "            self.trimmed_mean = np.nan\n",
        "        else:\n",
        "            self.trim_param = trim_param\n",
        "            self.trimmed_mean = trim_mean(self.data, trim_param)\n",
        "\n",
        "        if winsor_param is None:\n",
        "            self.winsor_param = None\n",
        "            self.winsorized_mean = np.nan\n",
        "        else:\n",
        "            # Winsorized data\n",
        "            self.data_winsorized = winsorize(self.data, winsor_param)\n",
        "            self.winsorized_mean = self.data_winsorized.mean()\n",
        "            \n",
        "        if np.all(self.data > 0): # If all observations are greater than zero, calculate geometric and harmonic mean\n",
        "            self.geometric_mean = gmean(self.data)\n",
        "            self.harmonic_mean = hmean(self.data)\n",
        "        else:\n",
        "            self.geometric_mean = np.nan\n",
        "            self.harmonic_mean = np.nan\n",
        "\n",
        "        if weights is None:\n",
        "            self.weighted_mean = np.nan\n",
        "        else:\n",
        "            self.weighted_mean = np.average(self.data, weights=weights)\n",
        "\n",
        "        # Write the statistics in a list\n",
        "        central_tendency = [\n",
        "            self.mean,\n",
        "            self.median,\n",
        "            self.geometric_mean,\n",
        "            self.harmonic_mean,\n",
        "            self.weighted_mean,\n",
        "            self.trimmed_mean,\n",
        "            self.interquartile_mean,\n",
        "            self.winsorized_mean\n",
        "        ]\n",
        "\n",
        "        # Return the statistics as a table\n",
        "        labels = ['Mean', 'Median', 'Geometric Mean', 'Harmonic Mean', 'Weighted Mean', 'Trimmed Mean', 'Interquartile Mean', 'Winsorized Mean']\n",
        "        self.central_tendency = pd.DataFrame({'Value':central_tendency, 'Robust':[0, 1, 0, 0, 0, 1, 1, 1]}, labels)\n",
        "\n",
        "    # --- Dispersion ---\n",
        "    # Auxiliary functions to correct the bias\n",
        "    def c4(self, n):\n",
        "        return np.exp(np.log(np.sqrt(2/(n-1))) + loggamma(n/2) - loggamma((n-1)/2))\n",
        "        #return np.sqrt(2/(n-1)) * gamma(n/2) / gamma((n-1)/2)\n",
        "\n",
        "    def d2(self, n):\n",
        "        f = lambda x, n: 1 - (1 - norm.cdf(x))**n - (norm.cdf(x))**n\n",
        "        return round(quad(f, -np.inf, np.inf, args=(n,))[0], 3)\n",
        "\n",
        "    def CalculateDispersion(self):\n",
        "        # Original estimators\n",
        "        self.S0 = np.std(self.data)             # By default the standard deviation is calculated with zero degrees of freedom\n",
        "        self.S1 = np.std(self.data, ddof=1)     # Standard deviation with one degree of freedom\n",
        "        self.R = self.data.max() - self.data.min()\n",
        "        self.IQR = iqr(self.data)                \n",
        "        self.MAD = median_abs_deviation(self.data)   \n",
        "        self.AAD = abs(self.data - self.data.mean()).mean()\n",
        "\n",
        "        # Bias correction\n",
        "        self.S0_bias_correct = self.S0 * np.sqrt(self.n/(self.n-1)) / self.c4(self.n)\n",
        "        self.S1_bias_corrected = self.S1 / self.c4(self.n)\n",
        "        self.R_bias_corrected = self.R / self.d2(self.n)\n",
        "        self.IQR_bias_corrected = self.IQR / (2 * norm.ppf(0.75))\n",
        "        self.MAD_bias_corrected = self.MAD / norm.ppf(0.75)\n",
        "        self.AAD_bias_corrected = self.AAD * np.sqrt(np.pi/2)\n",
        "\n",
        "        # Write the statistics in a list\n",
        "        sigma_biased = [self.S0, self.S1, self.R, self.IQR, self.MAD, self.AAD]\n",
        "        sigma_unbiased = [\n",
        "            self.S0_bias_correct,\n",
        "            self.S1_bias_corrected,\n",
        "            self.R_bias_corrected,\n",
        "            self.IQR_bias_corrected,\n",
        "            self.MAD_bias_corrected,\n",
        "            self.AAD_bias_corrected\n",
        "        ] \n",
        "\n",
        "        # Return the statistics as a table\n",
        "        labels = ['Deviation, ddof=0', 'Deviation, ddof=1', 'Range', 'IQR', 'MAD', 'AAD']\n",
        "        self.dispersion = pd.DataFrame({'Value':sigma_biased, 'Value_bias_corrected':sigma_unbiased, 'Robust':[0,0,0,1,1,1]}, labels)\n",
        "\n",
        "    # --- Skew ---\n",
        "    def CalculateSkewness(self):\n",
        "        SkewCentralMoments = skew(self.data)\n",
        "        SkewKStatistics = skew(self.data, bias=False)\n",
        "\n",
        "        self.skew = pd.DataFrame({'Value':[SkewCentralMoments, SkewKStatistics]}, ['Skew Central Moments', 'Skew K Statistics'])\n",
        "    \n",
        "    # --- Kurtosis ---\n",
        "    def CalculateKurtosis(self):\n",
        "        KurtosisCentralMoments = kurtosis(self.data, fisher=False)\n",
        "        KurtosisKStatistics = kurtosis(self.data, fisher=False, bias=False)\n",
        "\n",
        "        self.kurtosis = pd.DataFrame(\n",
        "            {'Value':[KurtosisCentralMoments, KurtosisKStatistics], 'Excess Kurtosis':[KurtosisCentralMoments-3, KurtosisKStatistics-3]},\n",
        "            ['Kurtosis Central Moments', 'Kurtosis K Statistics']\n",
        "        )\n",
        "\n",
        "    def CalculateDescriptiveStatistics(self, trim_param, winsor_param, weights):\n",
        "        self.CalculateQuartiles()\n",
        "        self.CalculateCentralTendency(trim_param, winsor_param, weights)\n",
        "        self.CalculateDispersion()\n",
        "        self.CalculateSkewness()\n",
        "        self.CalculateKurtosis()\n",
        "\n",
        "    # --- Statistical Inference ---\n",
        "\n",
        "    # --- Confidence Intervals ---\n",
        "    def CalculateCiMean(self, alpha, hat_mean, hat_sigma, dist, sel, boots, bootstrap_samples):\n",
        "\n",
        "        if boots:\n",
        "            if sel == \"Sample Mean\":\n",
        "                boot_means = np.array([\n",
        "                    np.mean(np.random.choice(self.data, size=self.n, replace=True)) for _ in range(bootstrap_samples)\n",
        "                    ])\n",
        "            elif sel == \"Geometric Mean\":\n",
        "                if np.all(self.data > 0):\n",
        "                    boot_means = np.array([\n",
        "                        gmean(np.random.choice(self.data, size=self.n, replace=True)) for _ in range(bootstrap_samples)\n",
        "                    ])\n",
        "                else:\n",
        "                    self.ci_mean = np.nan, np.nan\n",
        "            elif sel == \"Harmonic Mean\":\n",
        "                if np.all(self.data > 0):\n",
        "                    boot_means = np.array([\n",
        "                        hmean(np.random.choice(self.data, size=self.n, replace=True)) for _ in range(bootstrap_samples)\n",
        "                    ])\n",
        "                else:\n",
        "                    self.ci_mean = np.nan, np.nan\n",
        "            elif sel == \"Trimmed Mean\":\n",
        "                if self.trim_param is None:\n",
        "                    self.ci_mean = np.nan, np.nan\n",
        "                else:\n",
        "                    boot_means = np.array([\n",
        "                        trim_mean(np.random.choice(self.data, size=self.n, replace=True), self.trim_param) for _ in range(bootstrap_samples)\n",
        "                    ])\n",
        "            elif sel == \"Interquartile Mean\":\n",
        "                boot_means = np.array([\n",
        "                    trim_mean(np.random.choice(self.data, size=self.n, replace=True), 0.25) for _ in range(bootstrap_samples)\n",
        "                ])\n",
        "            elif sel == \"Winsorized Mean\":\n",
        "                if self.winsor_param is None:\n",
        "                    return np.nan, np.nan\n",
        "                else:\n",
        "                    boot_means = np.array([\n",
        "                        np.mean(np.random.choice(self.data_winsorized, size=self.n, replace=True)) for _ in range(bootstrap_samples)\n",
        "                    ])\n",
        "            self.ci_mean = np.quantile(boot_means, [alpha/2, 1-alpha/2])\n",
        "        else:\n",
        "            # Calculate confidence interval for the mean\n",
        "            scale = hat_sigma / np.sqrt(self.n)\n",
        "\n",
        "            if dist==\"norm\":\n",
        "                self.ci_mean = norm.ppf(alpha/2, hat_mean, scale), norm.ppf(1-alpha/2, hat_mean, scale)\n",
        "            if dist==\"t\":\n",
        "                # Only if we are using standard deviaiton with one degree of freedom without correction\n",
        "                self.ci_mean = t.ppf(alpha/2, self.n-1, hat_mean, scale), t.ppf(1-alpha/2, self.n-1, hat_mean, scale)\n",
        "        \n",
        "    def CalculateCiMedian(self, alpha, hat_median, hat_sigma, boots, bootstrap_samples):\n",
        "        if boots:\n",
        "            boot_medians = np.array([\n",
        "                np.median(np.random.choice(self.data, size=self.n, replace=True)) for _ in range(bootstrap_samples)\n",
        "            ])\n",
        "\n",
        "            self.ci_median = np.quantile(boot_medians, [alpha/2, 1-alpha/2])\n",
        "        else:\n",
        "            # Calculate confidence interval based on the median\n",
        "            scale = hat_sigma * np.sqrt(np.pi/(2*self.n))\n",
        "            self.ci_median = norm.ppf(alpha/2, hat_median, scale), norm.ppf(1-alpha/2, hat_median, scale)\n",
        "\n",
        "    def d3(self, n):\n",
        "        d3_table = {\n",
        "            2: 0.852, 3: 0.888, 4: 0.880, 5: 0.864, 6: 0.848,\n",
        "            7: 0.833, 8: 0.820, 9: 0.808, 10: 0.797,\n",
        "            11: 0.787, 12: 0.778, 13: 0.770, 14: 0.763, 15: 0.756,\n",
        "            16: 0.750, 17: 0.744, 18: 0.739, 19: 0.734, 20: 0.729,\n",
        "            21: 0.724, 22: 0.720, 23: 0.716, 24: 0.712, 25: 0.708\n",
        "        }\n",
        "        return d3_table[n]\n",
        "\n",
        "    def d3_exact(self, n):\n",
        "        \"\"\"Compute the d3 constant (stddev of range) for sample size n of normal distribution.\"\"\"\n",
        "        # PDF and CDF of standard normal\n",
        "        phi = norm.pdf\n",
        "        Phi = norm.cdf\n",
        "\n",
        "        # Expected range squared E[R_n^2]\n",
        "        def integrand2(x2, x1):\n",
        "            return (x2 - x1)**2 * phi(x1) * phi(x2) * (Phi(x2) - Phi(x1))**(n-2)\n",
        "        \n",
        "        ERn2, _ = dblquad(\n",
        "            integrand2,\n",
        "            -np.inf, np.inf,\n",
        "            lambda x1: x1,\n",
        "            lambda x1: np.inf,\n",
        "            epsabs=1e-10, epsrel=1e-8\n",
        "        )\n",
        "        ERn2 = n * (n - 1) * ERn2\n",
        "        \n",
        "        ERn = self.d2(n)\n",
        "        var_Rn = ERn2 - ERn**2\n",
        "        return np.sqrt(var_Rn)\n",
        "\n",
        "    def ci_sigma_from_range(self, alpha):\n",
        "        if self.n <= 25:\n",
        "            d2_n = self.d2(self.n)\n",
        "            d3_n = self.d3(self.n)\n",
        "        else:\n",
        "            d2_n = self.d2(self.n)\n",
        "            d3_n = self.d3_exact(self.n)\n",
        "\n",
        "        z = norm.ppf(1 - alpha / 2)\n",
        "        \n",
        "        denom_lo = d2_n + z * d3_n\n",
        "        denom_hi = d2_n - z * d3_n\n",
        "        \n",
        "        if denom_hi <= 0:\n",
        "            raise ValueError(\"Invalid configuration: upper bound denominator â‰¤ 0\")\n",
        "        \n",
        "        return self.R / denom_lo, self.R / denom_hi\n",
        "\n",
        "    def CalculateCiDeviation(self, alpha, sel, boots, bootstrap_samples):\n",
        "        if boots:\n",
        "            if sel == \"Deviation (1 ddof)\":\n",
        "                boot_deviations = np.array([\n",
        "                        np.std(np.random.choice(self.data, size=self.n, replace=True), ddof=1) for _ in range(bootstrap_samples)\n",
        "                    ])\n",
        "\n",
        "                self.ci_deviation = np.quantile(boot_deviations, [alpha/2, 1-alpha/2]) / self.c4(self.n)\n",
        "                #self.S1 = np.quantile(boot_deviations, 0.5)\n",
        "                #self.S1_bias_corrected = self.S1 / self.c4(self.n)\n",
        "\n",
        "                #self.S0_bias_corrected = self.S1_bias_corrected\n",
        "                #self.S0 = np.sqrt(self.n/(self.n-1))\n",
        "\n",
        "            elif sel == \"Range (bias corrected)\":\n",
        "                boot_deviations = []\n",
        "                for _ in range(bootstrap_samples):\n",
        "                    boot_data = np.random.choice(self.data, size=self.n, replace=True)\n",
        "                    deviation = boot_data.max() - boot_data.min()\n",
        "                    boot_deviations.append(deviation)\n",
        "                boot_deviations = np.array(boot_deviations)\n",
        "\n",
        "                self.ci_deviation = np.quantile(boot_deviations, [alpha/2, 1-alpha/2]) / self.d2(self.n)\n",
        "                #self.R = np.quantile(boot_deviations, 0.5)\n",
        "                #self.R_bias_corrected = self.R / self.d2(self.n)\n",
        "\n",
        "            elif sel == \"IQR (bias corrected)\":\n",
        "                boot_deviations = np.array([\n",
        "                        iqr(np.random.choice(self.data, size=self.n, replace=True)) for _ in range(bootstrap_samples)\n",
        "                    ])\n",
        "\n",
        "                self.ci_deviation = np.quantile(boot_deviations, [alpha/2, 1-alpha/2]) / (2 * norm.ppf(0.75))\n",
        "                #self.IQR = np.quantile(boot_deviations, 0.5)\n",
        "                #self.IQR_bias_corrected = self.IQR / (2 * norm.ppf(0.75))\n",
        "\n",
        "            elif sel == \"MAD (bias corrected)\":\n",
        "                boot_deviations = np.array([\n",
        "                        median_abs_deviation(np.random.choice(self.data, size=self.n, replace=True)) for _ in range(bootstrap_samples)\n",
        "                    ])\n",
        "\n",
        "                self.ci_deviation = np.quantile(boot_deviations, [alpha/2, 1-alpha/2]) / (norm.ppf(0.75))\n",
        "                #self.MAD = np.quantile(boot_deviations, 0.5)\n",
        "                #self.MAD_bias_corrected = self.MAD / (norm.ppf(0.75))\n",
        "\n",
        "            elif sel == \"AAD (bias corrected)\":\n",
        "                boot_deviations = []\n",
        "                for _ in range(bootstrap_samples):\n",
        "                    boot_data = np.random.choice(self.data, size=self.n, replace=True)\n",
        "                    deviation = abs(boot_data - boot_data.mean()).mean()\n",
        "                    boot_deviations.append(deviation)\n",
        "                boot_deviations = np.array(boot_deviations)\n",
        "\n",
        "                self.ci_deviation = np.quantile(boot_deviations, [alpha/2, 1-alpha/2]) * np.sqrt(np.pi/2)\n",
        "                #self.AAD = np.quantile(boot_deviations, 0.5)\n",
        "                #self.AAD_bias_corrected = self.AAD * np.sqrt(np.pi/2)\n",
        "        \n",
        "        else:\n",
        "            if sel == \"Deviation (1 ddof)\":\n",
        "                # Exact Distribution\n",
        "                num = self.S1 * np.sqrt(self.n-1)\n",
        "                den_low = np.sqrt(chi2.ppf(1-alpha/2, self.n-1))\n",
        "                den_upp = np.sqrt(chi2.ppf(alpha/2, self.n-1))\n",
        "\n",
        "                self.ci_deviation = num/den_low, num/den_upp\n",
        "            elif sel == \"Range (bias corrected)\":\n",
        "                # Exact Distribution\n",
        "                self.ci_deviation = self.ci_sigma_from_range(alpha)\n",
        "            elif sel == \"IQR (bias corrected)\":\n",
        "                # Asymptotic Distribution\n",
        "                w = 2 * norm.ppf(0.75)\n",
        "                k = np.sqrt(np.pi/(2*np.exp(-norm.ppf(0.75)**2)))\n",
        "                z = norm.ppf(1-alpha/2)\n",
        "                self.ci_deviation = self.IQR / (w+z*k/np.sqrt(self.n)), self.IQR / (w-z*k/np.sqrt(self.n))\n",
        "            elif sel == \"MAD (bias corrected)\":\n",
        "                # Asymptotic Distribution\n",
        "                w = norm.ppf(0.75)\n",
        "                k = np.sqrt(np.pi/(8*np.exp(-norm.ppf(0.75)**2)))\n",
        "                z = norm.ppf(1-alpha/2)\n",
        "                self.ci_deviation = self.MAD / (w+z*k/np.sqrt(self.n)), self.MAD / (w-z*k/np.sqrt(self.n))\n",
        "            elif sel == \"AAD (bias corrected)\":\n",
        "                # Asymptotic Distribution\n",
        "                w = np.sqrt(2/np.pi)\n",
        "                k = np.sqrt((1-2/np.pi))\n",
        "                z = norm.ppf(1-alpha/2)\n",
        "                self.ci_deviation = self.AAD / (w+z*k/np.sqrt(self.n)), self.AAD / (w-z*k/np.sqrt(self.n))\n",
        "\n",
        "    def CalculateConfidenceInterval(\n",
        "            self, alpha, hat_mean, hat_median, hat_sigma, dist,\n",
        "            mean_select, sigma_select, boots_mean, boots_median, boots_deviation, bootstrap_samples):\n",
        "        self.CalculateCiMean(alpha, hat_mean, hat_sigma, dist, mean_select, boots_mean, bootstrap_samples)\n",
        "        self.CalculateCiMedian(alpha, hat_median, hat_sigma, boots_median, bootstrap_samples)\n",
        "        self.CalculateCiDeviation(alpha, sigma_select, boots_deviation, bootstrap_samples)\n",
        "\n",
        "        # Return the statistics as a table\n",
        "        labels = ['Mean', 'Median', 'Deviation']\n",
        "        self.confidence_intervals = pd.DataFrame(\n",
        "            [self.ci_mean, self.ci_median, self.ci_deviation],\n",
        "            index=labels, columns=[\"Lower\", \"Upper\"]\n",
        "        )\n",
        "\n",
        "    # --- Prediction Intervals ---\n",
        "    def CalculatePiMean(self, alpha, hat_mean, hat_sigma, dist):\n",
        "        # Calculate prediction interval based on the mean\n",
        "        scale = np.sqrt(hat_sigma**2 + hat_sigma**2/self.n)\n",
        "\n",
        "        if dist == \"norm\":\n",
        "            self.pi_mean = norm.ppf(alpha/2, hat_mean, scale), norm.ppf(1-alpha/2, hat_mean, scale)\n",
        "        if dist == \"t\":\n",
        "            # Only if we are using standard deviaiton with one degree of freedom without correction\n",
        "            self.pi_mean = t.ppf(alpha/2, self.n-1, hat_mean, scale), t.ppf(1-alpha/2, self.n-1, hat_mean, scale)\n",
        "    \n",
        "    def CalculatePiMedian(self, alpha, hat_median=None, hat_sigma=None):\n",
        "        scale = np.sqrt(hat_sigma**2 + np.pi*hat_sigma**2/(2*self.n))\n",
        "        self.pi_median = norm.ppf(alpha/2, hat_median, scale), norm.ppf(1-alpha/2, hat_median, scale)\n",
        "\n",
        "    def CalculatePiIqr(self, alpha):\n",
        "        # Calculate prediction interval based on the first and third quartile\n",
        "        q1, q3 = np.quantile(self.data, [0.25, 0.75])\n",
        "        iqr = q3-q1\n",
        "        delta = 0.5 * (norm.ppf(1-alpha/2)/norm.ppf(0.75)-1)\n",
        "\n",
        "        self.pi_iqr = q1 - delta * iqr, q3 + delta * iqr\n",
        "\n",
        "    def CalculatePiBoots(self, alpha, bootstrap_samples):\n",
        "        labels = [\"Bootstrap\"]\n",
        "        self.pi_boots = np.mean(\n",
        "            np.array([np.quantile(np.random.choice(self.data, size=self.n, replace=True), [alpha/2, 1-alpha/2]) for _ in range(bootstrap_samples)]),\n",
        "            axis=0)\n",
        "\n",
        "        self.prediction_intervals_boots = pd.DataFrame([self.pi_boots], index=labels, columns=[\"Lower\", \"Upper\"])\n",
        "\n",
        "    def CalculatePredictionInterval(self, alpha, hat_mean, hat_median, hat_sigma, dist):\n",
        "        self.CalculatePiMean(alpha, hat_mean, hat_sigma, dist)\n",
        "        self.CalculatePiMedian(alpha, hat_median, hat_sigma)\n",
        "        self.CalculatePiIqr(alpha)\n",
        "\n",
        "        # Return the statistics as a table\n",
        "        labels = ['Mean', 'Median', 'IQR']\n",
        "        self.prediction_intervals = pd.DataFrame(\n",
        "            [self.pi_mean, self.pi_median, self.pi_iqr],\n",
        "            index=labels, columns=[\"Lower\", \"Upper\"]\n",
        "        )\n",
        "\n",
        "    # --- Relative Likelihood ---\n",
        "    def RelativeLogLikelihood(self, mu, sigma):\n",
        "        return self.n * (np.log(self.S0 / sigma) + 0.5 * (1 - (np.mean(self.data**2) - 2 * mu * np.mean(self.data) + mu**2) / sigma**2))\n",
        "\n",
        "    def RelativeLikelihood(self, mu, sigma):\n",
        "        return np.exp(self.RelativeLogLikelihood(mu, sigma))\n",
        "\n",
        "    # --- Graphical Analysis ---\n",
        "    \n",
        "    # --- Plot Histogram ---\n",
        "    def PlotHistogram(self, name_variable, kde, show_data, histo_add_ci, histo_choose_ci, histo_add_pi, histo_choose_pi, add_normal, hat_mu, hat_sigma):\n",
        "        # Style\n",
        "        plt.style.use(\"seaborn-v0_8-whitegrid\")\n",
        "        \n",
        "        show_intervals = histo_add_ci or histo_add_pi\n",
        "\n",
        "        if show_intervals:\n",
        "            fig, (ax1, ax2) = plt.subplots(2, 1, sharex=True, figsize=(8, 6))\n",
        "        else:\n",
        "            fig, ax1 = plt.subplots(1, 1, figsize=(8, 4))\n",
        "            ax2 = None\n",
        "\n",
        "        # Histogram and KDE\n",
        "        sns.histplot(self.data, kde=kde, stat=\"density\", color=\"rebeccapurple\", alpha=0.5, ax=ax1)\n",
        "        ax1.set_ylabel(\"Density\")\n",
        "        ax1.set_xlabel(f\"{name_variable}\")\n",
        "        ax1.set_title(f\"Distribution of {name_variable}\")\n",
        "\n",
        "        if add_normal:\n",
        "            y_vect = np.linspace(hat_mu - 3*hat_sigma, hat_mu + 3*hat_sigma, 100)\n",
        "            ax1.plot(y_vect, norm.pdf(y_vect, hat_mu, hat_sigma), color=\"black\", linestyle=\"--\", label=\"Normal density\")\n",
        "            ax1.legend()\n",
        "\n",
        "        if show_data:\n",
        "            _, upper = ax1.get_ylim()\n",
        "            sns.rugplot(self.data, height=0.1*upper, ax=ax1, color='black')\n",
        "\n",
        "        # Interval annotations (confidence/prediction)\n",
        "        if show_intervals:\n",
        "            ax2.set_yticks([])\n",
        "            ax2.set_xlabel(f\"{name_variable}\")\n",
        "            ax2.set_ylim(0, 0.5)\n",
        "\n",
        "            # Helper to plot a horizontal interval\n",
        "            def plot_interval(ax, y_val, low, high, label, color):\n",
        "                ax.hlines(y_val, low, high, color=color, linewidth=2, label=label)\n",
        "                ax.scatter((low + high)/2, y_val, color=color, s=30, zorder=5)\n",
        "                ax.text(high, y_val, f\" {label}\", va=\"center\", fontsize=9,\n",
        "                        bbox=dict(boxstyle='round,pad=0.2', facecolor='whitesmoke', edgecolor='gray'))\n",
        "\n",
        "            # Confidence Intervals\n",
        "            ci_y = 0.4\n",
        "            if histo_add_ci:\n",
        "                if histo_choose_ci in [\"Mean\", \"Both\"]:\n",
        "                    plot_interval(ax2, ci_y, self.ci_mean[0], self.ci_mean[1], \"CI Mean\", \"blue\")\n",
        "                if histo_choose_ci in [\"Median\", \"Both\"]:\n",
        "                    plot_interval(ax2, ci_y - 0.1, self.ci_median[0], self.ci_median[1], \"CI Median\", \"green\")\n",
        "\n",
        "            # Prediction Intervals\n",
        "            pi_y = 0.1\n",
        "            if histo_add_pi:\n",
        "                if histo_choose_pi == \"Mean\":\n",
        "                    plot_interval(ax2, pi_y, self.pi_mean[0], self.pi_mean[1], \"PI Mean\", \"darkred\")\n",
        "                elif histo_choose_pi == \"Median\":\n",
        "                    plot_interval(ax2, pi_y, self.pi_median[0], self.pi_median[1], \"PI Median\", \"darkred\")\n",
        "                elif histo_choose_pi == \"IQR\":\n",
        "                    plot_interval(ax2, pi_y, self.pi_iqr[0], self.pi_iqr[1], \"PI IQR\", \"darkred\")\n",
        "                elif histo_choose_pi == \"Bootstrap\":\n",
        "                    plot_interval(ax2, pi_y, self.pi_boots[0], self.pi_boots[1], \"PI Bootstrap\", \"darkred\")\n",
        "\n",
        "        return fig\n",
        "    \n",
        "    # --- Plot ECDF ---\n",
        "    def PlotEcdf(self, name_variable, alpha, confidence, add_normal, hat_mu, hat_sigma):\n",
        "\n",
        "        ecdf = ECDF(self.data)\n",
        "        \n",
        "        plt.style.use(\"seaborn-v0_8-whitegrid\")  # Consistent styling\n",
        "        \n",
        "        fig, ax = plt.subplots(figsize=(8, 5))\n",
        "\n",
        "        # ECDF step plot\n",
        "        ax.step(ecdf.x, ecdf.y, where='post', color='rebeccapurple', linewidth=2, label=\"ECDF\")\n",
        "\n",
        "        # Optional: scatter markers (remove if redundant)\n",
        "        ax.scatter(ecdf.x, ecdf.y, color='rebeccapurple', s=10, alpha=0.6)\n",
        "\n",
        "        # Confidence band using DKW inequality\n",
        "        if confidence:\n",
        "            epsilon = np.sqrt(np.log(2 / alpha) / (2 * self.n))\n",
        "            lower = np.clip(ecdf.y - epsilon, 0, 1)\n",
        "            upper = np.clip(ecdf.y + epsilon, 0, 1)\n",
        "            ax.fill_between(ecdf.x, lower, upper, step='post', color='plum', alpha=0.4, label='DKW CI')\n",
        "\n",
        "        # Optional: add normal CDF for comparison\n",
        "        if add_normal:\n",
        "            y_vals = np.linspace(hat_mu - 3 * hat_sigma, hat_mu + 3 * hat_sigma, 100)\n",
        "            ax.plot(y_vals, norm.cdf(y_vals, hat_mu, hat_sigma), color='black', linestyle='--', linewidth=2, label=\"Normal CDF\")\n",
        "            ax.set_xlim(min(self.data.min(), y_vals.min()) - 0.1, max(self.data.max(), y_vals.max()) + 0.1)\n",
        "        else:\n",
        "            ax.set_xlim(self.data.min() - 0.1, self.data.max() + 0.1)\n",
        "\n",
        "        # Axis labels and title\n",
        "        ax.set_title(\"Empirical Cumulative Distribution Function\", fontsize=14)\n",
        "        ax.set_xlabel(f\"{name_variable}\", fontsize=12)\n",
        "        ax.set_ylabel(\"ECDF\", fontsize=12)\n",
        "        ax.set_ylim(0, 1.05)\n",
        "\n",
        "        # Gridlines and legend\n",
        "        ax.grid(True, linestyle='--', alpha=0.5)\n",
        "        ax.legend(loc=\"lower right\", fontsize=10)\n",
        "\n",
        "        return fig\n",
        "\n",
        "    # --- Plot Confidence Regions ---\n",
        "    def PlotConfidenceRegions(self, probs, eps_mu, eps_sigma, add):\n",
        "\n",
        "        # Reverse probabilities to get increasing chi2 levels\n",
        "        probs = probs[::-1]\n",
        "        levels = np.exp(-0.5 * chi2.ppf(probs, 2))\n",
        "\n",
        "        # Grids for mu and sigma\n",
        "        mu_vect = np.linspace(self.ci_mean[0] - eps_mu[0], self.ci_mean[1] + eps_mu[1], 200)\n",
        "        sigma_vect = np.linspace(self.ci_deviation[0] - eps_sigma[0], self.ci_deviation[1] + eps_sigma[1], 200)\n",
        "        mu_grid, sigma_grid = np.meshgrid(mu_vect, sigma_vect)\n",
        "\n",
        "        # Create plot\n",
        "        fig, ax = plt.subplots(figsize=(8, 6))\n",
        "\n",
        "        # Contour plot of relative likelihood\n",
        "        Z = self.RelativeLikelihood(mu_grid, sigma_grid)\n",
        "        contour = ax.contour(mu_grid, sigma_grid, Z, levels=levels, cmap=\"plasma\")\n",
        "\n",
        "        # Mark the MLE estimate\n",
        "        ax.scatter(self.mean, self.S0, color='black', s=60, label=\"MLE\", zorder=5)\n",
        "\n",
        "        # Optional: add rectangular CI box\n",
        "        if add:\n",
        "            ci_x = [self.ci_mean[0], self.ci_mean[1], self.ci_mean[1], self.ci_mean[0], self.ci_mean[0]]\n",
        "            ci_y = [self.ci_deviation[0], self.ci_deviation[0], self.ci_deviation[1], self.ci_deviation[1], self.ci_deviation[0]]\n",
        "            ax.plot(ci_x, ci_y, color='red', linestyle='--', label=\"CI box\")\n",
        "\n",
        "        # Axis and title\n",
        "        ax.set_title(r\"Confidence Regions for $\\mu$ and $\\sigma$\", fontsize=14)\n",
        "        ax.set_xlabel(r\"$\\mu$\", fontsize=12)\n",
        "        ax.set_ylabel(r\"$\\sigma$\", fontsize=12)\n",
        "        ax.grid(True, linestyle='--', alpha=0.6)\n",
        "\n",
        "        # Format legend from contour handles\n",
        "        handles, _ = contour.legend_elements()\n",
        "        formatted_probs = [f\"{100*p:.1f}%\" for p in probs]\n",
        "        ax.legend(handles + [ax.collections[-1]], formatted_probs + [\"MLE\"], loc=\"upper right\", frameon=True)\n",
        "\n",
        "        plt.tight_layout()\n",
        "        return fig\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ee47afaa",
      "metadata": {},
      "source": [
        "# ðŸ§  ðŸŒ General functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "38b1fdbc",
      "metadata": {},
      "outputs": [],
      "source": [
        "def save_table_as_csv(filename):\n",
        "    df = export_cache.get(\"table\")\n",
        "    if df is None:\n",
        "        return \"âŒ Error: No table available to save.\"\n",
        "    \n",
        "    if not filename.strip():\n",
        "        return \"âŒ Error: Filename is empty.\"\n",
        "\n",
        "    try:\n",
        "        filepath = os.path.abspath(f\"{filename.strip()}.csv\")\n",
        "        df.to_csv(filepath, index=False)\n",
        "        return \"âœ… Table saved successfully.\"\n",
        "    except Exception as e:\n",
        "        return f\"âŒ Error: {e}\"\n",
        "    \n",
        "def save_figure_as_image(filename):\n",
        "    fig = export_cache.get(\"figure\")\n",
        "    if fig is None:\n",
        "        return \"âŒ Error: No figure available to save.\"\n",
        "    \n",
        "    if not filename.strip():\n",
        "        return \"âŒ Error: Filename is empty.\"\n",
        "\n",
        "    try:\n",
        "        filepath = os.path.abspath(f\"{filename.strip()}.png\")\n",
        "        fig.savefig(filepath, bbox_inches='tight')\n",
        "        return \"âœ… Image saved successfully.\"\n",
        "    except Exception as e:\n",
        "        return f\"âŒ Error: {e}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "0cecaeaa",
      "metadata": {},
      "outputs": [],
      "source": [
        "def blank_plot():\n",
        "    fig, ax = plt.subplots()\n",
        "    ax.axis('off')\n",
        "    return fig\n",
        "\n",
        "def load_numeric_cols():\n",
        "    numeric_cols = df_cache.get(\"numeric_cols\", [])\n",
        "    selected = numeric_cols[0] if numeric_cols else None\n",
        "    return gr.update(choices=numeric_cols, value=selected)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "2650afd1",
      "metadata": {},
      "outputs": [],
      "source": [
        "def prepare_data(column):\n",
        "    # --- Read data and validate ---\n",
        "    original_df = df_cache.get(\"df\")\n",
        "    filtered_df = df_cache.get(\"filtered_df\")\n",
        "\n",
        "    if original_df is None:\n",
        "        return None, None, None, pd.DataFrame([[\"Please upload a valid CSV.\"]], columns=[\"Error\"]), blank_plot()\n",
        "\n",
        "    # --- Use filtered data if it differs from original ---\n",
        "    df = filtered_df if filtered_df is not None and not filtered_df.equals(original_df) else original_df\n",
        "\n",
        "    # --- Select numeric column ---\n",
        "    if column not in df.columns:\n",
        "        return None, None, None, pd.DataFrame([[\"Selected column is not in the dataframe.\"]], columns=[\"Error\"]), blank_plot()\n",
        "\n",
        "    data = df[column].dropna()\n",
        "\n",
        "    # --- Initialize or reuse Statistics object ---\n",
        "    stats = df_cache.get(\"stats\")\n",
        "    if stats is None or not np.array_equal(stats.data, data.to_numpy()):\n",
        "        stats = Statistics(data)\n",
        "        df_cache[\"stats\"] = stats\n",
        "\n",
        "    return df, data, stats, None, None  # df, data, stats, error_df, error_plot\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "ddb3dd11",
      "metadata": {},
      "outputs": [],
      "source": [
        "def choose_mu(sel, stats, text_box):\n",
        "    if sel == \"Sample Mean\":\n",
        "        hat_mu = stats.mean\n",
        "    elif sel == \"Sample Median\":\n",
        "        hat_mu = stats.median\n",
        "    elif sel == \"Geometric Mean\":\n",
        "        hat_mu = stats.geometric_mean\n",
        "    elif sel == \"Harmonic Mean\":\n",
        "        hat_mu = stats.harmonic_mean\n",
        "    elif sel == \"Weighted Mean\":\n",
        "        hat_mu = stats.weighted_mean\n",
        "    elif sel == \"Trimmed Mean\":\n",
        "        hat_mu = stats.trimmed_mean\n",
        "    elif sel == \"Interquartile Mean\":\n",
        "        hat_mu = stats.interquartile_mean\n",
        "    elif sel == \"Winsorized Mean\":\n",
        "        hat_mu = stats.winsorized_mean\n",
        "    elif sel == \"Other\":\n",
        "        hat_mu = float(text_box)\n",
        "        \n",
        "    return hat_mu\n",
        "\n",
        "def choose_sigma(sel, stats, text_box):\n",
        "    if sel == \"Deviation (1 ddof)\":\n",
        "        hat_sigma = stats.S1\n",
        "    elif sel == \"Range (bias corrected)\":\n",
        "        hat_sigma = stats.R_bias_corrected\n",
        "    elif sel == \"IQR (bias corrected)\":\n",
        "        hat_sigma = stats.IQR_bias_corrected\n",
        "    elif sel == \"MAD (bias corrected)\":\n",
        "        hat_sigma = stats.MAD_bias_corrected\n",
        "    elif sel == \"AAD (bias corrected)\":\n",
        "        hat_sigma = stats.AAD_bias_corrected\n",
        "    elif sel == \"Other\":\n",
        "        hat_sigma = float(text_box)\n",
        "\n",
        "    return hat_sigma"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7d2a1850",
      "metadata": {},
      "source": [
        "# ðŸŽ® ðŸŒ General logic of GUI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "d55dae87",
      "metadata": {},
      "outputs": [],
      "source": [
        "def add_normal_warning(check):\n",
        "    if check:\n",
        "        gr.Warning(\"If you haven't done it yet, run first a descriptive analysis for central tendency and dispersion.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "ae82e1b7",
      "metadata": {},
      "outputs": [],
      "source": [
        "def parse_text(input_str):\n",
        "        return float(input_str) if input_str.strip() else None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "c9978559",
      "metadata": {},
      "outputs": [],
      "source": [
        "def toggle_add_normal(check, sel_mu, sel_sigma):\n",
        "    if check:\n",
        "        if sel_mu == \"Other\":\n",
        "            if sel_sigma == \"Other\":\n",
        "                return [\n",
        "                    gr.update(visible=True), # hat_mu\n",
        "                    gr.update(visible=True), # hat_mu_text\n",
        "                    gr.update(visible=True), # hat_sigma\n",
        "                    gr.update(visible=True)  # hat_sigma_text\n",
        "                ]\n",
        "            else:\n",
        "                return (\n",
        "                    gr.update(visible=True),\n",
        "                    gr.update(visible=True),\n",
        "                    gr.update(visible=True),\n",
        "                    gr.update(visible=False)\n",
        "                )\n",
        "        else:\n",
        "            if sel_sigma == \"Other\":\n",
        "                return (\n",
        "                    gr.update(visible=True), \n",
        "                    gr.update(visible=False), \n",
        "                    gr.update(visible=True), \n",
        "                    gr.update(visible=True)\n",
        "                )\n",
        "            else:\n",
        "                return (\n",
        "                    gr.update(visible=True),\n",
        "                    gr.update(visible=False),\n",
        "                    gr.update(visible=True),\n",
        "                    gr.update(visible=False)\n",
        "                )\n",
        "    else:\n",
        "        return (\n",
        "            gr.update(visible=False),\n",
        "            gr.update(visible=False),\n",
        "            gr.update(visible=False),\n",
        "            gr.update(visible=False)\n",
        "        )"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6e41649d",
      "metadata": {},
      "source": [
        "# ðŸ–¥ï¸ ðŸŒ  General GUI blocks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "763c76fd",
      "metadata": {},
      "outputs": [],
      "source": [
        "def build_results_block():        \n",
        "    gr.Markdown(\"# ðŸŽ¯ Results\")\n",
        "\n",
        "    with gr.Row(visible=False, elem_id=\"row_centered\") as output_table_group:\n",
        "        save_table_button = gr.Button(\"ðŸ’¾ Save Table as CSV\")\n",
        "        name_save_table = gr.Textbox(label=\"Filename (without extension)\", placeholder=\"e.g. descriptive_stats\")\n",
        "        table_save_status = gr.Textbox(label=\"Table Save Status\", interactive=False)\n",
        "\n",
        "    output_table = gr.Dataframe(visible=False)\n",
        "\n",
        "    with gr.Row(visible=False, elem_id=\"row_centered\") as output_plot_group:\n",
        "        save_figure_button = gr.Button(\"ðŸ–¼ï¸ Save Figure as PNG\")\n",
        "        name_save_figure = gr.Textbox(label=\"Filename (without extension)\", placeholder=\"e.g. histogram\")\n",
        "        img_save_status = gr.Textbox(label=\"Image Save Status\", interactive=False)\n",
        "\n",
        "    output_plot = gr.Plot(visible=False)\n",
        "\n",
        "    save_table_button.click(\n",
        "        fn=save_table_as_csv,\n",
        "        inputs=[name_save_table],\n",
        "        outputs=[table_save_status]\n",
        "    )\n",
        "\n",
        "    save_figure_button.click(\n",
        "        fn=save_figure_as_image,\n",
        "        inputs=[name_save_figure],\n",
        "        outputs=[img_save_status]\n",
        "    )\n",
        "\n",
        "    return output_table_group, output_table, output_plot_group, output_plot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "d98c8d8f",
      "metadata": {},
      "outputs": [],
      "source": [
        "def build_results_block_2():       \n",
        "    gr.Markdown(\"# ðŸŽ¯ Results\")\n",
        "    \n",
        "    with gr.Row(visible=False, elem_id=\"row_centered\") as output_table_group:\n",
        "        save_table_button = gr.Button(\"ðŸ’¾ Save Coefficient Table as CSV\")\n",
        "        name_save_table = gr.Textbox(label=\"Filename (without extension)\", placeholder=\"e.g. descriptive_stats\")\n",
        "        table_save_status = gr.Textbox(label=\"Table Save Status\", interactive=False)\n",
        "\n",
        "    output_table = gr.HTML(visible=False)\n",
        "\n",
        "    with gr.Row(visible=False, elem_id=\"row_centered\") as output_plot_group:\n",
        "        save_figure_button = gr.Button(\"ðŸ–¼ï¸ Save Figure as PNG\")\n",
        "        name_save_figure = gr.Textbox(label=\"Filename (without extension)\", placeholder=\"e.g. histogram\")\n",
        "        img_save_status = gr.Textbox(label=\"Image Save Status\", interactive=False)\n",
        "\n",
        "    output_plot = gr.Plot(visible=False)\n",
        "\n",
        "    save_table_button.click(\n",
        "        fn=save_table_as_csv,\n",
        "        inputs=[name_save_table],\n",
        "        outputs=[table_save_status]\n",
        "    )\n",
        "\n",
        "    save_figure_button.click(\n",
        "        fn=save_figure_as_image,\n",
        "        inputs=[name_save_figure],\n",
        "        outputs=[img_save_status]\n",
        "    )\n",
        "\n",
        "    return output_table_group, output_table, output_plot_group, output_plot"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c3b8f8cd",
      "metadata": {},
      "source": [
        "# ðŸ§  ðŸ—„ï¸ Brain of Data Tab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "4d9ad4be",
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_effective_column_types(df):\n",
        "    all_numeric = df.select_dtypes(include=[np.number]).columns.tolist()\n",
        "    all_categorical = df.select_dtypes(exclude=[np.number]).columns.tolist()\n",
        "    overrides = df_cache.get(\"overrides\", {\"num_to_cat\": [], \"cat_to_num\": []})\n",
        "\n",
        "    numeric = [col for col in all_numeric if col not in overrides[\"num_to_cat\"]]\n",
        "    categorical = [col for col in all_categorical if col not in overrides[\"cat_to_num\"]]\n",
        "\n",
        "    numeric += [col for col in overrides[\"cat_to_num\"] if col in df.columns]\n",
        "    categorical += [col for col in overrides[\"num_to_cat\"] if col in df.columns]\n",
        "\n",
        "    return sorted(set(numeric)), sorted(set(categorical))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "5d21ea60",
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_csv(file):\n",
        "    try:\n",
        "        df = pd.read_csv(file.name)\n",
        "\n",
        "        if df.empty:\n",
        "            raise ValueError(\"The uploaded CSV file is empty.\")\n",
        "\n",
        "        df_cache[\"df\"] = df\n",
        "        df_cache[\"filtered_df\"] = df\n",
        "        df_cache[\"stats\"] = None\n",
        "\n",
        "        numeric_cols, categorical_cols = get_effective_column_types(df)\n",
        "\n",
        "        df_cache[\"numeric_cols\"] = numeric_cols\n",
        "        df_cache[\"categorical_cols\"] = categorical_cols\n",
        "\n",
        "        return (\n",
        "            gr.update(choices=categorical_cols, value=[]),            # cat_col_dropdown\n",
        "            gr.update(choices=numeric_cols, value=None),              # num_override_dropdown\n",
        "            gr.update(choices=categorical_cols, value=None),          # cat_override_dropdown\n",
        "            gr.update(choices=[], value=[], visible=False),           # cat_val_multiselect_1\n",
        "            gr.update(choices=[], value=[], visible=False),           # cat_val_multiselect_2\n",
        "            gr.update(choices=[], value=[], visible=False),           # cat_val_multiselect_3\n",
        "            \"CSV loaded successfully.\"                                # status_output (Textbox!)\n",
        "        )\n",
        "    except Exception as e:\n",
        "        return tuple([gr.update(choices=[], value=None)] * 7 + [f\"Error: {e}\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "d23791cc",
      "metadata": {},
      "outputs": [],
      "source": [
        "def show_data_overview(check):\n",
        "    if check:\n",
        "        df = df_cache.get(\"df\")\n",
        "\n",
        "        if df is None:\n",
        "            error_df = pd.DataFrame([[\"Please upload a valid CSV.\"]], columns=[\"Error\"])\n",
        "            return error_df, gr.update(visible=True), None, gr.update(visible=False)\n",
        "\n",
        "        # --- Compute description and data types ---\n",
        "        try:\n",
        "            desc = df.describe().T.round(ROUND).reset_index().rename(columns={\"index\": \"Variable\"})\n",
        "        except Exception as e:\n",
        "            desc = pd.DataFrame([[str(e)]], columns=[\"Error\"])\n",
        "\n",
        "        try:\n",
        "            dtypes_df = pd.DataFrame(df.dtypes).reset_index().rename(columns={\"index\": \"Variable\", 0: \"Type\"})\n",
        "        except Exception as e:\n",
        "            dtypes_df = pd.DataFrame([[str(e)]], columns=[\"Error\"])\n",
        "            \n",
        "        return desc, gr.update(visible=True), dtypes_df, gr.update(visible=True)\n",
        "    else:\n",
        "        return None, gr.update(visible=False), None, gr.update(visible=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "6bf7ab74",
      "metadata": {},
      "outputs": [],
      "source": [
        "def show_data_overview_filter(check):\n",
        "    if check:\n",
        "        original_df = df_cache.get(\"df\")\n",
        "        filtered_df = df_cache.get(\"filtered_df\")\n",
        "\n",
        "        if original_df is None:\n",
        "            error_df = pd.DataFrame([[\"Please upload a valid CSV.\"]], columns=[\"Error\"])\n",
        "            return error_df, gr.update(visible=True), None, gr.update(visible=False)\n",
        "\n",
        "        # --- Use filtered data if it differs from original ---\n",
        "        df = filtered_df if filtered_df is not None and not filtered_df.equals(original_df) else original_df\n",
        "\n",
        "        # --- Compute description and data types ---\n",
        "        try:\n",
        "            desc = df.describe().T.round(ROUND).reset_index().rename(columns={\"index\": \"Variable\"})\n",
        "        except Exception as e:\n",
        "            desc = pd.DataFrame([[str(e)]], columns=[\"Error\"])\n",
        "\n",
        "        try:\n",
        "            dtypes_df = pd.DataFrame(df.dtypes).reset_index().rename(columns={\"index\": \"Variable\", 0: \"Type\"})\n",
        "        except Exception as e:\n",
        "            dtypes_df = pd.DataFrame([[str(e)]], columns=[\"Error\"])\n",
        "            \n",
        "        return desc, gr.update(visible=True), dtypes_df, gr.update(visible=True)\n",
        "    else:\n",
        "        return None, gr.update(visible=False), None, gr.update(visible=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "c2384f45",
      "metadata": {},
      "outputs": [],
      "source": [
        "def reclassify_as_categorical(column):\n",
        "    numeric_cols = df_cache.get(\"numeric_cols\", [])\n",
        "    categorical_cols = df_cache.get(\"categorical_cols\", [])\n",
        "\n",
        "    if column and column in numeric_cols:\n",
        "        numeric_cols.remove(column)\n",
        "        categorical_cols.append(column)\n",
        "        df_cache[\"numeric_cols\"] = numeric_cols\n",
        "        df_cache[\"categorical_cols\"] = categorical_cols\n",
        "\n",
        "        return (\n",
        "            gr.update(choices=categorical_cols),                      # cat_col_dropdown\n",
        "            gr.update(choices=numeric_cols),                          # num_override_dropdown\n",
        "            gr.update(choices=categorical_cols),                      # cat_override_dropdown\n",
        "            f\"Column '{column}' reclassified as categorical.\"         # status\n",
        "        )\n",
        "    else:\n",
        "        return (\n",
        "            gr.update(), gr.update(), gr.update(), gr.update(),\n",
        "            f\"Column '{column}' is not currently classified as numeric.\"\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "4d2c1bda",
      "metadata": {},
      "outputs": [],
      "source": [
        "def reclassify_as_numeric(column):\n",
        "    numeric_cols = df_cache.get(\"numeric_cols\", [])\n",
        "    categorical_cols = df_cache.get(\"categorical_cols\", [])\n",
        "\n",
        "    if column and column in categorical_cols:\n",
        "        categorical_cols.remove(column)\n",
        "        numeric_cols.append(column)\n",
        "        df_cache[\"categorical_cols\"] = categorical_cols\n",
        "        df_cache[\"numeric_cols\"] = numeric_cols\n",
        "\n",
        "        return (\n",
        "            gr.update(choices=categorical_cols),                      # cat_col_dropdown\n",
        "            gr.update(choices=numeric_cols),                          # num_override_dropdown\n",
        "            gr.update(choices=categorical_cols),                      # cat_override_dropdown\n",
        "            f\"Column '{column}' reclassified as numeric.\"             # status\n",
        "        )\n",
        "    else:\n",
        "        return (\n",
        "            gr.update(), gr.update(), gr.update(), gr.update(),\n",
        "            f\"Column '{column}' is not currently classified as categorical.\"\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "03c84847",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Only 3 category filters are supported.\n",
        "def update_category_filters(selected_columns):\n",
        "    df = df_cache.get(\"df\")\n",
        "\n",
        "    if df is None or not selected_columns:\n",
        "        # Hide all category selectors if nothing is selected\n",
        "        return [gr.update(visible=False, choices=[], value=[]) for _ in range(3)]\n",
        "\n",
        "    updates = []\n",
        "    for i in range(3):\n",
        "        if i < len(selected_columns):\n",
        "            col = selected_columns[i]\n",
        "            if col in df.columns:\n",
        "                values = sorted(df[col].dropna().unique().tolist())\n",
        "                updates.append(gr.update(visible=True, choices=values, value=[]))\n",
        "            else:\n",
        "                updates.append(gr.update(visible=False, choices=[], value=[]))\n",
        "        else:\n",
        "            updates.append(gr.update(visible=False, choices=[], value=[]))\n",
        "\n",
        "    return updates"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "50a3647f",
      "metadata": {},
      "outputs": [],
      "source": [
        "def apply_filters(cat_cols, val1, val2, val3):\n",
        "    df = df_cache.get(\"df\")\n",
        "    if df is None:\n",
        "        return \"âŒ No data loaded.\"\n",
        "\n",
        "    filtered_df = df.copy()\n",
        "    category_filters = [val1, val2, val3]\n",
        "\n",
        "    if not cat_cols or all(not vals for vals in category_filters):\n",
        "        # No filters applied\n",
        "        df_cache[\"filtered_df\"] = df\n",
        "        return \"âš ï¸ No filters selected. Using full dataset.\"\n",
        "\n",
        "    for i, col in enumerate(cat_cols[:3]):\n",
        "        selected_vals = category_filters[i]\n",
        "        if selected_vals:\n",
        "            filtered_df = filtered_df[filtered_df[col].isin(selected_vals)]\n",
        "\n",
        "    df_cache[\"filtered_df\"] = filtered_df\n",
        "    return f\"âœ… Filter applied. Rows remaining: {len(filtered_df)}\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c4a4e433",
      "metadata": {},
      "source": [
        "# ðŸŽ®ðŸ—„ï¸ Logic control of Data Tab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "582ab70e",
      "metadata": {},
      "outputs": [],
      "source": [
        "def max_categorical_warning(check):\n",
        "    if check:\n",
        "        gr.Info(\"The maximum number of categorical columns for filter is 3.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "d48d6db8",
      "metadata": {},
      "outputs": [],
      "source": [
        "def toggle_preview(check):\n",
        "    df = df_cache.get(\"df\")\n",
        "    if check:\n",
        "        return df.head(5), gr.update(visible=True)\n",
        "    else:\n",
        "        return pd.DataFrame(), gr.update(visible=False) # csv_preview, csv_preview\n",
        "    \n",
        "def toggle_preview_filter(check):\n",
        "    df = df_cache.get(\"filtered_df\")\n",
        "    if check:\n",
        "        return df.head(5), gr.update(visible=True)\n",
        "    else:\n",
        "        return pd.DataFrame(), gr.update(visible=False) # csv_preview_filter, csv_preview_filter"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "efaf923a",
      "metadata": {},
      "source": [
        "# ðŸ–¥ï¸ ðŸ—„ï¸ GUI of Data Tab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "216a8e8a",
      "metadata": {},
      "outputs": [],
      "source": [
        "def build_data_tab():\n",
        "    #gr.Markdown(\"ðŸ“ File Explorer\")\n",
        "    with gr.Row():\n",
        "        file_input = gr.File(file_types=[\".csv\"], label=\"Upload CSV\")\n",
        "        status_output = gr.Textbox(label=\"Status\", interactive=False)\n",
        "        preview_checkbox = gr.Checkbox(label=\"Show CSV Preview\", value=False)\n",
        "        overview_checkbox = gr.Checkbox(label=\"Show Dataset Summary\", value=False)\n",
        "\n",
        "    csv_preview = gr.Dataframe(label=\"CSV Preview\", visible=False)\n",
        "    desc_output = gr.Dataframe(label=\"Descriptive Summary\", visible=False)\n",
        "    dtypes_output = gr.Dataframe(label=\"Variable Types\", visible=False)\n",
        "\n",
        "    with gr.Accordion(label=\"âž– Filter Data\", open=False) as filter_accordion:       \n",
        "        with gr.Row():\n",
        "            cat_col_dropdown = gr.Dropdown(label=\"Select Categorical Columns for Filter\", multiselect=True, max_choices=3, elem_classes=\"data_related\", elem_id=\"custom_dropdown\")\n",
        "            cat_val_multiselect_1 = gr.Dropdown(label=\"Categories for Filter 1\", multiselect=True, visible=False, interactive=True, elem_classes=\"data_related\", elem_id=\"custom_dropdown\")\n",
        "            cat_val_multiselect_2 = gr.Dropdown(label=\"Categories for Filter 2\", multiselect=True, visible=False, interactive=True, elem_classes=\"data_related\", elem_id=\"custom_dropdown\")\n",
        "            cat_val_multiselect_3 = gr.Dropdown(label=\"Categories for Filter 3\", multiselect=True, visible=False, interactive=True, elem_classes=\"data_related\", elem_id=\"custom_dropdown\")\n",
        "\n",
        "        with gr.Row(elem_id=\"row_centered\"):\n",
        "            apply_filter_button = gr.Button(\"ðŸš€ Apply Filter\")\n",
        "            filter_status = gr.Textbox(label=\"Filter Status\", interactive=False)\n",
        "            preview_checkbox_filter = gr.Checkbox(label=\"Show CSV Preview\", value=False)\n",
        "            overview_checkbox_filter = gr.Checkbox(label=\"Show Dataset Summary\", value=False)\n",
        "        \n",
        "    csv_preview_filter = gr.Dataframe(label=\"CSV Preview\", visible=False)\n",
        "    desc_output_filter = gr.Dataframe(label=\"Descriptive Summary\", visible=False)\n",
        "    dtypes_output_filter = gr.Dataframe(label=\"Variable Types\", visible=False)\n",
        "\n",
        "    with gr.Accordion(label=\"ðŸ› ï¸ Fix Variable Type\", open=False):\n",
        "        with gr.Row(elem_id=\"row_centered\"):\n",
        "            # Reclassify numeric âž categorical\n",
        "            num_override_dropdown = gr.Dropdown(label=\"Reclassify Numeric Column as Categorical\", elem_classes=\"data_related\", elem_id=\"custom_dropdown\")\n",
        "            fix_to_categorical_button = gr.Button(\"Reclassify as Categorical\")\n",
        "\n",
        "            # Reclassify categorical âž numeric\n",
        "            cat_override_dropdown = gr.Dropdown(label=\"Reclassify Categorical Column as Numeric\", elem_classes=\"data_related\", elem_id=\"custom_dropdown\")\n",
        "            fix_to_numeric_button = gr.Button(\"Reclassify as Numeric\")\n",
        "\n",
        "            fix_dtype_status = gr.Textbox(label=\"Status\", interactive=False)        \n",
        "\n",
        "    # --- Modify behavior of components of the GUI ---\n",
        "    file_input.change(\n",
        "        fn=load_csv,\n",
        "        inputs=[file_input],\n",
        "        outputs=[\n",
        "            cat_col_dropdown,\n",
        "            num_override_dropdown,\n",
        "            cat_override_dropdown,\n",
        "            cat_val_multiselect_1,\n",
        "            cat_val_multiselect_2,\n",
        "            cat_val_multiselect_3,\n",
        "            status_output\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    preview_checkbox.change(\n",
        "        fn=toggle_preview,\n",
        "        inputs=preview_checkbox,\n",
        "        outputs=[csv_preview, csv_preview]\n",
        "    )\n",
        "\n",
        "    overview_checkbox.change(\n",
        "        fn=show_data_overview,\n",
        "        inputs=[overview_checkbox],\n",
        "        outputs=[desc_output, desc_output, dtypes_output, dtypes_output]\n",
        "    )\n",
        "\n",
        "    fix_to_categorical_button.click(\n",
        "        fn=reclassify_as_categorical,\n",
        "        inputs=[num_override_dropdown],\n",
        "        outputs=[\n",
        "            cat_col_dropdown,\n",
        "            num_override_dropdown,\n",
        "            cat_override_dropdown,\n",
        "            fix_dtype_status\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    fix_to_numeric_button.click(\n",
        "        fn=reclassify_as_numeric,\n",
        "        inputs=[cat_override_dropdown],\n",
        "        outputs=[\n",
        "            cat_col_dropdown,\n",
        "            num_override_dropdown,\n",
        "            cat_override_dropdown,\n",
        "            fix_dtype_status\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    cat_col_dropdown.change(\n",
        "        fn=max_categorical_warning,\n",
        "        inputs=cat_col_dropdown,\n",
        "        outputs=[]\n",
        "    )\n",
        "\n",
        "    cat_col_dropdown.change(\n",
        "        fn=update_category_filters,\n",
        "        inputs=cat_col_dropdown,\n",
        "        outputs=[cat_val_multiselect_1, cat_val_multiselect_2, cat_val_multiselect_3]\n",
        "    )\n",
        "\n",
        "    apply_filter_button.click(\n",
        "        fn=apply_filters,\n",
        "        inputs=[\n",
        "            cat_col_dropdown,\n",
        "            cat_val_multiselect_1,\n",
        "            cat_val_multiselect_2,\n",
        "            cat_val_multiselect_3\n",
        "        ],\n",
        "        outputs=[filter_status]\n",
        "    )\n",
        "\n",
        "    preview_checkbox_filter.change(\n",
        "        fn=toggle_preview_filter,\n",
        "        inputs=preview_checkbox_filter,\n",
        "        outputs=[csv_preview_filter, csv_preview_filter]\n",
        "    )\n",
        "\n",
        "    overview_checkbox_filter.change(\n",
        "        fn=show_data_overview_filter,\n",
        "        inputs=[overview_checkbox_filter],\n",
        "        outputs=[desc_output_filter, desc_output_filter, dtypes_output_filter, dtypes_output_filter]\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "902a9052",
      "metadata": {},
      "source": [
        "# ðŸŽ® ðŸ“Š Logic control of Graph Tab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "a9821215",
      "metadata": {},
      "outputs": [],
      "source": [
        "def histo_add_ci_warning(check):\n",
        "    if check:\n",
        "        gr.Warning(\"If you haven't done it yet, run first a statistical inference for confidence interval.\")\n",
        "\n",
        "def histo_add_pi_warning(check):\n",
        "    if check:\n",
        "        gr.Warning(\"If you haven't done it yet, run first a statistical inference for prediction interval.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "57436c2f",
      "metadata": {},
      "outputs": [],
      "source": [
        "def toggle_graph_stat(graph_stat):\n",
        "    if graph_stat == \"Histogram\":\n",
        "        return (\n",
        "            gr.update(visible=True), # histo_add_kde\n",
        "            gr.update(visible=True), # histo_add_data\n",
        "            gr.update(visible=True), # histo_normal_row\n",
        "            gr.update(visible=True), # histo_ci_row\n",
        "            gr.update(visible=True), # histo_pi_row\n",
        "            gr.update(visible=False), # ecdf_normal_row\n",
        "            gr.update(visible=False), # ecdf_add_conf\n",
        "            gr.update(visible=False), # ecdf_alpha\n",
        "        )\n",
        "    elif graph_stat == \"Empirical Cumulative Distribution Function (ECDF)\":\n",
        "        return ( \n",
        "            gr.update(visible=False), \n",
        "            gr.update(visible=False),\n",
        "            gr.update(visible=False),\n",
        "            gr.update(visible=False),\n",
        "            gr.update(visible=False),\n",
        "            gr.update(visible=True),\n",
        "            gr.update(visible=True),\n",
        "            gr.update(visible=True),\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "6b68ef61",
      "metadata": {},
      "outputs": [],
      "source": [
        "def run_graph_stat(\n",
        "        column,\n",
        "        graph_stat,\n",
        "        histo_add_kde_check, histo_add_data_check,\n",
        "        histo_add_ci, histo_choose_ci,\n",
        "        histo_add_pi, histo_choose_pi,\n",
        "        histo_add_normal,\n",
        "        histo_hat_mu, histo_hat_mu_text,\n",
        "        histo_hat_sigma, histo_hat_sigma_text,\n",
        "        ecdf_add_conf,\n",
        "        ecdf_alpha,\n",
        "        ecdf_add_normal,\n",
        "        ecdf_hat_mu, ecdf_hat_mu_text,\n",
        "        ecdf_hat_sigma, ecdf_hat_sigma_text\n",
        "        ):\n",
        "    \n",
        "    df, data, stats, error_df, error_plot = prepare_data(column)\n",
        "    if error_df:\n",
        "        return gr.update(visible=False), gr.update(visible=True), error_df, gr.update(visible=False), gr.update(visible=False), error_plot\n",
        "\n",
        "    # --- Graphical Analysis ---\n",
        "    if graph_stat == \"Histogram\":\n",
        "        hat_mu, hat_sigma = None, None\n",
        "\n",
        "        if histo_add_normal:\n",
        "            hat_mu = choose_mu(histo_hat_mu, stats, histo_hat_mu_text)\n",
        "            hat_sigma = choose_sigma(histo_hat_sigma, stats, histo_hat_sigma_text)\n",
        "\n",
        "        fig = stats.PlotHistogram(\n",
        "            column,\n",
        "            histo_add_kde_check,\n",
        "            histo_add_data_check,\n",
        "            histo_add_ci, histo_choose_ci,\n",
        "            histo_add_pi, histo_choose_pi,\n",
        "            histo_add_normal,\n",
        "            hat_mu,\n",
        "            hat_sigma\n",
        "        )\n",
        "        \n",
        "    elif graph_stat == \"Empirical Cumulative Distribution Function (ECDF)\":\n",
        "\n",
        "        alpha = parse_text(ecdf_alpha)\n",
        "        alpha = 1-alpha\n",
        "        if alpha is None or not (0 < alpha < 1):\n",
        "            return [\n",
        "                gr.update(visible=False),\n",
        "                gr.update(visible=True),\n",
        "                pd.DataFrame([[\"Invalid alpha value.\"]], columns=[\"Error\"]),\n",
        "                gr.update(visible=False),\n",
        "                gr.update(visible=False),\n",
        "                None]\n",
        "\n",
        "        hat_mu, hat_sigma = None, None\n",
        "\n",
        "        if ecdf_add_normal:\n",
        "            hat_mu = choose_mu(ecdf_hat_mu, stats, ecdf_hat_mu_text)\n",
        "            hat_sigma = choose_sigma(ecdf_hat_sigma, stats, ecdf_hat_sigma_text)\n",
        "\n",
        "        fig = stats.PlotEcdf(\n",
        "            column,\n",
        "            alpha,\n",
        "            ecdf_add_conf,\n",
        "            ecdf_add_normal,\n",
        "            hat_mu,\n",
        "            hat_sigma\n",
        "        )\n",
        "    \n",
        "    #export_cache[\"table\"] = None\n",
        "    export_cache[\"figure\"] = fig\n",
        "\n",
        "    # output_table_row, output_table, output_table, output_plot_row, output_plot, output_plot\n",
        "    return gr.update(visible=False), gr.update(visible=False), pd.DataFrame(), gr.update(visible=True), gr.update(visible=True), fig "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c28f4d67",
      "metadata": {},
      "source": [
        "# ðŸ–¥ï¸ ðŸ“Š GUI of Graph Tab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "38f51fd9",
      "metadata": {},
      "outputs": [],
      "source": [
        "def build_graphical_tab():\n",
        "    gr.Markdown(\"# ðŸ“Š Graphical Analysis\")\n",
        "    \n",
        "    with gr.Row(elem_id=\"row_centered\"):\n",
        "        refresh_columns_button = gr.Button(\"ðŸ”„ Refresh Numeric Columns\")\n",
        "        column_dropdown = gr.Dropdown(label=\"Select Numeric Column\", choices=[], interactive=True, elem_classes=\"data_related\", elem_id=\"custom_dropdown\")\n",
        "\n",
        "        graph_stat_dropdown = gr.Dropdown(\n",
        "            label=\"Select Graph\",\n",
        "            choices=[\n",
        "                \"Histogram\",\n",
        "                \"Empirical Cumulative Distribution Function (ECDF)\"\n",
        "            ],\n",
        "            value=\"Histogram\",\n",
        "            interactive=True\n",
        "        )\n",
        "\n",
        "        histo_add_kde = gr.Checkbox(label=\"Add KDE\", value=True, visible=True, interactive=True)\n",
        "        histo_add_data = gr.Checkbox(label=\"Show data\", value=False, visible=True, interactive=True)\n",
        "\n",
        "        ecdf_add_conf = gr.Checkbox(label=\"Add CI for the ECDF\", value=True, visible=False, interactive=True)\n",
        "        ecdf_alpha = gr.Textbox(label=\"Confidence level (e.g. 0.95)\", value=0.95, interactive=True, visible=False)\n",
        "\n",
        "    with gr.Row() as histo_normal_row:\n",
        "        histo_add_normal = gr.Checkbox(label=\"Add Normal Density\", value=False)\n",
        "\n",
        "        histo_hat_mu = gr.Dropdown(\n",
        "            label=\"Î¼\",\n",
        "            choices=[\n",
        "                'Sample Mean',\n",
        "                'Sample Median',\n",
        "                'Geometric Mean',\n",
        "                'Harmonic Mean',\n",
        "                'Weighted Mean',\n",
        "                'Trimmed Mean',\n",
        "                'Interquartile Mean',\n",
        "                'Winsorized Mean',\n",
        "                \"Other\"\n",
        "            ],\n",
        "            value=\"Sample Mean\",\n",
        "            interactive=True,\n",
        "            visible=False\n",
        "        )\n",
        "        histo_hat_mu_text = gr.Textbox(label=\"Write the value of a consistent estimator\", visible=False)\n",
        "\n",
        "        histo_hat_sigma = gr.Dropdown(\n",
        "            label=\"Ïƒ\",\n",
        "            choices=[\n",
        "                \"Deviation (1 ddof)\",\n",
        "                \"Range (bias corrected)\",\n",
        "                \"IQR (bias corrected)\",\n",
        "                \"MAD (bias corrected)\",\n",
        "                \"AAD (bias corrected)\",\n",
        "                \"Other\"\n",
        "            ],\n",
        "            value=\"Deviation (1 ddof)\",\n",
        "            interactive=True,\n",
        "            visible=False\n",
        "        )\n",
        "        histo_hat_sigma_text = gr.Textbox(label=\"Write the value of a consistent estimator\", visible=False)\n",
        "\n",
        "    with gr.Row() as histo_ci_row:\n",
        "        histo_add_ci = gr.Checkbox(label=\"Add Confidence Interval\", value=False)\n",
        "\n",
        "        histo_choose_ci = gr.Radio(\n",
        "            label=\"Confidence Interval\",\n",
        "            choices=[\"Mean\", \"Median\", \"Both\"],\n",
        "            value=\"Both\",\n",
        "            interactive=True,\n",
        "            visible=False\n",
        "        )\n",
        "\n",
        "    with gr.Row() as histo_pi_row:                \n",
        "        histo_add_pi = gr.Checkbox(label=\"Add Prediction Interval\", value=False)\n",
        "        histo_choose_pi = gr.Radio(\n",
        "            label=\"Prediction Interval\",\n",
        "            choices=[\"Mean\", \"Median\", \"IQR\", \"Bootstrap\"],\n",
        "            value=\"Mean\",\n",
        "            interactive=True,\n",
        "            visible=False\n",
        "        )\n",
        "\n",
        "    with gr.Row(visible=False) as ecdf_normal_row:\n",
        "        ecdf_add_normal = gr.Checkbox(label=\"Add Normal CDF\", value=False)\n",
        "\n",
        "        ecdf_hat_mu = gr.Dropdown(\n",
        "            label=\"Î¼\",\n",
        "            choices=[\n",
        "                'Sample Mean',\n",
        "                'Sample Median',\n",
        "                'Geometric Mean',\n",
        "                'Harmonic Mean',\n",
        "                'Weighted Mean',\n",
        "                'Trimmed Mean',\n",
        "                'Interquartile Mean',\n",
        "                'Winsorized Mean',\n",
        "                \"Other\"\n",
        "            ],\n",
        "            value=\"Sample Mean\",\n",
        "            interactive=True,\n",
        "            visible=False\n",
        "        )\n",
        "        ecdf_hat_mu_text = gr.Textbox(label=\"Write the value of a consistent estimator\", visible=False)\n",
        "\n",
        "        ecdf_hat_sigma = gr.Dropdown(\n",
        "            label=\"Ïƒ\",\n",
        "            choices=[\n",
        "                \"Deviation (1 ddof)\",\n",
        "                \"Range (bias corrected)\",\n",
        "                \"IQR (bias corrected)\",\n",
        "                \"MAD (bias corrected)\",\n",
        "                \"AAD (bias corrected)\",\n",
        "                \"Other\"\n",
        "            ],\n",
        "            value=\"Deviation (1 ddof)\",\n",
        "            interactive=True,\n",
        "            visible=False\n",
        "        )\n",
        "        ecdf_hat_sigma_text = gr.Textbox(label=\"Write the value of a consistent estimator\", visible=False)\n",
        "\n",
        "    with gr.Column(elem_id=\"column_centered\"):\n",
        "        run_graph_stat_button = gr.Button(value=\"ðŸš€ Run Graphical Analysis\", elem_id=\"run_button\")\n",
        "\n",
        "    # --- Results ---\n",
        "    output_table_row, output_table, output_plot_row, output_plot = build_results_block()\n",
        "\n",
        "    # --- Modify behavior of components of the GUI ---\n",
        "    refresh_columns_button.click(\n",
        "        fn=load_numeric_cols,\n",
        "        inputs=[],\n",
        "        outputs=[column_dropdown]\n",
        "    )\n",
        "\n",
        "    graph_stat_dropdown.change(\n",
        "        fn=toggle_graph_stat,\n",
        "        inputs=[graph_stat_dropdown],\n",
        "        outputs=[\n",
        "            histo_add_kde,\n",
        "            histo_add_data,\n",
        "            histo_normal_row,\n",
        "            histo_ci_row,\n",
        "            histo_pi_row,\n",
        "            ecdf_normal_row,\n",
        "            ecdf_add_conf,\n",
        "            ecdf_alpha]\n",
        "    )\n",
        "\n",
        "    histo_add_ci.change(\n",
        "        fn=lambda check: gr.update(visible=check),\n",
        "        inputs=[histo_add_ci],\n",
        "        outputs=[histo_choose_ci]\n",
        "    )\n",
        "\n",
        "    histo_add_pi.change(\n",
        "        fn=lambda check: gr.update(visible=check),\n",
        "        inputs=[histo_add_pi],\n",
        "        outputs=[histo_choose_pi]\n",
        "    )\n",
        "\n",
        "    histo_add_ci.change(\n",
        "        fn=histo_add_ci_warning,\n",
        "        inputs=[histo_add_ci],\n",
        "        outputs=[]\n",
        "    )\n",
        "\n",
        "    histo_add_pi.change(\n",
        "        fn=histo_add_pi_warning,\n",
        "        inputs=[histo_add_pi],\n",
        "        outputs=[]\n",
        "    )\n",
        "\n",
        "    histo_add_normal.change(\n",
        "        fn=toggle_add_normal,\n",
        "        inputs=[histo_add_normal, histo_hat_mu, histo_hat_sigma],\n",
        "        outputs=[histo_hat_mu, histo_hat_mu_text, histo_hat_sigma, histo_hat_sigma_text]\n",
        "    )\n",
        "\n",
        "    histo_add_normal.change(\n",
        "        fn=add_normal_warning,\n",
        "        inputs=histo_add_normal,\n",
        "        outputs=[]\n",
        "    )\n",
        "\n",
        "    histo_hat_mu.change(\n",
        "        fn=lambda choice: gr.update(visible=(choice == \"Other\")),\n",
        "        inputs=histo_hat_mu,\n",
        "        outputs=histo_hat_mu_text\n",
        "    )\n",
        "\n",
        "    histo_hat_sigma.change(\n",
        "        fn=lambda choice: gr.update(visible=(choice == \"Other\")),\n",
        "        inputs=histo_hat_sigma,\n",
        "        outputs=histo_hat_sigma_text\n",
        "    )\n",
        "\n",
        "    ecdf_add_conf.change(\n",
        "        fn=lambda check: gr.update(visible=check),\n",
        "        inputs=ecdf_add_conf,\n",
        "        outputs=ecdf_alpha\n",
        "    )\n",
        "\n",
        "    ecdf_add_normal.change(\n",
        "        fn=toggle_add_normal,\n",
        "        inputs=[ecdf_add_normal, ecdf_hat_mu, ecdf_hat_sigma],\n",
        "        outputs=[ecdf_hat_mu, ecdf_hat_mu_text, ecdf_hat_sigma, ecdf_hat_sigma_text]\n",
        "    )\n",
        "\n",
        "    ecdf_add_normal.change(\n",
        "        fn=add_normal_warning,\n",
        "        inputs=ecdf_add_normal,\n",
        "        outputs=[]\n",
        "    )\n",
        "\n",
        "    ecdf_hat_mu.change(\n",
        "        fn=lambda choice: gr.update(visible=(choice == \"Other\")),\n",
        "        inputs=ecdf_hat_mu,\n",
        "        outputs=ecdf_hat_mu_text\n",
        "    )\n",
        "\n",
        "    ecdf_hat_sigma.change(\n",
        "        fn=lambda choice: gr.update(visible=(choice == \"Other\")),\n",
        "        inputs=ecdf_hat_sigma,\n",
        "        outputs=ecdf_hat_sigma_text\n",
        "    )\n",
        "\n",
        "    # --- Run Analysis Button ---\n",
        "    run_graph_stat_button.click(\n",
        "        run_graph_stat,\n",
        "        inputs=[\n",
        "            column_dropdown,\n",
        "            graph_stat_dropdown,\n",
        "            histo_add_kde, histo_add_data,\n",
        "            histo_add_ci, histo_choose_ci,\n",
        "            histo_add_pi, histo_choose_pi,\n",
        "            histo_add_normal,\n",
        "            histo_hat_mu, histo_hat_mu_text,\n",
        "            histo_hat_sigma, histo_hat_sigma_text,\n",
        "            ecdf_add_conf,\n",
        "            ecdf_alpha,\n",
        "            ecdf_add_normal,\n",
        "            ecdf_hat_mu, ecdf_hat_mu_text,\n",
        "            ecdf_hat_sigma, ecdf_hat_sigma_text          \n",
        "        ],\n",
        "        outputs=[output_table_row, output_table, output_table, output_plot_row, output_plot, output_plot])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5b2f7179",
      "metadata": {},
      "source": [
        "# ðŸŽ® ðŸ§® Logic control of Descriptive Tab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "6a13dab5",
      "metadata": {},
      "outputs": [],
      "source": [
        "def parse_weights(input_str, length):\n",
        "    if not input_str.strip():\n",
        "        return None\n",
        "    weights = [float(w.strip()) for w in input_str.split(',') if w.strip()]\n",
        "    if len(weights) != length:\n",
        "        raise ValueError(f\"Number of weights ({len(weights)}) must match number of observations ({length})\")\n",
        "    return weights\n",
        "\n",
        "def parse_winsor(input_str):\n",
        "    if not input_str.strip():\n",
        "        return None\n",
        "    winsor_param = [float(w.strip()) for w in input_str.split(',') if w.strip()]\n",
        "    if len(winsor_param) != 2:\n",
        "        raise ValueError(f\"Length of winsorized input ({len(winsor_param)}) must be two (lower, and upper)\")\n",
        "    return winsor_param\n",
        "\n",
        "def parse_quantiles(input_str):\n",
        "    if ',' in input_str:\n",
        "        q = [float(x.strip()) for x in input_str.split(',') if x.strip()]\n",
        "    else:\n",
        "        q = float(input_str)\n",
        "    return q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "2864a27a",
      "metadata": {},
      "outputs": [],
      "source": [
        "def toggle_desc_params(desc_stat):\n",
        "    if desc_stat == \"Quantiles\":\n",
        "        return (\n",
        "            gr.update(visible=True),  # quantiles input\n",
        "            gr.update(visible=False) # central_tendecy_params\n",
        "        )\n",
        "    elif desc_stat in [\"Central Tendency\", \"All Descriptive Statistics\"]:\n",
        "        return (\n",
        "            gr.update(visible=False),  \n",
        "            gr.update(visible=True),\n",
        "        )\n",
        "    else:\n",
        "        return (\n",
        "            gr.update(visible=False),  \n",
        "            gr.update(visible=False)\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "d4bbfcdc",
      "metadata": {},
      "outputs": [],
      "source": [
        "def run_desc_stat(\n",
        "        column,\n",
        "        descriptive_stat,\n",
        "        quantiles_input, weights_input, trim_input, winsor_input\n",
        "        ):\n",
        "    \n",
        "    df, data, stats, error_df, error_plot = prepare_data(column)\n",
        "    if error_df:\n",
        "        return gr.update(visible=False), gr.update(visible=True), error_df, gr.update(visible=False), gr.update(visible=False), error_plot \n",
        "\n",
        "    # --- Descriptive Analysis ---\n",
        "    if descriptive_stat == \"Quantiles\":\n",
        "        q = parse_quantiles(quantiles_input)\n",
        "        stats.CalculateQuantiles(q)\n",
        "        df_output = stats.quantiles.round(ROUND).reset_index().rename(columns={\"index\": \"Measure\"})\n",
        "\n",
        "    elif descriptive_stat == \"Quartiles\":\n",
        "        stats.CalculateQuartiles()\n",
        "        df_output = stats.quartiles.round(ROUND).reset_index().rename(columns={\"index\": \"Measure\"})\n",
        "\n",
        "    elif descriptive_stat == \"Central Tendency\":\n",
        "        trim_param = parse_text(trim_input)\n",
        "        winsor_param = parse_winsor(winsor_input)\n",
        "        weights = parse_weights(weights_input, len(data))\n",
        "\n",
        "        stats.CalculateCentralTendency(weights=weights, winsor_param=winsor_param, trim_param=trim_param)\n",
        "        df_output = stats.central_tendency.round(ROUND).reset_index().rename(columns={\"index\": \"Measure\"})\n",
        "\n",
        "    elif descriptive_stat == \"Dispersion\":\n",
        "        stats.CalculateDispersion()\n",
        "        df_output = stats.dispersion.round(ROUND).reset_index().rename(columns={\"index\": \"Measure\"})\n",
        "\n",
        "    elif descriptive_stat == \"Skewness\":\n",
        "        stats.CalculateSkewness()\n",
        "        df_output = stats.skew.round(ROUND).reset_index().rename(columns={\"index\": \"Measure\"})\n",
        "\n",
        "    elif descriptive_stat == \"Kurtosis\":\n",
        "        stats.CalculateKurtosis()\n",
        "        df_output = stats.kurtosis.round(ROUND).reset_index().rename(columns={\"index\": \"Measure\"})\n",
        "\n",
        "    elif descriptive_stat == \"All Descriptive Statistics\":\n",
        "        trim_param = parse_text(trim_input)\n",
        "        winsor_param = parse_winsor(winsor_input)\n",
        "        weights = parse_weights(weights_input, len(data))\n",
        "\n",
        "        stats.CalculateDescriptiveStatistics(weights=weights, winsor_param=winsor_param, trim_param=trim_param)\n",
        "\n",
        "        # Merge all tables with a hierarchical index\n",
        "        df_combined = pd.concat([\n",
        "            stats.quartiles,\n",
        "            stats.central_tendency,\n",
        "            stats.dispersion,\n",
        "            stats.skew,\n",
        "            stats.kurtosis\n",
        "        ], keys=[\"Quartiles\", \"Central Tendency\", \"Dispersion\", \"Skewness\", \"Kurtosis\"])\n",
        "\n",
        "        df_output = df_combined.round(ROUND).reset_index().rename(columns={\"level_0\": \"Statistic Type\", \"level_1\": \"Measure\"})\n",
        "\n",
        "    export_cache[\"table\"] = df_output\n",
        "    #export_cache[\"figure\"] = fig\n",
        "\n",
        "    # output_table_row, output_table, output_table, output_plot_row, output_plot, output_plot\n",
        "    return gr.update(visible=True), gr.update(visible=True), df_output, gr.update(visible=False), gr.update(visible=False), None "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "40df50f4",
      "metadata": {},
      "source": [
        "# ðŸ–¥ï¸ ðŸ§® GUI of Descriptive Tab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "3e2e9d3a",
      "metadata": {},
      "outputs": [],
      "source": [
        "def build_descriptive_tab():\n",
        "    gr.Markdown(\"# ðŸ§® Descriptive Analysis\")\n",
        "\n",
        "    with gr.Row(elem_id=\"row_centered\"):\n",
        "        refresh_columns_button = gr.Button(\"ðŸ”„ Refresh Numeric Columns\")\n",
        "        column_dropdown = gr.Dropdown(label=\"Select Numeric Column\", choices=[], elem_classes=\"data_related\", elem_id=\"custom_dropdown\")\n",
        "\n",
        "        descriptive_stat = gr.Dropdown(\n",
        "            label=\"Select Descriptive Statistic\",\n",
        "            choices=[\n",
        "                \"Quantiles\",\n",
        "                \"Quartiles\",\n",
        "                \"Central Tendency\",\n",
        "                \"Dispersion\",\n",
        "                \"Skewness\",\n",
        "                \"Kurtosis\",\n",
        "                \"All Descriptive Statistics\"\n",
        "            ],\n",
        "            value=\"All Descriptive Statistics\",\n",
        "            interactive=True\n",
        "        )\n",
        "        quantiles_input = gr.Textbox(label=\"Quantiles (e.g., 0.25, 0.5, 0.75)\", value=\"0.25, 0.5, 0.75\", visible=False)\n",
        "\n",
        "    with gr.Row() as central_tendecy_params:\n",
        "        weights_input = gr.Textbox(label=\"Weights (comma-separated)\", placeholder=\"e.g., 1, 1, 0.5, 0.8\", visible=True)\n",
        "        trim_input = gr.Textbox(label=\"Trim percentage (e.g., 0.1)\", value=0.1, visible=True)\n",
        "        winsor_input = gr.Textbox(label=\"Winsorized percentages (e.g., 0.1, 0.1)\", value=\"0.1, 0.1\", visible=True)\n",
        "\n",
        "    with gr.Column(elem_id=\"column_centered\"):\n",
        "        run_desc_stat_button = gr.Button(value=\"ðŸš€ Run Descriptive Analysis\", elem_id=\"run_button\")\n",
        "\n",
        "    # --- Results ---\n",
        "    output_table_row, output_table, output_plot_row, output_plot = build_results_block()\n",
        "\n",
        "    # --- Modify behavior of components of the GUI ---\n",
        "    refresh_columns_button.click(\n",
        "        fn=load_numeric_cols,\n",
        "        inputs=[],\n",
        "        outputs=[column_dropdown]\n",
        "    )\n",
        "\n",
        "    descriptive_stat.change(\n",
        "        fn=toggle_desc_params,\n",
        "        inputs=descriptive_stat,\n",
        "        outputs=[quantiles_input, central_tendecy_params]\n",
        "    )\n",
        "\n",
        "    # --- Run Analysis Button ---\n",
        "    run_desc_stat_button.click(\n",
        "        run_desc_stat,\n",
        "        inputs=[\n",
        "            column_dropdown,\n",
        "            descriptive_stat,\n",
        "            quantiles_input, weights_input, trim_input, winsor_input\n",
        "        ],\n",
        "        outputs=[output_table_row, output_table, output_table, output_plot_row, output_plot, output_plot]\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8da322cf",
      "metadata": {},
      "source": [
        "# ðŸŽ® ðŸ’­ Logic control of Statistical Inference Tab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "b904f228",
      "metadata": {},
      "outputs": [],
      "source": [
        "def stat_inf_warning(check):\n",
        "    if check:\n",
        "        gr.Warning(\"If you haven't done it yet, run first a descriptive analysis for central tendency and dispersion.\")\n",
        "\n",
        "def conf_interval_warning(check):\n",
        "    if check == \"Confidence Regions\":\n",
        "        gr.Warning(\"If you haven't done it yet, run first a statistical inference for CI.\")\n",
        "\n",
        "def conf_interval_range(check):\n",
        "    if check == \"Range (bias corrected)\":\n",
        "        gr.Info(\"CI calculations for deviation can be slow for n larger than 25, due to the complexity of the integrals.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "1c6dbec1",
      "metadata": {},
      "outputs": [],
      "source": [
        "def parse_probs(input_str):\n",
        "    if not input_str.strip():\n",
        "        return None\n",
        "    probs = [float(w.strip()) for w in input_str.split(',') if w.strip()]\n",
        "    return probs\n",
        "\n",
        "def parse_margin(input_str):\n",
        "    if not input_str.strip():\n",
        "        return None\n",
        "    eps = [float(w.strip()) for w in input_str.split(',') if w.strip()]\n",
        "    if len(eps) != 2:\n",
        "        raise ValueError(f\"Length of margin ({len(eps)}) must be two (Î¼,Ïƒ)\")\n",
        "    return eps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "437e826d",
      "metadata": {},
      "outputs": [],
      "source": [
        "def toggle_stat_inf(sel, boots_mean_check, boots_median_check, boots_deviation_check, boots_prediction_check):\n",
        "    if sel == \"Confidence Interval\":\n",
        "        return [\n",
        "            gr.update(visible=True), # alpha_input\n",
        "            gr.update(visible=True), # stat_inf_intervals\n",
        "            gr.update(visible=True, value=boots_mean_check), # boots_mean_check\n",
        "            gr.update(visible=True, value=boots_median_check), # boots_median_check\n",
        "            gr.update(visible=True, value=boots_deviation_check), # boots_deviation_check\n",
        "            gr.update(visible=False, value=False), # boots_prediction_check\n",
        "            gr.update(visible=False) # stat_inf_regions\n",
        "        ]\n",
        "    elif sel == \"Prediction Interval\":\n",
        "        if boots_prediction_check:\n",
        "            return [\n",
        "                gr.update(visible=True), # alpha_input\n",
        "                gr.update(visible=False), # stat_inf_intervals\n",
        "                gr.update(visible=False, value=False), # boots_mean_check\n",
        "                gr.update(visible=False, value=False), # boots_median_check\n",
        "                gr.update(visible=False, value=False), # boots_deviation_check\n",
        "                gr.update(visible=True, value=boots_prediction_check), # boots_prediction_check\n",
        "                gr.update(visible=False) # stat_inf_regions\n",
        "            ]\n",
        "        else:\n",
        "            return [\n",
        "                gr.update(visible=True), # alpha_input\n",
        "                gr.update(visible=True), # stat_inf_intervals\n",
        "                gr.update(visible=False, value=False), # boots_mean_check\n",
        "                gr.update(visible=False, value=False), # boots_median_check\n",
        "                gr.update(visible=False, value=False), # boots_deviation_check\n",
        "                gr.update(visible=True, value=boots_prediction_check), # boots_prediction_check\n",
        "                gr.update(visible=False) # stat_inf_regions\n",
        "            ]\n",
        "    elif sel == \"Confidence and Prediction Intervals\":\n",
        "            return [\n",
        "                gr.update(visible=True), # alpha_input\n",
        "                gr.update(visible=True), # stat_inf_intervals\n",
        "                gr.update(visible=True, value=boots_mean_check), # boots_mean_check\n",
        "                gr.update(visible=True, value=boots_median_check), # boots_median_check\n",
        "                gr.update(visible=True, value=boots_deviation_check), # boots_deviation_check\n",
        "                gr.update(visible=True, value=boots_prediction_check), # boots_prediction_check\n",
        "                gr.update(visible=False) # stat_inf_regions\n",
        "            ]\n",
        "    elif sel == \"Confidence Regions\":\n",
        "            return [\n",
        "                gr.update(visible=False), # alpha_input\n",
        "                gr.update(visible=False), # stat_inf_intervals\n",
        "                gr.update(visible=False, value=False), # boots_mean_check\n",
        "                gr.update(visible=False, value=False), # boots_median_check\n",
        "                gr.update(visible=False, value=False), # boots_deviation_check\n",
        "                gr.update(visible=False, value=False), # boots_prediction_check\n",
        "                gr.update(visible=True) # stat_inf_regions\n",
        "            ]\n",
        "    elif sel == \"Confidence Interval and Regions\":\n",
        "            return [\n",
        "                gr.update(visible=True), # alpha_input\n",
        "                gr.update(visible=True), # stat_inf_intervals\n",
        "                gr.update(visible=True, value=boots_mean_check), # boots_mean_check\n",
        "                gr.update(visible=True, value=boots_median_check), # boots_median_check\n",
        "                gr.update(visible=True, value=boots_deviation_check), # boots_deviation_check\n",
        "                gr.update(visible=False, value=False), # boots_prediction_check\n",
        "                gr.update(visible=True) # stat_inf_regions\n",
        "            ]\n",
        "    \n",
        "def toggle_slider_visibility(boots_mean_check, boots_median_check, boots_deviation_check, boots_prediction_check):\n",
        "    # Show slider if any checkbox is checked\n",
        "    visible = boots_mean_check or boots_median_check or boots_deviation_check or boots_prediction_check\n",
        "    return gr.update(visible=visible)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "b856f8c3",
      "metadata": {},
      "outputs": [],
      "source": [
        "def update_mean_choices(check):\n",
        "    if check:\n",
        "        return gr.update(\n",
        "            choices=[\n",
        "                \"Sample Mean\",\n",
        "                \"Geometric Mean\",\n",
        "                \"Harmonic Mean\",\n",
        "                \"Trimmed Mean\",\n",
        "                \"Interquartile Mean\",\n",
        "                \"Winsorized Mean\"\n",
        "            ],\n",
        "            value=\"Sample Mean\")\n",
        "    else:\n",
        "        return gr.update(\n",
        "            choices=[\n",
        "                \"Sample Mean\",\n",
        "                \"Geometric Mean\",\n",
        "                \"Harmonic Mean\",\n",
        "                \"Weighted Mean\",\n",
        "                \"Trimmed Mean\",\n",
        "                \"Interquartile Mean\",\n",
        "                \"Winsorized Mean\",\n",
        "                \"Other\"\n",
        "            ],\n",
        "            value=\"Sample Mean\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "3c6993c2",
      "metadata": {},
      "outputs": [],
      "source": [
        "def update_median_choices(check):\n",
        "    if check:\n",
        "        return gr.update(\n",
        "            choices=[\n",
        "                \"Sample Median\"\n",
        "            ],\n",
        "            value=\"Sample Median\")\n",
        "    else:\n",
        "        return gr.update(\n",
        "            choices=[\n",
        "                \"Sample Median\",\n",
        "                \"Other\"\n",
        "            ],\n",
        "            value=\"Sample Median\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "7923859d",
      "metadata": {},
      "outputs": [],
      "source": [
        "def update_deviation_choices(check):\n",
        "    if check:\n",
        "        return gr.update(\n",
        "            choices=[\n",
        "                \"Deviation (1 ddof)\",\n",
        "                \"Range (bias corrected)\",\n",
        "                \"IQR (bias corrected)\",\n",
        "                \"MAD (bias corrected)\",\n",
        "                \"AAD (bias corrected)\"\n",
        "            ],\n",
        "            value=\"Deviation (1 ddof)\")\n",
        "    else:\n",
        "        return gr.update(\n",
        "            choices=[\n",
        "                \"Deviation (1 ddof)\",\n",
        "                \"Range (bias corrected)\",\n",
        "                \"IQR (bias corrected)\",\n",
        "                \"MAD (bias corrected)\",\n",
        "                \"AAD (bias corrected)\",\n",
        "                \"Other\"\n",
        "            ],\n",
        "            value=\"Deviation (1 ddof)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "c63d5484",
      "metadata": {},
      "outputs": [],
      "source": [
        "def run_stat_inf(\n",
        "        column,\n",
        "        statistical_inf,\n",
        "        alpha_input,\n",
        "        probs_input, eps_input_mu, eps_input_sigma,\n",
        "        like_add_interval,\n",
        "        mean_select, mean_estimate_text,\n",
        "        median_select, median_estimate_text,\n",
        "        sigma_select, sigma_estimate_text,\n",
        "        boots_mean, boots_median, boots_deviation, boots_prediction,\n",
        "        bootstrap_samples\n",
        "        ):\n",
        "    \n",
        "    df, data, stats, error_df, error_plot = prepare_data(column)\n",
        "    if error_df:\n",
        "        return gr.update(visible=False), gr.update(visible=True), error_df, gr.update(visible=False), gr.update(visible=False), error_plot \n",
        "\n",
        "    # --- Statistical Inference ---\n",
        "    alpha = parse_text(alpha_input)\n",
        "    alpha = 1 - alpha\n",
        "    if alpha is None or not (0 < alpha < 1):\n",
        "        return [\n",
        "            gr.update(visible=False),\n",
        "            gr.update(visible=True),\n",
        "            pd.DataFrame([[\"Invalid alpha value.\"]], columns=[\"Error\"]),\n",
        "            gr.update(visible=False),\n",
        "            gr.update(visible=False),\n",
        "            None]\n",
        "\n",
        "    # Choose mean\n",
        "    hat_mean = choose_mu(mean_select, stats, mean_estimate_text)\n",
        "    \n",
        "    # Choose median\n",
        "    if median_select == \"Sample Median\":\n",
        "        hat_median = stats.median\n",
        "    elif  median_select == \"Other\":\n",
        "        hat_median = float(median_estimate_text)\n",
        "\n",
        "    # Choose sigma\n",
        "    hat_sigma = choose_sigma(sigma_select, stats, sigma_estimate_text)\n",
        "        \n",
        "    if (mean_select == \"Sample Mean\") and (sigma_select == \"Deviation (1 ddof)\"):\n",
        "        dist=\"t\"\n",
        "    else:\n",
        "        dist=\"norm\"\n",
        "\n",
        "    if statistical_inf == \"Confidence Interval\":\n",
        "        stats.CalculateConfidenceInterval(\n",
        "            alpha, hat_mean, hat_median, hat_sigma, dist,\n",
        "            mean_select, sigma_select, boots_mean, boots_median, boots_deviation, bootstrap_samples)\n",
        "        df_output = stats.confidence_intervals.round(ROUND).reset_index().rename(columns={\"index\": \"Measure\"})\n",
        "        fig = None\n",
        "        visible_table = True\n",
        "        visible_fig = False\n",
        "\n",
        "    elif statistical_inf == \"Prediction Interval\":\n",
        "        if boots_prediction:\n",
        "            stats.CalculatePiBoots(alpha, bootstrap_samples)\n",
        "            df_output = stats.prediction_intervals_boots.round(ROUND).reset_index().rename(columns={\"index\": \"Measure\"})\n",
        "        else:\n",
        "            stats.CalculatePredictionInterval(alpha, hat_mean, hat_median, hat_sigma, dist)\n",
        "            df_output = stats.prediction_intervals.round(ROUND).reset_index().rename(columns={\"index\": \"Measure\"})\n",
        "        fig = None\n",
        "        visible_table = True\n",
        "        visible_fig = False\n",
        "\n",
        "    elif statistical_inf == \"Confidence and Prediction Intervals\":\n",
        "        stats.CalculateConfidenceInterval(\n",
        "            alpha, hat_mean, hat_median, hat_sigma, dist,\n",
        "            mean_select, sigma_select, boots_mean, boots_median, boots_deviation, bootstrap_samples)\n",
        "        if boots_prediction:\n",
        "            stats.CalculatePiBoots(alpha, bootstrap_samples)\n",
        "\n",
        "            # Merge all tables with a hierarchical index\n",
        "            df_combined = pd.concat([\n",
        "                stats.confidence_intervals,\n",
        "                stats.prediction_intervals_boots\n",
        "            ], keys=[\"Confidence\", \"Prediction\"])\n",
        "        else:\n",
        "            stats.CalculatePredictionInterval(alpha, hat_mean, hat_median, hat_sigma, dist)\n",
        "\n",
        "            # Merge all tables with a hierarchical index\n",
        "            df_combined = pd.concat([\n",
        "                stats.confidence_intervals,\n",
        "                stats.prediction_intervals\n",
        "            ], keys=[\"Confidence\", \"Prediction\"])\n",
        "    \n",
        "        df_output = df_combined.round(ROUND).reset_index().rename(columns={\"level_0\": \"Interval Type\", \"level_1\": \"Measure\"})\n",
        "        fig = None\n",
        "        visible_table = True\n",
        "        visible_fig = False\n",
        "\n",
        "    elif statistical_inf == \"Confidence Regions\":\n",
        "        probs = parse_probs(probs_input)\n",
        "        eps_mu = parse_margin(eps_input_mu)\n",
        "        eps_sigma = parse_margin(eps_input_sigma)\n",
        "        fig = stats.PlotConfidenceRegions(probs, eps_mu, eps_sigma, like_add_interval)\n",
        "        df_output = pd.DataFrame()\n",
        "        visible_table = False \n",
        "        visible_fig = True\n",
        "    \n",
        "    elif statistical_inf == \"Confidence Interval and Regions\":\n",
        "        probs = parse_probs(probs_input)\n",
        "        eps_mu = parse_margin(eps_input_mu)\n",
        "        eps_sigma = parse_margin(eps_input_sigma)\n",
        "        stats.CalculateConfidenceInterval(\n",
        "            alpha, hat_mean, hat_median, hat_sigma, dist,\n",
        "            mean_select, sigma_select, boots_mean, boots_median, boots_deviation, bootstrap_samples)\n",
        "        df_output = stats.confidence_intervals.round(ROUND).reset_index().rename(columns={\"index\": \"Measure\"})\n",
        "        fig = stats.PlotConfidenceRegions(probs, eps_mu, eps_sigma, like_add_interval)\n",
        "        visible_table = True\n",
        "        visible_fig = True\n",
        "\n",
        "    export_cache[\"table\"] = df_output\n",
        "    export_cache[\"figure\"] = fig\n",
        "\n",
        "    # output_table_row, output_table, output_table, output_plot_row, output_plot, output_plot\n",
        "    return gr.update(visible=visible_table), gr.update(visible=visible_table), df_output, gr.update(visible=visible_fig), gr.update(visible=visible_fig), fig"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dccce95f",
      "metadata": {},
      "source": [
        "# ðŸ–¥ï¸ ðŸ’­ GUI of Statistical Inference Tab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "467c4bd5",
      "metadata": {},
      "outputs": [],
      "source": [
        "def build_inference_tab():\n",
        "    gr.Markdown(\"# ðŸ’­ Statistical Inference\")\n",
        "\n",
        "    with gr.Accordion(\"ðŸ§  Technical Information\", open=False):\n",
        "        gr.Markdown(\n",
        "            \"\"\"\n",
        "            - All intervals are calculated assuming the observations are i.i.d. from a Normal distribution.  \n",
        "            - If the sample mean and the sample deviation with one degree of freedom are selected as estimators for the mean and standard deviation, \n",
        "            then a *t*-distribution is used to compute the Confidence Interval (CI) for the mean and the Prediction Interval (PI) based on the mean.  \n",
        "            - The asymptotic Normal distribution is used for the CI and PI based on the median.\n",
        "            - The exact distribution for the CI of the deviation is used when the deviation with 1 ddof or the range is selected.\n",
        "            - The asymptotic Normal distribution for the CI for the deviation is used when the IQR, AAD or MAD is selected.\n",
        "            - When the sample size is not large, it might be preferable to use intervals based on bootstrap.\n",
        "            \"\"\"\n",
        "        )\n",
        "\n",
        "    with gr.Row(elem_id=\"row_centered\"):\n",
        "        refresh_columns_button = gr.Button(\"ðŸ”„ Refresh Numeric Columns\")\n",
        "        column_dropdown = gr.Dropdown(label=\"Select Numeric Column\", choices=[], elem_classes=\"data_related\", elem_id=\"custom_dropdown\")\n",
        "        \n",
        "        stat_inf_dropdown = gr.Dropdown(\n",
        "            label=\"Type of Estimation\",\n",
        "            choices=[\n",
        "                \"Confidence Interval\",\n",
        "                \"Prediction Interval\",\n",
        "                \"Confidence and Prediction Intervals\",\n",
        "                \"Confidence Regions\",\n",
        "                \"Confidence Interval and Regions\"\n",
        "            ],\n",
        "            value=\"Confidence and Prediction Intervals\",\n",
        "            interactive=True\n",
        "        )\n",
        "        alpha_input = gr.Textbox(label=\"Confidence level (e.g. 0.95)\", value=0.95, interactive=True)\n",
        "\n",
        "    with gr.Row(visible=True) as stat_inf_intervals:\n",
        "        mean_select = gr.Dropdown(\n",
        "            choices=[\n",
        "                \"Sample Mean\",\n",
        "                \"Geometric Mean\",\n",
        "                \"Harmonic Mean\",\n",
        "                \"Weighted Mean\",\n",
        "                \"Trimmed Mean\",\n",
        "                \"Interquartile Mean\",\n",
        "                \"Winsorized Mean\",\n",
        "                \"Other\"\n",
        "                ],\n",
        "            label=\"Mean Estimate\",\n",
        "            value=\"Sample Mean\"\n",
        "        )\n",
        "\n",
        "        mean_estimate_text = gr.Textbox(label=\"Write the value of a consistent estimator\", visible=False)\n",
        "\n",
        "        median_select = gr.Dropdown(\n",
        "            choices=[\"Sample Median\", \"Other\"],\n",
        "            label=\"Median Estimate\", value=\"Sample Median\"\n",
        "        )\n",
        "        median_estimate_text = gr.Textbox(label=\"Write the value of a consistent estimator\", visible=False)\n",
        "\n",
        "        sigma_select = gr.Dropdown(\n",
        "            choices=[\n",
        "                \"Deviation (1 ddof)\",\n",
        "                \"Range (bias corrected)\",\n",
        "                \"IQR (bias corrected)\",\n",
        "                \"MAD (bias corrected)\",\n",
        "                \"AAD (bias corrected)\",\n",
        "                \"Other\"\n",
        "            ],\n",
        "            label=\"Deviation Estimate\",\n",
        "            value=\"Deviation (1 ddof)\"\n",
        "        )\n",
        "        sigma_estimate_text = gr.Textbox(label=\"Write the value of a consistent estimator\", visible=False)\n",
        "\n",
        "    with gr.Row(visible=True) as stat_inf_boots:\n",
        "        boots_mean_check = gr.Checkbox(label=\"Use bootstrap for the mean?\", value=False)\n",
        "        boots_median_check = gr.Checkbox(label=\"Use bootstrap for the median?\", value=False)\n",
        "        boots_deviation_check = gr.Checkbox(label=\"Use bootstrap for the deviation?\", value=False)\n",
        "        boots_prediction_check = gr.Checkbox(label=\"Use bootstrap for the prediction?\", value=False)\n",
        "    \n",
        "    boots_sample = gr.Slider(minimum=100, maximum=5000, value=1000, step=100, label=\"Bootstrap Samples\", visible=False)\n",
        "\n",
        "    with gr.Row(visible=False) as stat_inf_regions:\n",
        "        like_probs = gr.Textbox(label=\"Confidence levels (from lower to higher)\", value=\"0.1, 0.5, 0.75, 0.89, 0.95\", interactive=True, visible=True)\n",
        "        like_eps_mu = gr.Textbox(label=\"Extra margin for Î¼ and Ïƒ\", value=\"0.1, 0.1\", interactive=True, visible=True)\n",
        "        like_eps_sigma = gr.Textbox(label=\"Extra margin for Ïƒ\", value=\"0.05, 0.05\", interactive=True, visible=True)\n",
        "        like_add_interval = gr.Checkbox(label=\"Add CI for Î¼ and Ïƒ\", value=True)\n",
        "\n",
        "    with gr.Column(elem_id=\"column_centered\"):\n",
        "        run_stat_inf_button = gr.Button(value=\"ðŸš€ Run Statistical Inference\", elem_id=\"run_button\")\n",
        "    \n",
        "    # --- Results ---\n",
        "    output_table_row, output_table, output_plot_row, output_plot = build_results_block()\n",
        "\n",
        "    # --- Modify behavior of components of the GUI ---\n",
        "    refresh_columns_button.click(\n",
        "        fn=load_numeric_cols,\n",
        "        inputs=[],\n",
        "        outputs=[column_dropdown]\n",
        "    )\n",
        "\n",
        "    column_dropdown.change(\n",
        "        fn=stat_inf_warning,\n",
        "        inputs=[column_dropdown],\n",
        "        outputs=[]\n",
        "    )\n",
        "\n",
        "    stat_inf_dropdown.change(\n",
        "        fn=conf_interval_warning,\n",
        "        inputs=[stat_inf_dropdown],\n",
        "        outputs=[]\n",
        "    )\n",
        "\n",
        "    stat_inf_dropdown.change(\n",
        "        fn=toggle_stat_inf,\n",
        "        inputs=[stat_inf_dropdown, boots_mean_check, boots_median_check, boots_deviation_check, boots_prediction_check],\n",
        "        outputs=[alpha_input, stat_inf_intervals, boots_mean_check, boots_median_check, boots_deviation_check, boots_prediction_check, stat_inf_regions]\n",
        "    )\n",
        "\n",
        "    boots_prediction_check.change(\n",
        "        fn=toggle_stat_inf,\n",
        "        inputs=[stat_inf_dropdown, boots_mean_check, boots_median_check, boots_deviation_check, boots_prediction_check],\n",
        "        outputs=[alpha_input, stat_inf_intervals, boots_mean_check, boots_median_check, boots_deviation_check, boots_prediction_check, stat_inf_regions]\n",
        "    )\n",
        "\n",
        "    mean_select.change(\n",
        "        fn=lambda choice: gr.update(visible=(choice == \"Other\")),\n",
        "        inputs=mean_select,\n",
        "        outputs=mean_estimate_text\n",
        "    )\n",
        "\n",
        "    median_select.change(\n",
        "        fn=lambda choice: gr.update(visible=(choice == \"Other\")),\n",
        "        inputs=median_select,\n",
        "        outputs=median_estimate_text\n",
        "    )\n",
        "\n",
        "    sigma_select.change(\n",
        "        fn=lambda choice: gr.update(visible=(choice == \"Other\")),\n",
        "        inputs=sigma_select,\n",
        "        outputs=sigma_estimate_text\n",
        "    )\n",
        "\n",
        "    sigma_select.change(\n",
        "        fn=conf_interval_range,\n",
        "        inputs=sigma_select,\n",
        "        outputs=[]\n",
        "    )\n",
        "    for checkbox in [boots_mean_check, boots_median_check, boots_deviation_check, boots_prediction_check]:\n",
        "        checkbox.change(\n",
        "            fn=toggle_slider_visibility,\n",
        "            inputs=[boots_mean_check, boots_median_check, boots_deviation_check, boots_prediction_check],\n",
        "            outputs=boots_sample\n",
        "        )\n",
        "\n",
        "    boots_mean_check.change(\n",
        "        fn=update_mean_choices,\n",
        "        inputs=boots_mean_check,\n",
        "        outputs=mean_select\n",
        "    )\n",
        "\n",
        "    boots_median_check.change(\n",
        "        fn=update_median_choices,\n",
        "        inputs=boots_median_check,\n",
        "        outputs=median_select\n",
        "    )\n",
        "\n",
        "    boots_deviation_check.change(\n",
        "        fn=update_deviation_choices,\n",
        "        inputs=boots_deviation_check,\n",
        "        outputs=sigma_select\n",
        "    )\n",
        "\n",
        "    # --- Run Analysis Button ---\n",
        "    run_stat_inf_button.click(\n",
        "        run_stat_inf,\n",
        "        inputs=[\n",
        "            column_dropdown,\n",
        "            stat_inf_dropdown,\n",
        "            alpha_input,\n",
        "            like_probs, like_eps_mu, like_eps_sigma,\n",
        "            like_add_interval,\n",
        "            mean_select, mean_estimate_text,\n",
        "            median_select, median_estimate_text,\n",
        "            sigma_select, sigma_estimate_text,\n",
        "            boots_mean_check, boots_median_check, boots_deviation_check, boots_prediction_check,\n",
        "            boots_sample\n",
        "        ],\n",
        "        outputs=[output_table_row, output_table, output_table, output_plot_row, output_plot, output_plot]\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "28f822a0",
      "metadata": {},
      "source": [
        "# ðŸ§  ðŸ§ª Brain of Hypothesis Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "c12d488f",
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_ttest_mean_distribution(numeric_col, sample, mu0, df_output, alternative, bootstrap_samples):\n",
        "    plt.style.use(\"seaborn-v0_8-whitegrid\")\n",
        "\n",
        "    # --- t-test using Pingouin ---\n",
        "    t_val = df_output[\"T\"].values[0]\n",
        "    p_val = df_output[\"p-val\"].values[0]\n",
        "    df = df_output[\"dof\"].values[0]\n",
        "\n",
        "    # --- Sample stats ---\n",
        "    n = len(sample)\n",
        "    sample_mean = np.mean(sample)\n",
        "    sample_std = np.std(sample, ddof=1)\n",
        "    se = sample_std / np.sqrt(n)\n",
        "\n",
        "    # --- Theoretical t-distribution under Hâ‚€ ---\n",
        "    x = np.linspace(mu0 - 5 * se, mu0 + 5 * se, 1000)\n",
        "    t_density = t.pdf((x - mu0) / se, df) / se\n",
        "\n",
        "    # --- Bootstrap sampling distribution of the mean (off-screen figure) ---\n",
        "    boot_means = np.array([\n",
        "        np.mean(np.random.choice(sample, size=n, replace=True))\n",
        "        for _ in range(bootstrap_samples)\n",
        "    ])\n",
        "\n",
        "    fig_tmp, ax_tmp = plt.subplots()\n",
        "    sns.kdeplot(boot_means, bw_adjust=1.2, ax=ax_tmp)\n",
        "    x_kde, y_kde = ax_tmp.lines[0].get_data()\n",
        "    plt.close(fig_tmp)  # Close temporary plot\n",
        "\n",
        "    # --- Plot ---\n",
        "    fig, ax = plt.subplots(figsize=(8, 5))\n",
        "\n",
        "    # Plot bootstrap KDE\n",
        "    ax.plot(x_kde, y_kde, color=\"rebeccapurple\", label=\"Bootstrap sampling dist.\", linewidth=2)\n",
        "\n",
        "    # Plot theoretical t-distribution under Hâ‚€\n",
        "    ax.plot(x, t_density, color=\"gray\", linestyle=\"--\", linewidth=2, label=fr\"$t$-distribution ($H_0$)\")\n",
        "\n",
        "    # --- Shade p-value region under t-distribution ---\n",
        "    if alternative == \"two-sided\":\n",
        "        delta = abs(sample_mean - mu0)\n",
        "        lower = mu0 - delta\n",
        "        upper = mu0 + delta\n",
        "        mask = (x <= lower) | (x >= upper)\n",
        "    elif alternative == \"greater\":\n",
        "        mask = x >= sample_mean\n",
        "    elif alternative == \"less\":\n",
        "        mask = x <= sample_mean\n",
        "    else:\n",
        "        raise ValueError(\"alternative must be 'two-sided', 'greater', or 'less'\")\n",
        "\n",
        "    ax.fill_between(x, 0, t_density, where=mask, color=\"red\", alpha=0.3,\n",
        "                    label=f\"p-value â‰ˆ {p_val:.3f}\")\n",
        "\n",
        "    # --- Reference lines ---\n",
        "    ax.axvline(mu0, color=\"tab:orange\", linestyle=\"--\", linewidth=2, label=fr\"$\\mu_0 = {mu0}$\")\n",
        "    ax.axvline(sample_mean, color=\"black\", linestyle=\"-\", linewidth=1.5,\n",
        "               label=fr\"Sample mean = {sample_mean:.2f}\")\n",
        "\n",
        "    # --- Formatting ---\n",
        "    ax.set_title(f\"Sampling Distribution of the Mean ({numeric_col})\", fontsize=14)\n",
        "    ax.set_xlabel(\"Sample Mean\", fontsize=12)\n",
        "    ax.set_ylabel(\"Density\", fontsize=12)\n",
        "    ax.grid(True, linestyle='--', alpha=0.5)\n",
        "    ax.legend()\n",
        "    plt.tight_layout()\n",
        "\n",
        "    return fig\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "7ac09c17",
      "metadata": {},
      "outputs": [],
      "source": [
        "def one_sample_ttest(numeric_col, mu0_text, alternative, graph_check, bootstrap_samples):\n",
        "\n",
        "    df, data, stats, error_df, error_plot = prepare_data(numeric_col)\n",
        "    if error_df:\n",
        "        return gr.update(visible=False), gr.update(visible=True), error_df, gr.update(visible=False), gr.update(visible=False), error_plot \n",
        "\n",
        "    mu0 = float(mu0_text)\n",
        "\n",
        "    try:\n",
        "        sample = df[numeric_col].dropna()\n",
        "        if sample.empty:\n",
        "            return [\n",
        "                gr.update(visible=False),\n",
        "                gr.update(visible=True),\n",
        "                pd.DataFrame([[\"No valid data in the selected column.\"]], columns=[\"Error\"]),\n",
        "                gr.update(visible=False),\n",
        "                gr.update(visible=False),\n",
        "                None\n",
        "            ]\n",
        "\n",
        "        # --- One-sample t-test ---\n",
        "        df_output = pg.ttest(sample, mu0, alternative=alternative, paired=False).round(4)\n",
        "\n",
        "        # --- Plot ---\n",
        "        if graph_check:\n",
        "            fig = plot_ttest_mean_distribution(numeric_col, sample, mu0, df_output, alternative, bootstrap_samples)\n",
        "\n",
        "            export_cache[\"table\"] = df_output\n",
        "            export_cache[\"figure\"] = fig\n",
        "\n",
        "            return [\n",
        "                gr.update(visible=True),\n",
        "                gr.update(visible=True),\n",
        "                df_output,\n",
        "                gr.update(visible=True),\n",
        "                gr.update(visible=True),\n",
        "                fig\n",
        "            ]\n",
        "        \n",
        "        else:\n",
        "            export_cache[\"table\"] = df_output\n",
        "            export_cache[\"figure\"] = None\n",
        "\n",
        "            return [\n",
        "                gr.update(visible=True),\n",
        "                gr.update(visible=True),\n",
        "                df_output,\n",
        "                gr.update(visible=False),\n",
        "                gr.update(visible=False),\n",
        "                None\n",
        "            ]\n",
        "\n",
        "    except Exception as e:\n",
        "        return [\n",
        "            gr.update(visible=False),\n",
        "            gr.update(visible=True),\n",
        "            pd.DataFrame([[f\"âŒ Error: {e}\"]], columns=[\"Error\"]),\n",
        "            gr.update(visible=False),\n",
        "            gr.update(visible=False),\n",
        "            None\n",
        "        ]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "35901676",
      "metadata": {},
      "outputs": [],
      "source": [
        "def mirror_plot(numeric_col, group1, name_group1, group2, name_group2, df_output):\n",
        "    # Extract test results from df_output\n",
        "    t_val = df_output[\"T\"].values[0]\n",
        "    p_val = df_output[\"p-val\"].values[0]\n",
        "\n",
        "    # Means\n",
        "    mean1 = np.mean(group1)\n",
        "    mean2 = np.mean(group2)\n",
        "\n",
        "    # Setup plot\n",
        "    fig, ax = plt.subplots(figsize=(10, 6))\n",
        "\n",
        "    # Shared binning and KDE range\n",
        "    combined = np.concatenate([group1, group2])\n",
        "    x_min, x_max = min(combined), max(combined)\n",
        "    bin_range = np.linspace(x_min, x_max, 30)\n",
        "    bin_centers = (bin_range[:-1] + bin_range[1:]) / 2\n",
        "    bin_width = np.diff(bin_range)[0]\n",
        "    x_vals = np.linspace(x_min, x_max, 200)\n",
        "\n",
        "    # --- Group 1 (top) ---\n",
        "    sns.histplot(group1, bins=bin_range, stat=\"density\", kde=False,\n",
        "                 color=\"rebeccapurple\", label=name_group1, alpha=0.6, ax=ax)\n",
        "    kde1 = gaussian_kde(group1)\n",
        "    ax.plot(x_vals, kde1(x_vals), color=\"rebeccapurple\", linewidth=2)\n",
        "    ax.axvline(mean1, color=\"rebeccapurple\", linestyle=\"--\", linewidth=2,\n",
        "               label=f\"{name_group1} mean = {mean1:.2f}\")\n",
        "\n",
        "    # --- Group 2 (bottom, mirrored) ---\n",
        "    heights2, _ = np.histogram(group2, bins=bin_range, density=True)\n",
        "    ax.bar(bin_centers, -heights2, width=bin_width,\n",
        "           color=\"tab:orange\", edgecolor=\"black\", alpha=0.6, label=name_group2)\n",
        "    kde2 = gaussian_kde(group2)\n",
        "    ax.plot(x_vals, -kde2(x_vals), color=\"tab:orange\", linewidth=2)\n",
        "    ax.axvline(mean2, color=\"tab:orange\", linestyle=\"--\", linewidth=2,\n",
        "               label=f\"{name_group2} mean = {mean2:.2f}\")\n",
        "\n",
        "    # Baseline\n",
        "    ax.axhline(0, color=\"black\", linewidth=1)\n",
        "\n",
        "    # Title, labels\n",
        "    ax.set_title(\"Mirror Plot: Two-Sample Distribution Comparison\", fontsize=14)\n",
        "    ax.set_xlabel(numeric_col)\n",
        "    ax.set_ylabel(\"Density (Top â†‘ vs. Bottom â†“)\", fontsize=11)\n",
        "\n",
        "    # Annotate t-test result\n",
        "    ax.text(0.01, 0.95,\n",
        "            f\"p = {p_val:.3f}\",\n",
        "            transform=ax.transAxes,\n",
        "            fontsize=11,\n",
        "            verticalalignment='top',\n",
        "            bbox=dict(boxstyle=\"round\", facecolor=\"white\", alpha=0.6))\n",
        "\n",
        "    ax.legend()\n",
        "    plt.tight_layout()\n",
        "    return fig"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "fd788680",
      "metadata": {},
      "outputs": [],
      "source": [
        "def two_sample_ttest(numeric_col, alternative, cat_col1, cat_vals1, name_group1, cat_col2, cat_vals2, name_group2, correction):\n",
        "\n",
        "    df, data, stats, error_df, error_plot = prepare_data(numeric_col)\n",
        "    if error_df:\n",
        "        return [\n",
        "            gr.update(visible=False),\n",
        "            gr.update(visible=True),\n",
        "            error_df,\n",
        "            gr.update(visible=False),\n",
        "            gr.update(visible=False),\n",
        "            error_plot\n",
        "        ] \n",
        "\n",
        "    try:\n",
        "        # Ensure category values match the type of the actual column\n",
        "        cat_vals1 = pd.Series(cat_vals1).astype(df[cat_col1].dtype)\n",
        "        cat_vals2 = pd.Series(cat_vals2).astype(df[cat_col2].dtype)\n",
        "\n",
        "        group1 = df[df[cat_col1].isin(cat_vals1)][numeric_col].dropna()\n",
        "        group2 = df[df[cat_col2].isin(cat_vals2)][numeric_col].dropna()\n",
        "\n",
        "        if group1.empty or group2.empty:\n",
        "            return [\n",
        "                gr.update(visible=False),\n",
        "                gr.update(visible=True),\n",
        "                pd.DataFrame([[\"One or both groups are empty after filtering.\"]], columns=[\"Error\"]),\n",
        "                gr.update(visible=False),\n",
        "                gr.update(visible=False),\n",
        "                error_plot\n",
        "            ]\n",
        "\n",
        "        # --- t-test ---\n",
        "        df_output = pg.ttest(group1, group2, alternative=alternative, paired=False, correction=correction).round(ROUND)\n",
        "\n",
        "        # --- Plot ---\n",
        "        fig = mirror_plot(numeric_col, group1, name_group1, group2, name_group2, df_output)\n",
        "\n",
        "        export_cache[\"table\"] = df_output\n",
        "        export_cache[\"figure\"] = fig\n",
        "\n",
        "        # output_table_row, output_table, output_table, output_plot_row, output_plot, output_plot\n",
        "        return gr.update(visible=True), gr.update(visible=True), df_output, gr.update(visible=True), gr.update(visible=True), fig\n",
        "\n",
        "    except Exception as e:\n",
        "        return [\n",
        "            gr.update(visible=False),\n",
        "            gr.update(visible=True),\n",
        "            pd.DataFrame([[f\"âŒ Error: {e}\"]], columns=[\"Error\"]),\n",
        "            gr.update(visible=False),\n",
        "            gr.update(visible=False),\n",
        "            None\n",
        "        ]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "id": "fbede597",
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_variance_distribution(p, group1, name_group1, var1, group2, name_group2, var2, method, bootstrap_samples):\n",
        "        # Bootstrap variances\n",
        "        boot1 = [np.var(np.random.choice(group1, size=len(group1), replace=True), ddof=1)\n",
        "                for _ in range(bootstrap_samples)]\n",
        "        boot2 = [np.var(np.random.choice(group2, size=len(group2), replace=True), ddof=1)\n",
        "                for _ in range(bootstrap_samples)]\n",
        "\n",
        "        # Plot\n",
        "        fig, ax = plt.subplots(figsize=(8, 5))\n",
        "        sns.kdeplot(boot1, label=f\"{name_group1} variance\", fill=True, color=\"rebeccapurple\", alpha=0.6, ax=ax)\n",
        "        sns.kdeplot(boot2, label=f\"{name_group2} variance\", fill=True, color=\"tab:orange\", alpha=0.6, ax=ax)\n",
        "\n",
        "        ax.axvline(var1, color=\"rebeccapurple\", linestyle=\"--\", linewidth=2)\n",
        "        ax.axvline(var2, color=\"tab:orange\", linestyle=\"--\", linewidth=2)\n",
        "\n",
        "        ax.set_title(f\"Bootstrap Variance Distributions\\n{method}\", fontsize=14)\n",
        "        ax.set_xlabel(\"Variance\", fontsize=12)\n",
        "        ax.set_ylabel(\"Density\", fontsize=12)\n",
        "        ax.grid(True, linestyle=\"--\", alpha=0.5)\n",
        "\n",
        "        # Annotate test result\n",
        "        ax.text(0.98, 0.95,\n",
        "                f\"{method}\\n\"\n",
        "                f\"p = {round(p, 3)}\\n\"\n",
        "                f\"Var({name_group1}) = {round(var1, 2)}\\n\"\n",
        "                f\"Var({name_group2}) = {round(var2, 2)}\",\n",
        "                transform=ax.transAxes,\n",
        "                ha=\"right\", va=\"top\",\n",
        "                bbox=dict(boxstyle=\"round\", facecolor=\"white\", alpha=0.7),\n",
        "                fontsize=11)\n",
        "\n",
        "        ax.legend()\n",
        "        plt.tight_layout()\n",
        "\n",
        "        return fig"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "id": "5fc7a4af",
      "metadata": {},
      "outputs": [],
      "source": [
        "def variance_test(numeric_col, cat_col1, cat_vals1, name_group1,\n",
        "                  cat_col2, cat_vals2, name_group2,\n",
        "                  test_type, graph_check, bootstrap_samples):\n",
        "\n",
        "    df, data, stats, error_df, error_plot = prepare_data(numeric_col)\n",
        "    if error_df:\n",
        "        return [\n",
        "            gr.update(visible=False),\n",
        "            gr.update(visible=True),\n",
        "            error_df,\n",
        "            gr.update(visible=False),\n",
        "            gr.update(visible=False),\n",
        "            error_plot\n",
        "        ]\n",
        "\n",
        "    try:\n",
        "        # Ensure category values match the type of the actual column\n",
        "        cat_vals1 = pd.Series(cat_vals1).astype(df[cat_col1].dtype)\n",
        "        cat_vals2 = pd.Series(cat_vals2).astype(df[cat_col2].dtype)\n",
        "\n",
        "        group1 = df[df[cat_col1].isin(cat_vals1)][numeric_col].dropna()\n",
        "        group2 = df[df[cat_col2].isin(cat_vals2)][numeric_col].dropna()\n",
        "\n",
        "        if group1.empty or group2.empty:\n",
        "            err = pd.DataFrame([[\"One or both groups are empty after filtering.\"]], columns=[\"Error\"])\n",
        "            return [\n",
        "                gr.update(visible=False),\n",
        "                gr.update(visible=True),\n",
        "                err,\n",
        "                gr.update(visible=False),\n",
        "                gr.update(visible=False),\n",
        "                None\n",
        "            ]\n",
        "\n",
        "        # --- Apply variance test ---\n",
        "        if test_type == \"Bartlett\":\n",
        "            stat, p = bartlett(group1, group2)\n",
        "            method = \"Bartlett's test\"\n",
        "        elif test_type == \"Levene\":\n",
        "            stat, p = levene(group1, group2, center=\"mean\")\n",
        "            method = \"Levene's test\"\n",
        "        else:\n",
        "            err = pd.DataFrame([[\"Invalid test type selected.\"]], columns=[\"Error\"])\n",
        "            return [\n",
        "                gr.update(visible=False),\n",
        "                gr.update(visible=True),\n",
        "                err,\n",
        "                gr.update(visible=False),\n",
        "                gr.update(visible=False),\n",
        "                None\n",
        "            ]\n",
        "\n",
        "        # --- Observed variances ---\n",
        "        var1 = np.var(group1, ddof=1)\n",
        "        var2 = np.var(group2, ddof=1)\n",
        "\n",
        "        # --- Create result table ---\n",
        "        df_output = pd.DataFrame({\n",
        "            \"Test\": [method],\n",
        "            \"Statistic\": [round(stat, ROUND)],\n",
        "            \"p-value\": [round(p, ROUND)],\n",
        "            f\"Var({name_group1})\": [round(var1, ROUND)],\n",
        "            f\"Var({name_group2})\": [round(var2, ROUND)]\n",
        "        })\n",
        "\n",
        "        # --- Create plot ---\n",
        "        if graph_check:\n",
        "            fig = plot_variance_distribution(p, group1, name_group1, var1, group2, name_group2, var2, method, bootstrap_samples)\n",
        "\n",
        "            export_cache[\"table\"] = df_output\n",
        "            export_cache[\"figure\"] = fig\n",
        "\n",
        "            return [\n",
        "                gr.update(visible=True),\n",
        "                gr.update(visible=True),\n",
        "                df_output,\n",
        "                gr.update(visible=True),\n",
        "                gr.update(visible=True),\n",
        "                fig\n",
        "            ]\n",
        "        \n",
        "        else:\n",
        "            export_cache[\"table\"] = df_output\n",
        "            export_cache[\"figure\"] = None\n",
        "\n",
        "            return [\n",
        "                gr.update(visible=True),\n",
        "                gr.update(visible=True),\n",
        "                df_output,\n",
        "                gr.update(visible=False),\n",
        "                gr.update(visible=False),\n",
        "                None\n",
        "            ]\n",
        "\n",
        "    except Exception as e:\n",
        "        err = pd.DataFrame([[f\"âŒ Error: {e}\"]], columns=[\"Error\"])\n",
        "        return [\n",
        "            gr.update(visible=False),\n",
        "            gr.update(visible=True),\n",
        "            err,\n",
        "            gr.update(visible=False),\n",
        "            gr.update(visible=False),\n",
        "            None\n",
        "        ]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "id": "da466086",
      "metadata": {},
      "outputs": [],
      "source": [
        "def one_way_anova_plot(data_group, numeric_col, cat_col, df_output):\n",
        "\n",
        "    f_val = df_output[\"F\"].values[0]\n",
        "    p_val = df_output[\"p-unc\"].values[0]\n",
        "\n",
        "    # Unique groups and color palette\n",
        "    groups = sorted(data_group[cat_col].dropna().unique())\n",
        "    palette = sns.color_palette(\"tab10\", n_colors=len(groups))\n",
        "    group_color_map = {group: color for group, color in zip(groups, palette)}\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(8, 5))\n",
        "\n",
        "    # Plot KDEs manually, one per group\n",
        "    for group in groups:\n",
        "        subset = data_group[data_group[cat_col] == group][numeric_col].dropna()\n",
        "        sns.kdeplot(\n",
        "            subset,\n",
        "            fill=True,\n",
        "            common_norm=False,\n",
        "            color=group_color_map[group],\n",
        "            alpha=0.5,\n",
        "            linewidth=1,\n",
        "            label=str(group),\n",
        "            ax=ax\n",
        "        )\n",
        "\n",
        "    # Overall mean\n",
        "    overall_mean = data_group[numeric_col].mean()\n",
        "    ax.axvline(overall_mean, color=\"black\", linestyle=\":\", linewidth=1.2, label=\"Overall mean\")\n",
        "\n",
        "    ax.legend(title=cat_col)\n",
        "\n",
        "    # Add group means with matching colors\n",
        "    group_means = data_group.groupby(cat_col)[numeric_col].mean()\n",
        "    for group, mean_val in group_means.items():\n",
        "        ax.axvline(mean_val, color=group_color_map[group], linestyle=\"--\", linewidth=1.5, label=f\"{group} mean\")\n",
        "\n",
        "    # Annotation with F and p\n",
        "    ax.text(0.98, 0.95,\n",
        "            f\"p = {p_val:.3f}\",\n",
        "            transform=ax.transAxes,\n",
        "            ha=\"right\", va=\"top\",\n",
        "            bbox=dict(boxstyle=\"round\", facecolor=\"white\", alpha=0.7),\n",
        "            fontsize=11)\n",
        "\n",
        "    # Labels and title\n",
        "    ax.set_title(\"Group Distributions for One-way ANOVA\", fontsize=14)\n",
        "    ax.set_xlabel(numeric_col, fontsize=12)\n",
        "    ax.set_ylabel(\"Density\", fontsize=12)\n",
        "    ax.grid(True, linestyle=\"--\", alpha=0.3)\n",
        "    plt.tight_layout()\n",
        "\n",
        "    return fig\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "id": "473e7ee8",
      "metadata": {},
      "outputs": [],
      "source": [
        "def one_way_anova(numeric_col, cat_col, cat_vals):\n",
        "    df, data, stats, error_df, error_plot = prepare_data(numeric_col)\n",
        "    if error_df:\n",
        "        return[\n",
        "            gr.update(visible=False),\n",
        "            gr.update(visible=True),\n",
        "            error_df,\n",
        "            gr.update(visible=False),\n",
        "            gr.update(visible=False),\n",
        "            error_plot\n",
        "        ] \n",
        "\n",
        "    try:\n",
        "        # Ensure category values match the type of the actual column\n",
        "        cat_vals = pd.Series(cat_vals).astype(df[cat_col].dtype)\n",
        "        data_group = df[df[cat_col].isin(cat_vals)][[numeric_col, cat_col]].dropna()\n",
        "\n",
        "        if data_group.empty:\n",
        "            err = pd.DataFrame([[\"Dataset is empty after filtering.\"]], columns=[\"Error\"])\n",
        "            return [\n",
        "                gr.update(visible=False),\n",
        "                gr.update(visible=True),\n",
        "                err,\n",
        "                gr.update(visible=False),\n",
        "                gr.update(visible=False),\n",
        "                error_plot\n",
        "            ]\n",
        "\n",
        "        # --- One-way ANOVA ---\n",
        "        df_output = pg.anova(dv=numeric_col, between=cat_col, data=data_group, detailed=True).round(ROUND)\n",
        "\n",
        "        # --- Plot setup ---\n",
        "        fig = one_way_anova_plot(data_group, numeric_col, cat_col, df_output)\n",
        "\n",
        "        export_cache[\"table\"] = df_output\n",
        "        export_cache[\"figure\"] = fig\n",
        "\n",
        "        return gr.update(visible=True), gr.update(visible=True), df_output, gr.update(visible=True), gr.update(visible=True), fig\n",
        "\n",
        "    except Exception as e:\n",
        "        err = pd.DataFrame([[f\"âŒ Error: {e}\"]], columns=[\"Error\"])\n",
        "        return gr.update(visible=False), gr.update(visible=True), err, gr.update(visible=False), gr.update(visible=False), None\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5c5d9fcb",
      "metadata": {},
      "source": [
        "# ðŸŽ® ðŸ§ª Logic control of Hypothesis Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "id": "ca04a49b",
      "metadata": {},
      "outputs": [],
      "source": [
        "def refresh_categorical_columns():\n",
        "    df = df_cache.get(\"df\")\n",
        "    if df is None:\n",
        "        return [gr.update(choices=[])] * 6\n",
        "\n",
        "    cat_cols = df_cache.get(\"categorical_cols\", [])\n",
        "    return [\n",
        "        gr.update(choices=cat_cols, value=None),  # cat_column_dropdown_1\n",
        "        gr.update(choices=cat_cols, value=None),  # cat_column_dropdown_2\n",
        "        gr.update(choices=cat_cols, value=None),  # cat_column_dropdown_3\n",
        "        gr.update(choices=[], value=[]),          # cat_values_dropdown_1\n",
        "        gr.update(choices=[], value=[]),          # cat_values_dropdown_2\n",
        "        gr.update(choices=[], value=[])           # cat_values_dropdown_3\n",
        "    ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "id": "acc10a33",
      "metadata": {},
      "outputs": [],
      "source": [
        "def update_category_options(col):\n",
        "    df = df_cache.get(\"df\")\n",
        "    if df is None:\n",
        "        return gr.update(choices=[], value=[])\n",
        "\n",
        "    values = sorted(df[col].dropna().unique()) if col else []\n",
        "    values_str = [str(v) for v in values]\n",
        "\n",
        "    return gr.update(choices=values_str, value=[])\n",
        "\n",
        "def update_group_name(cat_vals, default_label):\n",
        "    # If exactly one category is selected, use it directly\n",
        "    if len(cat_vals) >= 1:\n",
        "        return gr.update(value=cat_vals[0])\n",
        "\n",
        "    # If nothing is selected, also fallback to default label\n",
        "    return gr.update(value=default_label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "id": "3efd95c3",
      "metadata": {},
      "outputs": [],
      "source": [
        "def toggle_hypo_test(sel):\n",
        "    if sel == \"One sample Student's t-test\":\n",
        "        return [\n",
        "            gr.update(visible=True),  # mu0_input\n",
        "            gr.update(visible=True),  # alternative\n",
        "            gr.update(visible=True),  # ttest_graph_option\n",
        "            gr.update(visible=False), # ttest_correction_variance\n",
        "            gr.update(visible=False), # select_variance_test\n",
        "            gr.update(visible=False), # category_group\n",
        "            gr.update(visible=False), # group1\n",
        "            gr.update(visible=False), # group2\n",
        "            gr.update(visible=False)  # group_anova\n",
        "        ]\n",
        "    elif sel == \"Equal variance between two groups\":\n",
        "        return [\n",
        "            gr.update(visible=False),\n",
        "            gr.update(visible=False),\n",
        "            gr.update(visible=True),  \n",
        "            gr.update(visible=False), \n",
        "            gr.update(visible=True), \n",
        "            gr.update(visible=True), \n",
        "            gr.update(visible=True), \n",
        "            gr.update(visible=True), \n",
        "            gr.update(visible=False)  \n",
        "        ]\n",
        "    elif sel == \"Two samples Student's t-test\":\n",
        "        return [\n",
        "            gr.update(visible=False),\n",
        "            gr.update(visible=True),\n",
        "            gr.update(visible=False),  \n",
        "            gr.update(visible=True), \n",
        "            gr.update(visible=False), \n",
        "            gr.update(visible=True), \n",
        "            gr.update(visible=True), \n",
        "            gr.update(visible=True), \n",
        "            gr.update(visible=False)  \n",
        "        ]\n",
        "    elif sel == \"One-way ANOVA\":\n",
        "        return [\n",
        "            gr.update(visible=False),\n",
        "            gr.update(visible=False),\n",
        "            gr.update(visible=False),  \n",
        "            gr.update(visible=False), \n",
        "            gr.update(visible=False), \n",
        "            gr.update(visible=True), \n",
        "            gr.update(visible=False), \n",
        "            gr.update(visible=False), \n",
        "            gr.update(visible=True)  \n",
        "        ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "id": "2a3fa4c2",
      "metadata": {},
      "outputs": [],
      "source": [
        "def run_hypothesis_testing(\n",
        "        numeric_col,\n",
        "        hypo_test,\n",
        "        mu0_text,\n",
        "        alternative,\n",
        "        graph_check, bootstrap_samples,\n",
        "        cat_col1, cat_vals1, name_group1,\n",
        "        cat_col2, cat_vals2, name_group2,\n",
        "        cat_col3, cat_vals3,\n",
        "        correction,\n",
        "        test_type\n",
        "    ):\n",
        "\n",
        "    if hypo_test == \"One sample Student's t-test\":\n",
        "        return one_sample_ttest(numeric_col, mu0_text, alternative, graph_check, bootstrap_samples)\n",
        "    elif hypo_test == \"Two samples Student's t-test\":\n",
        "        return two_sample_ttest(numeric_col, alternative, cat_col1, cat_vals1, name_group1, cat_col2, cat_vals2, name_group2, correction)\n",
        "    elif hypo_test == \"Equal variance between two groups\":\n",
        "        return variance_test(numeric_col, cat_col1, cat_vals1, name_group1, cat_col2, cat_vals2, name_group2, test_type, graph_check, bootstrap_samples)\n",
        "    elif hypo_test == \"One-way ANOVA\":\n",
        "        return one_way_anova(numeric_col, cat_col3, cat_vals3)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0bcc2acf",
      "metadata": {},
      "source": [
        "# ðŸ–¥ï¸ ðŸ§ª GUI of Hypothesis Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "id": "6ba6208d",
      "metadata": {},
      "outputs": [],
      "source": [
        "def build_hypothesis_tab():\n",
        "    gr.Markdown(\"# ðŸ§ª Hypothesis Testing\")\n",
        "\n",
        "    with gr.Row(elem_id=\"row_centered\"):\n",
        "        refresh_columns_button = gr.Button(\"ðŸ”„ Refresh Numeric Columns\")\n",
        "        column_dropdown = gr.Dropdown(label=\"Select Numeric Column\", choices=[], interactive=True, elem_classes=\"data_related\", elem_id=\"custom_dropdown\")\n",
        "        \n",
        "        hypo_test_dropdown = gr.Dropdown(\n",
        "            label=\"Type of Hypothesis\",\n",
        "            choices=[\n",
        "                \"One sample Student's t-test\",\n",
        "                \"Equal variance between two groups\",\n",
        "                \"Two samples Student's t-test\",\n",
        "                \"One-way ANOVA\"\n",
        "            ],\n",
        "            value=\"One sample Student's t-test\",\n",
        "            interactive=True\n",
        "        )\n",
        "\n",
        "        mu0_input = gr.Textbox(label=\"Î¼â‚€ (Null Hypothesis Mean)\", value=\"\", visible=True)\n",
        "        alternative = gr.Radio(label=\"Alternative hypothesis\", choices=[\"two-sided\", \"greater\", \"less\"], value=\"two-sided\", interactive=True, visible=True)\n",
        "        ttest_correction_check = gr.Checkbox(label=\"Correct for unequal variances (Welch's t-test)\", value=True, visible=False)\n",
        "        equal_var_dropdown = gr.Dropdown(label=\"Select Variance Test\", choices=[\"Bartlett\", \"Levene\"], value=\"Levene\", visible=False)\n",
        "\n",
        "    with gr.Row() as ttest_graph_option:\n",
        "        ttest_graph_check = gr.Checkbox(label=\"Include graph\", value=True, interactive=True)\n",
        "        ttest_boots_sample = gr.Slider(minimum=100, maximum=5000, value=1000, step=100, label=\"Bootstrap Samples\")\n",
        "\n",
        "    with gr.Group(visible=False) as category_group:\n",
        "        refresh_categorical_button = gr.Button(\"ðŸ”„ Refresh Categorical Columns\")\n",
        "\n",
        "        with gr.Row() as group1:\n",
        "            cat_column_dropdown_1 = gr.Dropdown(label=\"Categorical Column 1\", choices=[], elem_classes=\"data_related\", elem_id=\"custom_dropdown\")\n",
        "            cat_values_dropdown_1 = gr.Dropdown(label=\"Categories for Column 1\", multiselect=True, choices=[], interactive=True, elem_classes=\"data_related\", elem_id=\"custom_dropdown\")\n",
        "            name_group1 = gr.Textbox(label=\"Name of Group 1\", value=\"Group 1\", visible=True, interactive=True)\n",
        "\n",
        "        with gr.Row() as group2:\n",
        "            cat_column_dropdown_2 = gr.Dropdown(label=\"Categorical Column 2\", choices=[], elem_classes=\"data_related\", elem_id=\"custom_dropdown\")\n",
        "            cat_values_dropdown_2 = gr.Dropdown(label=\"Categories for Column 2\", multiselect=True, choices=[], interactive=True, elem_classes=\"data_related\", elem_id=\"custom_dropdown\")\n",
        "            name_group2 = gr.Textbox(label=\"Name of Group 2\", value=\"Group 2\", visible=True, interactive=True)\n",
        "\n",
        "        with gr.Row() as group_anova:\n",
        "            cat_column_dropdown_3 = gr.Dropdown(label=\"Categorical Column\", choices=[], elem_classes=\"data_related\", elem_id=\"custom_dropdown\")\n",
        "            cat_values_dropdown_3 = gr.Dropdown(label=\"Categories for Column\", multiselect=True, choices=[], interactive=True, elem_classes=\"data_related\", elem_id=\"custom_dropdown\")\n",
        "\n",
        "    with gr.Column(elem_id=\"column_centered\"):\n",
        "        run_hypo_test_button = gr.Button(value=\"ðŸš€ Run Hypothesis Testing\", elem_id=\"run_button\")\n",
        "\n",
        "    # --- Results ---\n",
        "    output_table_row, output_table, output_plot_row, output_plot = build_results_block()\n",
        "\n",
        "    # --- Modify behavior of components of the GUI ---\n",
        "    hypo_test_dropdown.change(\n",
        "        fn=toggle_hypo_test,\n",
        "        inputs=[hypo_test_dropdown],\n",
        "        outputs=[mu0_input, alternative, ttest_graph_option, ttest_correction_check, equal_var_dropdown, category_group, group1, group2, group_anova]\n",
        "    )\n",
        "\n",
        "    refresh_columns_button.click(\n",
        "        fn=load_numeric_cols,\n",
        "        inputs=[],\n",
        "        outputs=[column_dropdown]\n",
        "    )\n",
        "\n",
        "    ttest_graph_check.change(\n",
        "        fn=lambda check: gr.update(visible=check),\n",
        "        inputs=[ttest_graph_check],\n",
        "        outputs=[ttest_boots_sample],\n",
        "    )\n",
        "\n",
        "    refresh_categorical_button.click(\n",
        "        fn=refresh_categorical_columns,\n",
        "        outputs=[\n",
        "            cat_column_dropdown_1,\n",
        "            cat_column_dropdown_2,\n",
        "            cat_column_dropdown_3,\n",
        "            cat_values_dropdown_1,\n",
        "            cat_values_dropdown_2,\n",
        "            cat_values_dropdown_3\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    cat_column_dropdown_1.change(\n",
        "        fn=update_category_options,\n",
        "        inputs=[cat_column_dropdown_1],\n",
        "        outputs=[cat_values_dropdown_1]\n",
        "    )\n",
        "\n",
        "    cat_column_dropdown_2.change(\n",
        "        fn=update_category_options,\n",
        "        inputs=[cat_column_dropdown_2],\n",
        "        outputs=[cat_values_dropdown_2]\n",
        "    )\n",
        "\n",
        "    cat_column_dropdown_3.change(\n",
        "        fn=update_category_options,\n",
        "        inputs=[cat_column_dropdown_3],\n",
        "        outputs=[cat_values_dropdown_3]\n",
        "    )\n",
        "\n",
        "    cat_values_dropdown_1.change(\n",
        "        fn=update_group_name,\n",
        "        inputs=[cat_values_dropdown_1, name_group1],\n",
        "        outputs=name_group1\n",
        "    )\n",
        "\n",
        "    cat_values_dropdown_2.change(\n",
        "        fn=update_group_name,\n",
        "        inputs=[cat_values_dropdown_2, name_group2],\n",
        "        outputs=name_group2\n",
        "    )\n",
        "\n",
        "    # --- Run Analysis Button ---\n",
        "    run_hypo_test_button.click(\n",
        "        fn=run_hypothesis_testing,\n",
        "        inputs=[\n",
        "            column_dropdown,\n",
        "            hypo_test_dropdown,\n",
        "            mu0_input,\n",
        "            alternative,\n",
        "            ttest_graph_check, ttest_boots_sample,\n",
        "            cat_column_dropdown_1, cat_values_dropdown_1, name_group1,\n",
        "            cat_column_dropdown_2, cat_values_dropdown_2, name_group2,\n",
        "            cat_column_dropdown_3, cat_values_dropdown_3,\n",
        "            ttest_correction_check,\n",
        "            equal_var_dropdown\n",
        "        ],\n",
        "        outputs=[output_table_row, output_table, output_table, output_plot_row, output_plot, output_plot]\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "de26827f",
      "metadata": {},
      "source": [
        "# ðŸ§  ðŸ“ˆ Brain of Linear Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "id": "93432bdb",
      "metadata": {},
      "outputs": [],
      "source": [
        "def PlotSimpleRegression(data, x, y, intercept, formula_check, formula_latex, model, alpha, show_ci, show_pi, fit_to_obs, x_vect):\n",
        "\n",
        "    # Prepare prediction input\n",
        "    if fit_to_obs:\n",
        "        data = data.copy().sort_values(x).reset_index(drop=True)\n",
        "        x_plot = data[x]\n",
        "        X_pred = data[[x]]\n",
        "    else:\n",
        "        x_plot = x_vect\n",
        "        X_pred = pd.DataFrame({x: x_vect})\n",
        "\n",
        "    # Add intercept if needed\n",
        "    if intercept:\n",
        "        X_pred = sm.add_constant(X_pred)\n",
        "\n",
        "    # Get predictions and intervals\n",
        "    pred_table = model.get_prediction(X_pred).summary_frame(alpha=alpha)\n",
        "\n",
        "    # --- Plotting ---\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(8, 5.5))\n",
        "    # Scatter plot of data\n",
        "    sns.scatterplot(data=data, x=x, y=y, ax=ax,\n",
        "                    s=50, edgecolor=\"black\", linewidth=0.5,\n",
        "                    zorder=3, label=\"Data\")\n",
        "\n",
        "    # Regression line\n",
        "    ax.plot(x_plot, pred_table[\"mean\"], color=\"royalblue\", linewidth=2, label=\"Prediction\")\n",
        "\n",
        "    # Confidence interval\n",
        "    if show_ci:\n",
        "        ax.fill_between(\n",
        "            x_plot,\n",
        "            pred_table[\"mean_ci_lower\"],\n",
        "            pred_table[\"mean_ci_upper\"],\n",
        "            color=\"pink\",\n",
        "            alpha=0.5,\n",
        "            label=\"Confidence Interval (mean)\"\n",
        "        )\n",
        "\n",
        "    # Prediction interval\n",
        "    if show_pi:\n",
        "        ax.fill_between(\n",
        "            x_plot,\n",
        "            pred_table[\"obs_ci_lower\"],\n",
        "            pred_table[\"obs_ci_upper\"],\n",
        "            color=\"mediumpurple\",\n",
        "            alpha=0.4,\n",
        "            label=\"Prediction Interval (new obs)\"\n",
        "        )\n",
        "\n",
        "    # Highlight extrapolation region (if applicable)\n",
        "    if not fit_to_obs:\n",
        "        xmin, xmax = data[x].min(), data[x].max()\n",
        "        ax.axvspan(x_vect[0], xmin, color=\"gray\", alpha=0.1)\n",
        "        ax.axvspan(xmax, x_vect[-1], color=\"gray\", alpha=0.1)\n",
        "\n",
        "    # Title with formula\n",
        "    if formula_check:\n",
        "        if formula_latex:\n",
        "            ax.set_title(f\"Linear Regression: ${formula_latex}$\", fontsize=14)\n",
        "        else:\n",
        "            ax.set_title(f\"Linear Regression: {y} ~ {x}\", fontsize=14)\n",
        "    else:\n",
        "        ax.set_title(f\"Linear Regression: {y} ~ {x}\", fontsize=14)\n",
        "\n",
        "    # R-squared annotation\n",
        "    r2 = model.rsquared\n",
        "    ax.text(0.05, 0.95, f\"$R^2 = {r2:.3f}$\", transform=ax.transAxes,\n",
        "            ha=\"left\", va=\"top\", fontsize=11,\n",
        "            bbox=dict(boxstyle=\"round\", facecolor=\"white\", alpha=0.8))\n",
        "\n",
        "    # Axis labels\n",
        "    ax.set_xlabel(x, fontsize=12)\n",
        "    ax.set_ylabel(y, fontsize=12)\n",
        "\n",
        "    # Deduplicate legend\n",
        "    handles, labels = ax.get_legend_handles_labels()\n",
        "    by_label = dict(zip(labels, handles))\n",
        "    ax.legend(by_label.values(), by_label.keys(), frameon=False)\n",
        "\n",
        "    ax.grid(True, linestyle=\"--\", alpha=0.3)\n",
        "    \n",
        "    return fig\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "id": "4a96ae91",
      "metadata": {},
      "outputs": [],
      "source": [
        "def PlotCompareYHatY(data, y, model, alpha):\n",
        "    pred_table = model.get_prediction().summary_frame(alpha=alpha)\n",
        "    y_true = data[y]\n",
        "    y_pred = pred_table[\"mean\"]\n",
        "    y_err = pred_table[\"obs_ci_upper\"] - y_pred\n",
        "\n",
        "    residuals = y_true - y_pred\n",
        "    abs_residuals = np.abs(residuals)\n",
        "    max_error = np.max(abs_residuals)\n",
        "\n",
        "    # Create figure\n",
        "    fig, ax = plt.subplots(figsize=(7.5, 5.5))\n",
        "\n",
        "    # Scatter with residual magnitude color-coded, fixed color scale\n",
        "    sc = ax.scatter(\n",
        "        y_true,\n",
        "        y_pred,\n",
        "        c=abs_residuals,\n",
        "        cmap=\"Reds\",\n",
        "        vmin=0,\n",
        "        vmax=max_error,\n",
        "        edgecolor=\"black\",\n",
        "        alpha=0.6,\n",
        "        s=60,\n",
        "        label=\"Predicted vs Observed\",\n",
        "        zorder=3\n",
        "    )\n",
        "\n",
        "    # Error bars\n",
        "    ax.errorbar(\n",
        "        y_true,\n",
        "        y_pred,\n",
        "        yerr=y_err,\n",
        "        fmt=\"none\",\n",
        "        ecolor=\"gray\",\n",
        "        elinewidth=1,\n",
        "        alpha=0.4,\n",
        "        capsize=3,\n",
        "        zorder=1\n",
        "    )\n",
        "\n",
        "    # Reference line\n",
        "    min_val = min(y_true.min(), y_pred.min())\n",
        "    max_val = max(y_true.max(), y_pred.max())\n",
        "    buffer = 0.05 * (max_val - min_val)\n",
        "    ax.plot([min_val, max_val], [min_val, max_val], 'r--', label=\"Perfect Fit\", zorder=2)\n",
        "    ax.set_xlim(min_val - buffer, max_val + buffer)\n",
        "    ax.set_ylim(min_val - buffer, max_val + buffer)\n",
        "\n",
        "    # Title, labels, RÂ²\n",
        "    ax.set_title(\"Observed vs Predicted\", fontsize=14)\n",
        "    ax.set_xlabel(f\"Observed {y}\", fontsize=12)\n",
        "    ax.set_ylabel(f\"Predicted {y}\", fontsize=12)\n",
        "    r2 = model.rsquared\n",
        "    ax.text(0.05, 0.95, f\"$R^2 = {r2:.3f}$\",\n",
        "            transform=ax.transAxes,\n",
        "            ha=\"left\", va=\"top\",\n",
        "            fontsize=11,\n",
        "            bbox=dict(boxstyle=\"round\", facecolor=\"white\", alpha=0.7))\n",
        "\n",
        "    # Colorbar with same scale\n",
        "    cbar = plt.colorbar(sc, ax=ax)\n",
        "    cbar.set_label(\"|Residual|\", rotation=270, labelpad=15)\n",
        "\n",
        "    # Legend and grid\n",
        "    handles, labels = ax.get_legend_handles_labels()\n",
        "    ax.legend(handles, labels, frameon=False)\n",
        "    ax.grid(True, linestyle=\"--\", alpha=0.3)\n",
        "    plt.tight_layout()\n",
        "\n",
        "    return fig\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "id": "06ec4655",
      "metadata": {},
      "outputs": [],
      "source": [
        "def PlotCompareYHatY(data, y, model, alpha=0.05):\n",
        "    pred_table = model.get_prediction().summary_frame(alpha=alpha)\n",
        "    y_true = data[y]\n",
        "    y_pred = pred_table[\"mean\"]\n",
        "    y_err = pred_table[\"obs_ci_upper\"] - y_pred\n",
        "\n",
        "    residuals = y_true - y_pred  # Signed residuals (can use abs below)\n",
        "\n",
        "    # Create figure\n",
        "    fig, ax = plt.subplots(figsize=(7.5, 5.5))\n",
        "\n",
        "    # Scatter plot with sequential colormap (residual magnitude)\n",
        "    sc = ax.scatter(\n",
        "        y_true,\n",
        "        y_pred,\n",
        "        c=np.abs(residuals),\n",
        "        cmap=\"Reds\",  # Sequential colormap\n",
        "        edgecolor=\"black\",\n",
        "        alpha=0.6,\n",
        "        s=60,\n",
        "        label=\"Predicted vs Observed\",\n",
        "        zorder=3\n",
        "    )\n",
        "\n",
        "    # Error bars\n",
        "    ax.errorbar(\n",
        "        y_true,\n",
        "        y_pred,\n",
        "        yerr=y_err,\n",
        "        fmt=\"none\",\n",
        "        ecolor=\"gray\",\n",
        "        elinewidth=1,\n",
        "        alpha=0.4,\n",
        "        capsize=3,\n",
        "        zorder=1\n",
        "    )\n",
        "\n",
        "    # Reference line (perfect prediction)\n",
        "    min_val = min(y_true.min(), y_pred.min())\n",
        "    max_val = max(y_true.max(), y_pred.max())\n",
        "    buffer = 0.05 * (max_val - min_val)\n",
        "    ax.plot([min_val, max_val], [min_val, max_val], 'r--', label=\"Perfect Fit\", zorder=2)\n",
        "    ax.set_xlim(min_val - buffer, max_val + buffer)\n",
        "    ax.set_ylim(min_val - buffer, max_val + buffer)\n",
        "\n",
        "    # Labels and title\n",
        "    ax.set_title(\"Observed vs Predicted\", fontsize=14)\n",
        "    ax.set_xlabel(f\"Observed {y}\", fontsize=12)\n",
        "    ax.set_ylabel(f\"Predicted {y}\", fontsize=12)\n",
        "\n",
        "    # R-squared\n",
        "    r2 = model.rsquared\n",
        "    ax.text(0.05, 0.95, f\"$R^2 = {r2:.3f}$\",\n",
        "            transform=ax.transAxes,\n",
        "            ha=\"left\", va=\"top\",\n",
        "            fontsize=11,\n",
        "            bbox=dict(boxstyle=\"round\", facecolor=\"white\", alpha=0.7))\n",
        "\n",
        "    # Colorbar\n",
        "    cbar = plt.colorbar(sc, ax=ax)\n",
        "    cbar.set_label(\"|Residual|\", rotation=270, labelpad=15)\n",
        "\n",
        "    # Legend\n",
        "    handles, labels = ax.get_legend_handles_labels()\n",
        "    ax.legend(handles, labels, frameon=False)\n",
        "    ax.grid(True, linestyle=\"--\", alpha=0.3)\n",
        "    plt.tight_layout()\n",
        "\n",
        "    return fig\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "id": "10ed386c",
      "metadata": {},
      "outputs": [],
      "source": [
        "def linear_regression(\n",
        "        formula_check,\n",
        "        formula_text,\n",
        "        formula_latex,\n",
        "        dependent_var,\n",
        "        independent_vars,\n",
        "        alpha_input,\n",
        "        intercept,\n",
        "        graph_check,\n",
        "        graph_type,\n",
        "        show_ci,\n",
        "        show_pi,\n",
        "        fit_to_obs,\n",
        "        range_text):\n",
        "\n",
        "    # --- Read data and validate ---\n",
        "    original_df = df_cache.get(\"df\")\n",
        "    filtered_df = df_cache.get(\"filtered_df\")\n",
        "\n",
        "    if original_df is None:\n",
        "        return [\n",
        "            gr.update(visible=False),\n",
        "            gr.update(visible=True),\n",
        "            \"<b>Error:</b> No dataset loaded.\",\n",
        "            gr.update(visible=False),\n",
        "            gr.update(visible=False),\n",
        "            None]\n",
        "\n",
        "    # --- Use filtered data if it differs from original ---\n",
        "    df = filtered_df if filtered_df is not None and not filtered_df.equals(original_df) else original_df\n",
        "\n",
        "    alpha = parse_text(alpha_input)\n",
        "    alpha = 1 - alpha\n",
        "    if alpha is None or not (0 < alpha < 1):\n",
        "        return [\n",
        "            gr.update(visible=False),\n",
        "            gr.update(visible=True),\n",
        "            \"<b>Error:</b> Invalid alpha value.\",\n",
        "            gr.update(visible=False),\n",
        "            gr.update(visible=False),\n",
        "            None]\n",
        "\n",
        "    # Check variable validity\n",
        "    if dependent_var not in df.columns or not all(col in df.columns for col in independent_vars):\n",
        "        return [\n",
        "            gr.update(visible=False),\n",
        "            gr.update(visible=True),\n",
        "            \"<b>Error:</b> Invalid variable selection.\",\n",
        "            gr.update(visible=False),\n",
        "            gr.update(visible=False),\n",
        "            None]\n",
        "\n",
        "    # Drop rows with missing data\n",
        "    data = df[[dependent_var] + independent_vars].dropna()\n",
        "    y = data[dependent_var]\n",
        "    X = data[independent_vars]\n",
        "    try:\n",
        "        if formula_check:\n",
        "            try:\n",
        "                model = smf.ols(data=data, formula=formula_text).fit()\n",
        "            except Exception as e:\n",
        "                return [\n",
        "                    gr.update(visible=False),\n",
        "                    gr.update(visible=True),\n",
        "                    f\"<b>âŒ Please enter a valid regression formula:</b> {e}\",\n",
        "                    gr.update(visible=False),\n",
        "                    gr.update(visible=False),\n",
        "                    None]\n",
        "        else:\n",
        "            if intercept:\n",
        "                X = sm.add_constant(X)\n",
        "            model = sm.OLS(y, X).fit()\n",
        "\n",
        "        summary = model.summary2(alpha=alpha)\n",
        "        summary_html = summary.as_html()\n",
        "        df_output = summary.tables[1].round(ROUND).reset_index().rename({\"index\":\"Variable\"}, axis=1)\n",
        "        \n",
        "    except Exception as e:\n",
        "        df_output = None\n",
        "        return [\n",
        "            gr.update(visible=False),\n",
        "            gr.update(visible=True),\n",
        "            f\"<b>Regression failed:</b> {e}\",\n",
        "            gr.update(visible=False),\n",
        "            gr.update(visible=False),\n",
        "            None]\n",
        "\n",
        "    # Only plot if 1 independent variable\n",
        "    fig = None\n",
        "\n",
        "    if graph_check:\n",
        "        if graph_type == \"Simple Regression\":\n",
        "            x_col = independent_vars[0]\n",
        "\n",
        "            if not range_text:\n",
        "                x_vect = None\n",
        "            else:\n",
        "                x_min, x_max = [float(val.strip()) for val in range_text.split(\",\")]\n",
        "                x_vect = np.linspace(x_min, x_max, 100)\n",
        "                \n",
        "            fig = PlotSimpleRegression(\n",
        "                data, x_col, dependent_var, intercept, formula_check, formula_latex,\n",
        "                model, alpha, show_ci, show_pi, fit_to_obs, x_vect\n",
        "            )\n",
        "\n",
        "        elif graph_type == \"Observed vs Predicted\":\n",
        "            fig = PlotCompareYHatY(data, dependent_var, model, alpha)\n",
        "\n",
        "    export_cache[\"table\"] = df_output\n",
        "    export_cache[\"figure\"] = fig\n",
        "\n",
        "    return gr.update(visible=True), gr.update(visible=True), summary_html, gr.update(visible=True), gr.update(visible=True), fig"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0e410c11",
      "metadata": {},
      "source": [
        "# ðŸŽ® ðŸ“ˆ Logic control of Linear Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "id": "30ec32b1",
      "metadata": {},
      "outputs": [],
      "source": [
        "def update_graph_choices(independent_vars):\n",
        "    if len(independent_vars) == 1:\n",
        "        return gr.update(choices=[\"Simple Regression\", \"Observed vs Predicted\"], value=\"Simple Regression\")\n",
        "    else:\n",
        "        return gr.update(choices=[\"Observed vs Predicted\"], value=\"Observed vs Predicted\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "id": "073b91bc",
      "metadata": {},
      "outputs": [],
      "source": [
        "def toggle_graph_reg(sel, fit_to_obs):\n",
        "    if sel == \"Simple Regression\":\n",
        "        return [\n",
        "            gr.update(visible=True), # show_ci_check\n",
        "            gr.update(visible=True), # show_pi_check\n",
        "            gr.update(visible=True, value=fit_to_obs) # fit_to_obs\n",
        "        ]\n",
        "    elif sel == \"Observed vs Predicted\":\n",
        "        return [\n",
        "            gr.update(visible=False),\n",
        "            gr.update(visible=False),\n",
        "            gr.update(visible=False, value=True)\n",
        "        ]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cbfea3e2",
      "metadata": {},
      "source": [
        "# ðŸ–¥ï¸ ðŸ“ˆ GUI of Linear Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "id": "e48d978b",
      "metadata": {},
      "outputs": [],
      "source": [
        "def build_regression_tab():\n",
        "    gr.Markdown(\"# ðŸ“ˆ Linear Regression\")\n",
        "\n",
        "    with gr.Row(elem_id=\"row_centered\"):\n",
        "        refresh_columns_button = gr.Button(\"ðŸ”„ Refresh Numeric Columns\")\n",
        "        dependent_dropdown = gr.Dropdown(label=\"Dependent Variable\", choices=[], interactive=True, elem_classes=\"data_related\", elem_id=\"custom_dropdown\")\n",
        "        independent_dropdown = gr.Dropdown(label=\"Independent Variable(s)\", multiselect=True, choices=[], interactive=True, elem_classes=\"data_related\", elem_id=\"custom_dropdown\")\n",
        "    \n",
        "    with gr.Row():\n",
        "        formula_check = gr.Checkbox(label=\"Would you like to write down the regression formula?\", value=False, interactive=True)\n",
        "        formula_text = gr.Textbox(label=\"Write the formula\", placeholder=\"Y ~ X + np.sin(X) + I((X-5)**2)\", interactive=True, visible=False)\n",
        "        formula_latex = gr.Textbox(label=\"Write the formula in LaTeX (Optional)\", placeholder=\"Y = X + \\sin(X) + (X-5)^2\", interactive=True, visible=False)\n",
        "\n",
        "    with gr.Row():\n",
        "        alpha_input = gr.Textbox(label=\"Confidence level (e.g. 0.95)\", value=0.95, interactive=True)\n",
        "        intercept_check = gr.Checkbox(label=\"Include intercept\", value=True, interactive=True)\n",
        "        graph_check_reg = gr.Checkbox(label=\"Create graph\", value=True, interactive=True)\n",
        "        \n",
        "    with gr.Row() as graph_options:\n",
        "        graph_dropdown = gr.Dropdown(label=\"Graph\", choices=[\"Simple Regression\", \"Observed vs Predicted\"], interactive=True)\n",
        "        show_ci_check = gr.Checkbox(label=\"Include CI\", value=True, interactive=True)\n",
        "        show_pi_check = gr.Checkbox(label=\"Include PI\", value=True, interactive=True)\n",
        "        fit_to_obs_check = gr.Checkbox(label=\"Fit to observations\", value=True, interactive=True)\n",
        "        x_vect_input = gr.Textbox(label=\"Minimum and maximum of dependent variable \", value=\"\", visible=False, interactive=True)\n",
        "\n",
        "\n",
        "    with gr.Column(elem_id=\"column_centered\"):\n",
        "        run_regression_button = gr.Button(value=\"ðŸš€ Run Linear Regression\", elem_id=\"run_button\")\n",
        "\n",
        "    # --- Results ---\n",
        "    output_table_row, output_table, output_plot_row, output_plot = build_results_block_2()\n",
        "\n",
        "    # --- Modify behavior of components of the GUI ---\n",
        "    formula_check.change(\n",
        "        fn=lambda check: 2*[gr.update(visible=check)] + [gr.update(visible=not check, value=not check)],\n",
        "        inputs=[formula_check],\n",
        "        outputs=[formula_text, formula_latex, intercept_check]\n",
        "    )\n",
        "\n",
        "    refresh_columns_button.click(\n",
        "        fn=load_numeric_cols,\n",
        "        inputs=[],\n",
        "        outputs=[dependent_dropdown]\n",
        "    )\n",
        "\n",
        "    refresh_columns_button.click(\n",
        "        fn=load_numeric_cols,\n",
        "        inputs=[],\n",
        "        outputs=[independent_dropdown]\n",
        "    )\n",
        "\n",
        "    independent_dropdown.change(\n",
        "        fn=update_graph_choices,\n",
        "        inputs=[independent_dropdown],\n",
        "        outputs=[graph_dropdown]\n",
        "    )\n",
        "\n",
        "    graph_check_reg.change(\n",
        "        fn=lambda check: gr.update(visible=check),\n",
        "        inputs=[graph_check_reg],\n",
        "        outputs=[graph_options]\n",
        "    )\n",
        "\n",
        "    graph_dropdown.change(\n",
        "        fn=toggle_graph_reg,\n",
        "        inputs=[graph_dropdown, fit_to_obs_check],\n",
        "        outputs=[show_ci_check, show_pi_check, fit_to_obs_check]\n",
        "    )\n",
        "\n",
        "    fit_to_obs_check.change(\n",
        "        fn=lambda check: gr.update(visible=not check),\n",
        "        inputs=[fit_to_obs_check],\n",
        "        outputs=[x_vect_input]\n",
        "    )\n",
        "\n",
        "    # --- Run Analysis Button ---\n",
        "    run_regression_button.click(\n",
        "        fn=linear_regression,\n",
        "        inputs=[\n",
        "            formula_check, formula_text, formula_latex,\n",
        "            dependent_dropdown, independent_dropdown,\n",
        "            alpha_input, intercept_check,\n",
        "            graph_check_reg, graph_dropdown, show_ci_check, show_pi_check,\n",
        "            fit_to_obs_check, x_vect_input\n",
        "        ],\n",
        "        outputs=[output_table_row, output_table, output_table, output_plot_row, output_plot, output_plot]\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ff8d6205",
      "metadata": {},
      "source": [
        "# ðŸ–¥ï¸ GUI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "id": "4b391ed5",
      "metadata": {},
      "outputs": [],
      "source": [
        "css = \"\"\"\n",
        ".data_related li{\n",
        "    color: orange\n",
        "}\n",
        "\n",
        "#custom_dropdown [data-testid=\"block-info\"] {\n",
        "    color: orange;\n",
        "    /* font-weight: bold; */\n",
        "}\n",
        "\n",
        "#custom_dropdown input {\n",
        "    color: orange; /* !important; */\n",
        "    /* font-weight: bold; */\n",
        "}\n",
        "\n",
        "#custom_dropdown .dropdown-arrow path {\n",
        "  fill: orange;\n",
        "}\n",
        "\n",
        "#custom_dropdown .svelte-1scun43 {\n",
        "  color: orange; /* change color in multiselect */\n",
        "}\n",
        "\n",
        "#row_centered { \n",
        "    align-items: center;\n",
        "}\n",
        "\n",
        "#column_centered { \n",
        "    align-items: center;\n",
        "}\n",
        "\n",
        "#run_button {\n",
        "    width: 33%;  \n",
        "    justify-content: center;   \n",
        "    /* height: 40px; */\n",
        "    /* font-weight: bold; */\n",
        "    /* background-color: #4CAF50; */\n",
        "    /* color: white; */\n",
        "}\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "id": "63520ff5",
      "metadata": {},
      "outputs": [],
      "source": [
        "with gr.Blocks(theme=gr.themes.Soft(), css=css) as demo:\n",
        "    with gr.Tabs():\n",
        "        with gr.TabItem(\"ðŸ—„ï¸ Data\"):\n",
        "            build_data_tab()\n",
        "        with gr.TabItem(\"ðŸ“ Estimation\"):\n",
        "            with gr.Tabs():    \n",
        "                with gr.TabItem(\"ðŸ“Š Graphical Analysis\"):\n",
        "                    build_graphical_tab()\n",
        "                with gr.TabItem(\"ðŸ§® Descriptive Analysis\"):\n",
        "                    build_descriptive_tab()\n",
        "                with gr.TabItem(\"ðŸ’­ Statistical Inference\"):\n",
        "                    build_inference_tab()\n",
        "        with gr.TabItem(\"ðŸ§ª Hypothesis Testing\"):\n",
        "            build_hypothesis_tab()\n",
        "        with gr.TabItem(\"ðŸ“ˆ Linear Regression\"):\n",
        "            build_regression_tab()\n",
        "        #with gr.TabItem(\"ðŸ’€ Survival Analysis\"):\n",
        "        #    gr.Markdown(\"# ðŸš§ Upcoming\")\n",
        "        #with gr.TabItem(\"âŒš Time Series\"):\n",
        "        #    gr.Markdown(\"# ðŸš§ Upcoming\")\n",
        "        #with gr.TabItem(\"ðŸ—ºï¸ Spatial Analysis\"):\n",
        "        #    gr.Markdown(\"# ðŸš§ Upcoming\")\n",
        "        #with gr.TabItem(\"ðŸ­ Industrial Statistics\"):\n",
        "        #    gr.Markdown(\"# ðŸš§ Upcoming\")\n",
        "        #with gr.TabItem(\"ðŸ…±ï¸ Bayesian Statistics\"):\n",
        "        #    gr.Markdown(\"# ðŸš§ Upcoming\")\n",
        "\n",
        "    gr.Markdown(\"### ðŸ¤“ Created by Irving GÃ³mez MÃ©ndez, version 4.1.1, June 2025.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "id": "ffafe234",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "* Running on local URL:  http://127.0.0.1:7860\n",
            "\n",
            "To create a public link, set `share=True` in `launch()`.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": []
          },
          "execution_count": 62,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "demo.launch()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
